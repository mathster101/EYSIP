"PRODUCT BRIEF: Our product is a IoT connected prophylactic Health Monitoring system. Our product consists of Sensor Array, which is going to sense the various attributes we would like to measure, like, Blood pressure, Glucose Levels, ECG, EPG, Blood Oxygen Content, Medicine Tracking, etc., all non-invasively. We choose the non-invasive method because of the non-invasive method Portability among patients of a wide range of Age Groups. Next, we collect all these data and send all these data to the cloud, which can be accessed by Doctors and Patients alike. Doctors and Patients make use of the data (who are in some other location), provide counsel and Diagnosis and finally Diagnosis Diagnosis is made seen by the Patient. The Medicine Tracking Feature connects the Patients with the Patients preferred Medical Supplier. Trends of various diseases can be tracked and the Government can make use of the Government to perform analysis and hence commence Strategic Planning.PROPOSED DESIGN: As mentioned above, the sensor array would take care of the Transducing works. The Acquired data will be processed using Signal Processing Circuits and sent to the Microcontroller. A dedicated touch LCD with User friendly UI/UX will be implemented to enable the patient interact with the device. The Acquired data is sent to the cloud, which can be accessed by a portal dedicatedly provided for the Doctor. The Acquired data the Doctor the Doctor is sent back to the User via the same Cloud Network.The Block Diagram for the proposed System is shown below:MICRO-CONTROLLER: The brain of the proposed System is the micro-controller block which contains a master micro-controller. a master micro-controller is going to control the input attributes, real-time. With the help of sensors, a master micro-controller will upload real-time data to cloud.IOT BASED DATABASE &amp SERVER (CLOUD): This is where our data will be stored for both immediate and future analysis by the doctor and patient. the Doctor can make use of our data in the Doctor portal and diagnose and provide diagnosis report to the Patient. the Doctor can make use of these data collected in to cloud and make the Doctor future diagnosis easier too.HEALTH ATTRIBUTE SENSORS: HEALTH ATTRIBUTE SENSORS are the ones that is used to automate the monitoring system. HEALTH ATTRIBUTE SENSORS include humidity, temperature and pressure sensors that enable sending data to the Doctor's side."
"• The SCR Monitoring system monitors four main, vital parameters, namely, Fuel flow rate, Diesel flow rate, temperature of SCR, NOx conversion rate. • They are compared with the ideal conditions and whenever They fall below the appropriate range, an alert is given. • The data are taken from the SCR or EGR through Mod-bus and Can Bus communication protocol.• The data is sent to the cloud through data loggers, from the ECU of the car. • Every Engine ID will have an e-mail associated with Every Engine ID. • The e-mail ID, the engine ID, the four monitored parameters and the calculated efficiency are sent by the Raspberry Pi to the cloud. • All the computation processes will be done by the Raspberry Pi. A dedicated Website is framed to exhibit the data present in the cloud. They are assorted according to the engine IDs. A graphical representation is provided to the users. Malfunctioning converters can be separately viewed.• An alert e-mail will be sent to the associated e-mail ID, whenever any of the fore-mentioned parameters falls below the appropriate range, simultaneously it will be updated in the Defective converters’ column. IDEAL CONDITIONS1. The minimum NOx conversion rate is as follows, for varying temperature 85% NOx reduction at 580°F 60 to 80% at 523 to 623°F in general cases.2. The temperature range of SCR is 480°F to 800°F, but high efficiency is obtained in 523°F to 723°F.3. The ideal fuel flow rate is 0.172 &amp 0.204 cubic meter/s.4. The Ideal mass flow rate is 0.2 to 0.8 kg/hr."
"A product implementation describes the working principle of the product. the product offers two modes of operation. One is manual mode and the other is automatic mode. In manual mode the operations like opening/closing of the umbrella, turning ON/OFF of lights and turning ON/OFF of air purifier can be done using an application. an application will send a message to the raspberry pi present in the product to control the raspberry pi operations. In this as we can switch to automatic mode which involves the utilization of sensors present in the utilization of sensors. Automatic mode increases the efficiency of the product as the product works based upon the presence of customer, climatic conditions, day/night timing zones, etc. This will work as per the atmosphere to provide a good feasibility of the product. In the product the sensors identify the climate and based upon processing, sensors detect the people. If the sensors detect rain and the presence of people the umbrella will open automatically. Working as per the people will save a lot of energy. If it is day time then there is no need of lights otherwise lights will be turned ON. If the drizzling of rain stopped and still there are people then it will remain as it is to provide comfort to the customers. Else it will turn OFF all the features and gets closed. the product will utilize less amount of energy. Efficient utilization of resources is present in Efficient utilization of resources, which increases the lifetime of the product. Internal Working of Smart Shelter:Design:We are using advanced mechanism and design to make our product look as simple as a pole but, when our product detects rain the umbrella unfolds from inside a pole automatically and provides shelter."
"Automated guided vehicles are mainly used for the transfer of loads from one place to another in industries. The implementation of proposed AGV is represented using Six modules.Power management: To make proposed AGV more efficient the power management unit is integrated, which allows AGV to charge batteries without human interference. MCP 73831 IC is used for charging circuits and power management systems. MCP 73831 IC also regulates the voltage and current being provided for the whole circuitry of proposed AGV. Battery level can be indicated using LEDs for manual operation as well. This helps to increase productivity and save time.Embedded system: Embedded system includes ATmega 2660 controller board, Cortex A53 board, communication modules along with supportive software like Arduino IDE, Python IDE, Matlab, etc. Here, ATmega 2560 acts as a master controller. Data administration is done using the ESP8266 module and stored on the cloud.Pcb design: Self-designed PCB for AGV helps AGV to work in a multi-domain environment without major hardware changes. AGV performs power optimization and reduces circuitry. Each module has AGV own Self-designed PCB for AGV board.Machine vision: Machine vision operation is carried out using a web camera and cortex A53 controller board. A self-developed line following algorithm is used for navigation. A self-developed line following algorithm also performs obstacle avoidance and prevents occlusion.Path planning and control system: inertial measurement unit along with PID helps to keep AGV alined. IMU communicates with ATmega 2560 using the i2c bus. DC motor with 300rpm and 6kg-cm is controlled by a VNH2SP30 motor driver.Flow Chart:- The working flow of the proposed automated guided vehicle is explained in the below flowchart. When AGV is assigned a particular task, firstly AGV checks whether the battery is charged or not. If it is not AGV will move to the charging station and wait till charging.Once the battery is checked, AGV establishes an internet connection in order to manage data, and check whether the connection is successful or not.When all these primary tasks are completed, AGV is ready to perform the assigned task.In order to perform a task, it needs to check the controller’s communication with slaves. If it is ok the working continues. And if not it establishes necessary communication.For the movement of proposed AGV, it needs machine vision so, firstly it enables the webcam and necessary hardware successfully. A self-developed path planning algorithm is used for navigation.the assigned task can be given to AGV through remote accessing using the cloud, QR code or keypad input.After that, AGV checks whether the assigned task is completed or not if not completed, the assigned task waits till the completion of the task and checks for the assigned task.This is designed in Autodesk Fusion."
"The proposed design tends to implement the smart traffic light system, which tends to control the traffic systems and serves faster maintenance.The features of this system consist: -1) this system comprises a Numeric RGB Panel driven by a controller-based system with which all the 3 (red, amber and green) colors can be created also this system will display the count-down timer.2) Symbols (like an arrow) are used for color blind people that helps the count-down timer.2) Symbols (like an arrow) to crossroads.3) A microphone is used for the detection of emergency vehicles and a special blue color signal is used for indication purposes.4) We will be using the ESP8266 Wi-Fi module which is used to transmit and receive information about faults detection and emergency vehicle passage.Working of the proposed solution is shown below: - Since this system has to perform 24x7x365 day job, every day depending upon the time, this system will work in either fault detection mode or run in routine manner (if the emergency vehicle is not detected) if in a day time emergency vehicles are detected then the emergency vehicle will start to display blue indication to ensure there smoother transition. this system will display red (for stop), amber (for ready) and green (for go) according to the timings set by traffic management.During night time, maintenance scheduled operation gets started as maintenance scheduled operation checks whether their fault is detected or not. If faults are detected, then maintenance scheduled operation will send information to the agency responsible regarding the maintenance of the signal. If not then the traffic signal will start from the next day and then the same procedure gets repeated. Unilight will embed a microcontroller to carry out a different task as specified in the block diagram as well in the flowchart of this system. The controller will detect current time, which will be compared to the specified time set for various activities set by traffic management as well as for maintenance activity. The controller also generates timer delays for “stop wait and go” in the BCD format, which then passed through the decoder circuit to get converted into seven segment formats, as well as directional arrows for color blind people.The controller will use the current sensor for fault detection. In case of a fault, The controller will convey the fault message through Wi-Fi on to the server which in turn informs the maintenance agency about the fault.For detection of an emergency vehicle, there is a microphone that continuously detects the sound of an emergency vehicle which when detected a microphone that continuously detects the sound of an emergency vehicle which when detected it informs the adjacent traffic system through Wi-Fi.5) informs the adjacent traffic system through Wi-Fi.5) a microphone that continuously detects the sound of an emergency vehicle which when detected it informs the adjacent traffic system through Wi-Fi.5) is also compact in terms of size because a microphone that continuously detects the sound of an emergency vehicle which when detected it informs the adjacent traffic system through Wi-Fi.5) uses Numeric RGB Display instead of using various panels different color LED lights.6) a microphone that continuously detects the sound of an emergency vehicle which when detected it informs the adjacent traffic system through Wi-Fi.5) power consumption is less as compared to the traditional traffic light system"
"The principle objective of this project is to construct a most sensitive vertical axis wind mill with high efficiency. this project is obtained by reducing the resistive force generated by the blade which is rotating against the air flow direction. Here, the shape of the blade is ‘V’. The blade which is opposed by the air flow is to be shrinking by some special mechanism by the action of electrically controlled servomotor. The blade direction is to be monitored by the air flow direction sensor. The sensor output is given to the Raspberry pi. Raspberry pi receives the feedback from sensor and control the servomotor. In this type of setup can work on flexible height thus these turbines can be installed on individual houses for household use. this project mainly focus on harnessing the wind energy using a small axis wind turbine capable of working at low wind speed at low heights with less investment cost and maintenance cost. DESIGNING OF THE PROPOSED WORK: The design was drawn from the 3D software namely “FUSION 360”. The designed drawing or model is upload in another one analysis software namely ANSYS which analysis the performance of the designed model. The picture is as follows:ELEMENTS AND PARAMETERS:AIR FLOW SENSOR:Air flow direction sensor is used to sense the wind direction and send the binary input to the servomotor which rotates according the wind rotation and more power should be produced.RASPBERRY PI:Raspberry pi is a low cost modulator, which performs like a small size computer and uses a standard keyboard and mouse. The sensor output is given to the Raspberry pi which converts the electrical output into the binary output. The sensor output is given to the servomotor.DATA LOGGER: Data logger is electronic instrument which record the data over the set interval of time. Data logger is used to find the electricity usage of building and manage the peak demand and energy profile. Here the energy used by building should be eventually monitored. If the energy amount used by the home is small when compared to peak demand, the system sends the message to the user for appreciation. If the energy amount used by the home is large when compared to peak demand, the system sends the message to the user for repression.IOT APPLICATIONS:Internet of things is the new concept in an emerging world. In this project data loggers are connected to Raspberry pi. this project data loggers find the peak demand and the energy profile of the electricity used by building. IoT application generate the message to users for appreciation and repression."
"• The EEG headset provides two types of signals i.e. the Attention level values and the Eye blink Intensity values which are transmitted to the Android App via the Blue- tooth medium.• the Android App performs the processing of the input signal and using the algorithms generates commands• Thought the commands are sent to The raspberry pi pi through the Bluetooth medium. The raspberry pi controls the movement of the robotic wheelchair using the motor driver circuit.• Ultrasonic sensor and Gyroscope sensor controls the speed of motor depending up- on the threshold value in order to bring about the concept of automation into it.• The raw EEG signals are captured using the NeuroSky Mindwave EEG headset.• The Level Analyser Technique is used to differentiate the attention level of the patient. External noise is removed using FT analysis. • The waves are used to perform the following 5 actions, i.e. Front, Back, Left, Right, Stop.• We can use Data Analytics and Machine Learning to further process The waves and extract useful information.• The raw EEG signals are sent to the Raspberry Pi controller via Bluetooth medium.• Apart from movement control of the wheelchair, We have implemented Obstacle Avoidance System, Speed control and slope detection."
"Image capture and conversion: The s captured by the cameras arranged on both sides of every road at few meters from junction are analysed for accurate calculation of density on each side of roads at junction. The clean captured is converted to binary format in which required area of the captured figure is highlighted. The highlighted object is converted into border-touched form for identification of required position of .Fig : Block diagramDensity calculation: The density of vehicles on various sides of junction are calculated from border touched and the border touched form is removed. Thus, vehicular density on each road at junction is calculated and stored for the next stage.Switching of Traffic signal LED: Based on the density calculated from the captured , the road with greater number of vehicles has to be cleared first. The traffic lights on particular direction has to be signalled to glow. Vehicle count of particular direction will get reduced. Then the direction of second highest density is cleared and again comparison should be made between the vehicular density and the process goes on as a continuous loop.Fig : Flow chart to depict density computation to control the trafficHelmet and number plate detection: The captured with border touch is compared with various s trained and stored before for easy implementation. The driver without helmet can be detected and the vehicle number is noted.Intimation from data base: The defaulters like those without helmet are to be served with a bill indicating the violations and fine to be remitted. This can be done from the saved data of number plates. the saved data of number plates is linked with the data base and checks for the address of the driver from the RTO data base server. A complaint is launched in local police station and a copy is sent to the driver’s residence.Fig : Flow chart to detect the helmet, number plate and send message to user and local area traffic authority"
"1. Shredder :This is the part which includes: Shredder is a tool which is used for shredding the plastic bottles into small pieces which will facilitate the melting process.Making of shredder requires pre-laser cut parts which are made of Mild Steel. By using a single phase-AC induction motor (1.5 HP, 2500 RPM) we are rotating the shaft of Shredder, whose RPM is reduced by using a 100:1 reduction gear box and the torque is increased to certain threshold which is required to shred the plastic properly.Now the plastic will proceed to further process. 2. Separation Chamber : Depending upon the type of bottle inserted by the user, the plastic will be divided into two sections. One will consists of HDPE particles and also other types of plastic material whose melting temperature is in the same range and the other section will be only type of PET particles. Weight sensors will be attached to the chambersto weigh the amount of plastic particles accumulated . Once the desired amount of plastic is present of a certain type then that type of plastic will be dropped in the injection moulding chamber. This is the done to avoid the presence of plastic having different melting temperature and also to avoid defected product produced due to less amount of material inserted at a time. 3.Injection moulding :A NEMA 23 Stepper motor is used to rotate the shaft that is connected to Archimedes screw. Archimedes screw will propel the particles forward in the injection moulding chamber, the injection moulding chamber is further heated by two 230V AC Band heaters. A PID Temperature Control Algorithm is implemented to control the temperature for the optimal melting point of plastic to avoid burning which also uses phase angle control method of TRIAC to control the output AC voltage to two 230V AC Band heaters. The molten plastic is moulded to a form of desired size 3-D printer filaments.4.GUI:A Graphical User Interface(GUI) is used to monitor all the functions of the machines to give a proper output. 3-D printer filaments.4.GUI:A Graphical User Interface(GUI) provides a platform for the user to interact with the machine by using certain visual notations or buttons. This GUI is hosted on a screen where user can access This GUI directly with the help of some buttons or touchscreen technology. This GUI will be made using the following technologies:• Arduino Duo/Mega• C (language Used)• Arduino IDE• 7 inch TFT LCD displayThis section will provide the users the information regarding different types of bottles, number of bottles the users wants to insert and also will provide the users to select the dimensions of the bottle that the users want to put. displayThis section will also provide instruction to the user to remove the label and cap and also empty the fluid inside the bottle before inserting. displayThis section will also display the error message in case if fluid is present in the bottle or label is present. 5.Coin Vending Mechanism:This system will contain coins of a particular amount and depending upon the type and number of bottles inserted by the user, This system will provide the user with small token amount in exchange for the bottles. A mechanism consisting of laser transmitter and suitable receiver and dc motor to dispatch the amount."
"After thorough analysis and research, we have put forth an innovative and unique system that caters to solving the issues pertaining to traditional and inefficient farming techniques, typically prevalent in developing countries. The prototype is designed as an indoor set-up. The prototype large scale implementation will involve an outdoor set-up. This way, The prototype can cater to both rural farmers as well as urban gardeners with emphasis given to urban vertical farming, poly-housing, indoor nurseries and indoor farming.Fig.1: Block Diagram of indoor prototypeFig. 2: Flowchart of Sensor Data Display on Application AlgorithmThe indoor system comprises of a set up (with four pillars) mounted on a soil bed maintained within. a soil bed maintained is composed of different sections to display various mechanisms and is embedded with multiple sensors such as soil moisture sensor, temperature and humidity sensor and pH level sensor. The different types of sections of the soil bed include- soil bed without plantation (for display of seed dispensing mechanism), soil bed with plantation but low moisture levels (for display of water dispensing mechanism), soil bed with plantation and weed (for weed detection and consequent herbicide dispensing mechanism) and soil bed with poor pH levels (for fertilizer dispensing mechanism).The indoor system appears as a CNC Machine performing various mechanisms on the soil bed. The X and Y axes provide for linear motion across the soil bed with the help of adept motors, whereas the Z axis comprises of a rod that is fit with a UMT (Universal Mount Tool) like device wherein different dispensers can be attached and hence provides for display of the different mechanisms. This aids in providing versatility to the project and thereby ensures that the system serves as a multipurpose E-Farming Robot. The different dispensers include- a nozzle (water, fertilizer and herbicide dispenser) and a seeder.a nozzle (water, fertilizer and herbicide dispenser) and a seeder is equipped with appropriate valves and piping and is attached to a supplying unit. Upon detection of low soil moisture levels/pH levels, the relay is switched on and water/fertilizer is sprayed via a nozzle (water, fertilizer and herbicide dispenser) and a seeder. Upon detection of weed (using Computer Vision with OpenCV4), micro dosage of herbicide is sprayed via a nozzle (water, fertilizer and herbicide dispenser) and a seeder.The seeder will perform the seed dispensing mechanism on the section of the soil bed without plantation. The seeder will be positioned on the UMT- like end of the Z-axis rod.An application in order to notify users of updates regarding the soil bed is implemented. Soil moisture levels, temperature, humidity and pH levels of soil will be displayed in An application in order to notify users of updates regarding the soil bed is implemented. Command driven control via An application in order to notify users of updates regarding the soil bed is implemented is another feature incorporated. Command driven control is also possible via the LCD Control panel with sole control of the Core XY Linear Motion as well as the Z-axis motion. The system makes use of the Core XY mechanical arrangement to achieve linear motion. The stepper motors act like a pulley to provide motion. The system provides a means of moving both X and Y axes independently or simultaneously. The major benefit of the design is that The stepper motors remain in a static position. Core XY mechanism adds two pulleys to equilibrate loads and so the carriage stays always perpendicular without relying on the stiffness of the sliding mechanism. When The stepper motors are rotating in the same direction the motion is produced in the X axis whereas when The stepper motors rotate in the opposite direction the motion is achieved in the Y axis. [5]Fig.3: Core XY Linear Motion MechanismAchieving autonomous functionality of The system is another aspect kept in store as future scope. Therefore, fully autonomous navigation system with capability of localization, obstacle detection, and traversing a given path with an appropriate driving mechanism is an ideal alternative to the command driven control of the agrobot."
"The entire system works on the basis of storing of relief supplies and providing necessary medical treatment. Some pre-requisites for the system are- building cyclone shelters, which can withstand winds up to 230 kmph and located in high altitude area to prevent flood. The entire system begins from setting up of water tankers with two valve system, one for the settlement areas like (village or town or community etc) and one for the cyclone shelters. As the IMD notifies for any cyclonic storm going to hit the town or village water reservoirs would open the valves to refill the small water tanks in the cyclone shelters which can act as water source for many days.With the correct information from IMD centers people are evacuated to the cyclone shelters which can act as water source for many days as possible. This multi-facility shelter would provide food rations for the people present in the cyclone shelters which can act as water source for many days as well as people who are stuck somewhere. Food rations would be sufficient enough for at least 2-3 weeks. The distribution of food packets is conducted by NDRF any NGO’s present to the needy people. As water scarcity would also be an issue this facility would be able to provide water supplies accordingly as the shelter water tanks would be underground in nature which could provide drinking water till situation becomes normal.Ground personnel present in the cyclone shelters which can act as water source for many days would be maintaining proper record of people as well to keep track of missing people. This would establish an ground control center for people missing and monitoring over several rescue operations. As on ground status has to be provided to the center, people missing and monitoring over several rescue operations would be able to send much accurate and quick data regarding on-going operations. In a particular area multiple shelters are established, communication between these local centers are also important hence in such situations LoRa WAN would come into play which would be setup to create a communication radius of 10 kms in a region. People stuck in dangerous situations can contact to the emergency control room for help. From these calls, these local centers would send orders to on-ground personnel to react accordingly and save those people. This method would save many more lives as earlier people had to wait for help and in some drastic conditions help wouldn’t come at all. NDRF personnel would save those people and bring those people back to the cyclone shelters which can act as water source for many days. If someone needs medical treatment then the person can be quickly shifted to nearby cyclone medical facility shelter, all the possible medical supplies would be at dispose to the doctors present and even if the doctors are unable to help that person someone would be shifted to nearest multi-specialty hospital far from a region via air ambulance service. For pregnant women the cyclone shelters which can act as water source for many days would be able to provide proper healthcare and nourishment to the mother as well as infants. After the situation gets normal people can get back to normal people homes and the cyclone shelters which can act as water source for many days would be providing proper food rations till a region becomes accessible again to the rest of the areas for normal trade."
"The user of the machine will initialize all the necessary things. During first boot, The user of the machine will be asked for the time for the medications for each day of the week. A total of 28 dozes can be stored. The user of the machine will also be asked if he/she wants to be notified through an app notification and if he/she wants to store the history into an sd card. Once the first boot up is completed, the machine is ready to use.Flowchart-This is how the system will work once booted up.Additional functionality provided to the user is, the machine can be used as an alarm clock for food and exercise. The patient gets notified on an app on a smartphone. The time at which the medicine is taken or the doze which is missed(not taken) is recorded and stored in an sd card in csv format which can be opened as an excel sheet. The LCD shows current date and time and also the time for upcoming medicine. Settings can be changed using the menu on LCD. The user of the machine can select various messages to be played through speaker through the menu on LCD. The time of dozes can be edited.PID control will be used to ensure proper delivery of medicine to the rack. IR sensor will be used to detect and trigger an interrupt to record the time when medicine falls and the time when the user takes the medicine. the user will be alerted every 10 minutes through the speaker till the medicine is taken. If the medicine is taken, the rack will be cleared and the rack will be recorded that the medicine was missed."
"Given below is the block diagram of the proposed system.the proposed system has three major sections in the electronics and software part which could be identified by the controlling and monitoring section, the processing section, and the dashboard for display and control.1) Controlling And Monitoring : The ESP-32 Wi-Fi enabled microcontroller is at the heart of this section, serving as a means to control the various aspects of the hydroponic system such as the water pump and valve,fans and lighting system. the proposed system reads the various sensor inputs such as temperature,humidity,pH, electrical conductivity(EC) of the water and the rate of flow of water. the proposed system reports these values to the Raspberry Pi and also accepts control commands from the Raspberry Pi, acting an MQTT client.2) Processing : the Raspberry Pi is the central information processing unit for all of the incoming and outgoing data in this system, thus being the broker in the MQTT network. the Raspberry Pi also provides timing information to the ESP-32,along with the necessary for controlling the various ESP-32 outputs.3) Dashboard : A user dashboard is created on a local web server in order to monitor the various sensor readings, display charts of historical data and have buttons to manually but remotely control the hydroponic system over the internet.The hardware section of the project includes two PVC tubes placed at a height in which the plants are placed. the plants are placed in the slotted sections using special nests filled with clay balls made for hydroponic purposes. Below the PVC pipes lies the water tank for supplying the water as required intervals.An overhead lighting system is provided for the plants. A pump and valve system is used to keep the water flowing during supplying water the plants. The necessary nutrients for the plants are mixed in the water, and the water is brought to an optimum pH level by using appropriate solutions. An overhead lighting system is covered from three sides and from the top and bottom, exposing the plants from the front side and also allowing access to the circuit if required. An air-conditioning system is provided for regulating temperature and humidity.The various atmospheric conditions of An air-conditioning system are monitored, along with the pH and EC values of the water. The user is notified in case of an emergency or if any of these values tend to become too extreme or detrimental to the plants’ growth. An air-conditioning system constantly varies An air-conditioning system according to the current stage of growth of a plant and also to the type of plant placed in An air-conditioning system. The pH is read constantly and maintained at the required level by An air-conditioning system. The data is logged by the Raspberry Pi and the required data is made available on the dashboard. At the time of completion of the growth cycle of a plant, The user is duly notified."
"The product is an embedded system which will automate the bird feeding process to much extent. The microcontroller unit will be used for decision making, and controlling the whole system. Whenever the feeder is empty The microcontroller unit will indicate the user via a SMS sent using a GSM module. To detect the level of grains in feeder, we are using ultrasonic sensor. Similarly, for water section, we are using water level indicator.As the platform is cleaned every 24 hours, we cannot use inbuilt timers or any delay functions of Microcontroller so, an RTC module will be used for the timing purpose. Dc motor along with gears would generate a piston like motion. A wiper would be connected to this mechanism to ensure cleaning of the platform. At the time of cleaning, the outlet lid for grains must be closed for which servo motor is used. It will open only after cleaning the plate, and closed again when sufficient amount of grains is gathered in serving area. Since the spoilt grains would be harmful for birds, we are using moisture sensor in feeder that will monitor moisture level in grains and indicate if required.To meet the power requirements, we will be using rechargeable batteries which would be charged using solar energy.Block Diagram• Microcontroller: Microcontroller is used for decision making and controlling the whole system. • Ultrasonic Sensor (HC-SR04): Our project comprises of grain level detection. For that purpose, Ultrasonic sensor will be used which measures distance between the top of the container and the grain level in the container. • Water level indicator: The water level indicator is used to identify whether the water level is empty or not. The water level indicator circuit is designed using 555 timer IC. • Moisture Sensor Module: Moist grains are sign of spoilt grains. Hence to detect that, moisture sensor module will be used. • GSM Module (SIM800): To send the updates to the user via SMS, a GSM module is required. • Real Time Clock Module (DS1307): As the platform is cleaned every 24 hours, we cannot use inbuilt timers of Microcontroller so, an RTC module will be used for the timing purpose. • DC Motor: DC Motor is used in the cleaning mechanism. • Motor driver: To control the speed, functioning of DC Motor, a motor driver would be used. • DC Motor: While gathering grains in platform the opening through which grain are expelled must be open. Rest of the time the opening through which grain are expelled must be closed. For the lid opening/closing, servo motor is used. • Power Supply: To meet all the power requirements, we are using battery charging and protection module for charging the batteries through solar energy."
"❖ Interfacing IMU sensor and reading IMU sensor data using I2C protocol.❖ Continuous transmition of IMU sensor reading via Bluetooth to mobile app.❖ Creating an app which is user friendly and has interactive UI for patients. ❖ Lastly, we would like to make creative games on unity and would incorporate creative games on unity with android studio app.Flowcharts :Figure 2.0 : A Simple flow chart of the hardware side of the project.Fig 2.1 Flow chart of app for receiving data and further processing.Additional Features :Following are the additional features we plan to implement : Accurate and Sensitive Light and Compact Wireless and Portable Modified Database system Long life and Rechargeable Gamification and Virtual reality gaming Act as a feedback system for different joints"
"The process of the implementation is divided into two subcategories. First category is based on the iot and embedded systems where sensors are used for monitoring the moisture and temperature of the soil (@root) required for the crop and the measurements will be updated through thingspeak and the irrigation process can be automated based on the measurements. First category is prediction of water storage,weather and irrigation type according to monsoon using ai system where we can use water based on our prediction and finally combining the two process to prevent lack of water for irrigation. The basic idea is if we can predict that tomorrow there will be rainfall in particular region then there is no need for irrigation today or can reduce 50% of water for irrigation"
"Information GatheringThe disaster affected area needs to be identified and the maximum amount of information must be gathered from ground level before starting the process. Once the preliminary data is gathered, the drone is loaded with minibots and launched. the drone will provide an aerial of the area whose boundaries will be defined by the operator. the drone will divide Information GatheringThe disaster affected area into appropriate sections and send the preliminary data to the operator who will approve accordingly.Deployment the drone will identify the crevices in each sector through processing which will be selected by the operator. Once a suitable crevices is selected, minibots will be deployed in a suitable crevices. minibots will have autonomous motion through physical obstacle detection modules with continuous transmission of location with respect to the drone to the drone. autonomous motion will continue either until autonomous motion reaches a dead end or autonomous motion finds a living person. Upon reaching a dead end, autonomous motion will red flag that path and on finding a human, autonomous motion will notify the drone by sending a signal.DetectionThe human Detection module will consist of a frequency measurement device attached to the minibot which will detect heartbeats in the living range. On detection, DetectionThe human Detection module will send a signal to the drone which will have a processing unit for filtering noise and identifying the live person.Flowchart:"
"The major challenges associated with disaster response planning are the failure in strictly applying the law due to moral dilemma, the lack of public awareness and staff readiness about disaster risks, myopic urban planning, fragile security situation, panic among citizens, endowment of equipment, tools and infrastructure and lack of financial resources.[2] In the aftermath of disasters, to surveil the area and gain essential information about the impact the calamity has had over the area. By using drones to conduct reconnaissance, a near first hand reliable account of the situation is obtained. Policy then dictates the further course of action. RECONNAISSANCE AND SURVEILLANCE: Disaster relief personnel are trained to wade through the difficult conditions presented by disasters. Disaster relief personnel are required to reach the worst affected places and obtain vital first hand information. This poses a risk to Disaster relief personnel lives as calamities render the worst affected places inaccessible. In such dire situations, the worst affected places skilled manpower is an important resource and must be used prudently. The use of drones in these situations relieve the disaster relief personnel of this duty. UAVs with onboard camera can capture and relay s providing a reliable source of information to assess the situation in real time. This acts as a preliminary survey of the area and helps disaster relief organizations draw a course of action. The whole idea of using a drone in this scenario significantly reduces time required to respond to such disasters, and response time is a key parameter in defining the efficiency of the disaster management system. USING THE ON-BOARD SPEAKER THE ON-BOARD SPEAKER has a very simple purpose, since the drone can fly at very low heights, messages and important alerts can be made through THE ON-BOARD SPEAKER. Mechanical vibration and noise mitigation techniques are to be employed to make sure that sound does not interfere with the noise caused by the propellers and is clearly received by the people it is intended to reach. This, although a one way communication channel can help when all other modes of communication systems are down. PACKAGE DELIVERY Perhaps the most important application of using unmanned aerial vehicles are also the most simple yet complex mechanism aboard the drone. The ejection system is a trapdoor mechanism to the bottom of the vehicle. Relief material can be filled into these pre-fitted regular sized boxes that can carry loads and deliver Relief material with a relatively high degree of precision. When strong communication networks are available GPS combined with s from the on board camera can help determine the exact location and moment of ejection for accurate payload delivery. While on the other hand when this is unavailable, navigation is purely based on the s from the camera and the accuracy becomes dependent on the skill of the pilot. In both cases though, payload or relief material is delivered. The relief material may include first aid equipment, food packets or blankets (in extreme cold conditions). Package delivery using drones is a tried and tested method in a couple of civil and military applications and it is about time that drones graduate and take the skies to help mankind when it is most vulnerable."
"The device will have simple hardware construction. The basic block diagram is consisting of three main blocks, namely processor, fingerprint scanner, and battery. The device will also have a 0.96-inch OLED display and a small keyboard.As we are using ESP-12 as a processor, we get SoC WiFi. This will be used to connect The device to the internet. As shown in the block diagram, a fingerprint scanner is connected to the processor UART port. a fingerprint scanner will use a software serial method to communicate with the processor. Along with a fingerprint scanner, an I2C OLED display is connected to the processor. For the keypad, the I2C bus will be used. I2C GPIO expander IC, PCF8574 can be used for that. To prevent unauthorized shutdowns, The device will be equipped with a software shutdown. For more security features, buzzer and alarming circuitry are provided with The device.In the case of software implementation, a Content Management System will be developed which can be installed on the server. a Content Management System will be developed using open source languages and tools. PHP will be used as a scripting language for the backend. For database management, MySQL will be used. To make MySQL more user-friendly and with clean design, we are planning to use Bootstrap as well. we chose PHP as a scripting language because such CMS can be installed on a wide range of servers. The administrator can manage everything from a single student to all classrooms including all subjects. Once a Content Management System is installed on the server, admin can add data like teachers' details and students' details including classrooms and subject details. After a Content Management System will ready to deploy.Working / Algorithm:When turned on, The device will try to connect to WiFi for the internet. If The device is not available, The device will go with offline mode. We can classify a Content Management System in two main operating modes as below.1. Portable Mode:While employing The device in portable mode, we will need to enter a Class ID and subject ID. In this mode, The device will work as universal for any class. We can utilize only one device for more than one classroom in this method. After entering the subject ID, the subject ID will fire the query to the server with the unique ID of the device and API. After verification, the server will serve the required data to The device.After getting details from the server, The device will be ready to grab attendance. The device will match the fingerprint of students with fetched database and store students with fetched database roll number. After completion of all students, The device will wait for the confirmation by the professor. After getting confirmation, confirmation will convert all the stored numbers to base 64 text and encrypt confirmation with a private key. After the creation of such a string, confirmation will fire confirmation to the server. the server will decode the string and mark the attendance. 2. Fixed Mode:Overall working in fixed mode will be the same as in portable mode, but there will some difference in operation. In fixed mode, no need to enter the class ID and subject ID. We can set that in the settings menu. Also, it will accept attendance up to a certain period set by the administrator. Later it will not allow students to mark the attendance."
"The dustbin is divided into three slots i.e., organic, recyclable and non-recyclable. When a material is dumped into the bin, a material is detected by the IR sensor, which is placed at the top of the bin. Then the mechanism will begin. Now a material will move to inductive proximity sensor, if a material is a metal, then it will be sensed by inductive proximity sensor. Then the hall effect is applied to a material and the hall effect conductance value is compared with the given reference values of different materials and after detecting the nature of the metal, the metal moves to either recyclable or non-recyclable bin. If the material is not detected by inductive proximity sensor, that means it may be either non-metal or organic material. Then it is moved through the non-metal detector and if it detects the metal then the metal is moved the bin. Otherwise, the metal is moved to the bin. Then the organic waste is used as natural fertilizers and the recyclable materials are moved to factories to recycle natural fertilizers and the recyclable materials. The non-recyclable materials can be converted to energy by using incineration process. inductive proximity sensor:IR sensor is used to detect the presence of material. Inductive proximity sensor:An inductive proximity sensor is a device that uses the principle of electromagnetic induction to detect the metals. Hall effect:If the metal is detected then the hall effect is applied to the metal. Hall effect is the production of a potential difference across an electrical conductor when a magnetic field is applied in a direction perpendicular to that of the flow of current. The voltage value is compared with the values of all the metals and based on this, the nature of the metal is known. With respect this, the metal is moved to either recyclable or non-recyclable. Non-metal detector:If the material is not a metal, then the metal is moved to the non-metal detector. the material is detected if the metal is a non-metal, then the metal is moved to the recyclable bin. If the metal is not detected by any sensor, that means the metal is organic waste. So the metal is moved to organic waste bin. Flow Chart:"
First the coconut are cut into pieces. Then the coconut are made to flow into the spring conveyors through hopper. Within this the heating is done with the help of microwave. After that the heated pieces are made to flow in slit conveyors and again the heated pieces are allowed to pass through the spring conveyor where its temperature can be increased or decreased by using motor set up controlled by the timers. This process gets repeated until the heated pieces are completely dried.
"Implementation Basic Flowchart The system will be installed at the point of discharge of the respective industrial site. The main process will remain constant but processing boards, control panels, sensors, filters and other technical requirements will differ according to the scale, need of the different industries and type of pollutant found in type of pollutant waste water. The description of The main process is as follows: The main process comprises of four stages. ● Initial stage● Analysis ● Filtration● Final stage.Initial stage: In ● Initial stage● Analysis ● Filtration● Final stage its waste water will be send to The system via secondary components. In ● Initial stage● Analysis ● Filtration● Final stage first priority will be to remove any solid or macro matter from the affluent or waste water so as to make sure that there is no damage to components in The system due large solid particles. Also for some industries it would be necessary to manage the temperature of the discharge affluent water that would be covered in the initial stage itself.Analysis: the discharge affluent water that would be covered in the initial stage itself will be passed through the various sensors to identify the level and type of pollutants, ph level, COD, BOD etc. This data will be processed by processors to select the appropriate set of filters.Filtration: The need for ● Initial stage● Analysis ● Filtration● Final stage is to make its waste water reusable.The processes that filter the contaminants may be based around following techniques:● Microfiltration is normally an initial step in filtration process. In this step affluent is passed through a special pore sized membrane to separate microorganisms and other suspended particles. It is normally used in combination with other filtration techniques to supply other filtration techniques a steady stream free from unwanted contaminants ● Ultra-filtration (UF) is done via variety of membrane filtration in which forces like pressure or concentration gradients lead to a separation through a semi permeable membrane. Suspended solids and solutes of high molecular weight are retained, while water and low molecular weight solutes pass through the membrane in the permeate (filtrate). This separation process is used in industry and research for purifying and concentrating macromolecular (103 - 106 Da) solutions, especially protein solutions.● Nano filtration (NF) is a relatively new membrane filtration technique which is suitable for liquids which have low total dissolved solids such as ground water. Nano filtration (NF) can be used to decrease hardness of the water and remove organic matter.● Reverse osmosis (RO) is a water purification process that uses a partially permeable membrane to remove ions, unwanted molecules and larger particles from drinking water. In reverse osmosis, an applied pressure is used to overcome osmotic pressure, a colligative property that is driven by chemical potential differences of the solvent, a thermodynamic parameter. Reverse osmosis can remove many types of dissolved and suspended chemical from water, and is used in industrial processes. The result of RO is that the solute is maintained on the pressurized side of the membrane and the pure solvent is allowed to pass to the other side. Final Stage: the water will again be addressed to the sensors for assessing the final level of pollutants and this data will be monitored to check the efficiency of the system as a whole. The waste obtained after complete process will be disposed with maximum precautions"
"By Inserting the valid coin into the coin module, the customer will be able to select the suitable option 1)Coconut water 2) Coconut meat 3) Both. Accordingly the Relay 1 will be triggered and hence the coconut from the stalk will move towards the process of drilling and scraping by using the conveyor belt. The next step includes the drilling of Coconut , Relay-2 will be triggered by seconds delay this will turn on the drilling of Coconut by creating proper hole by which the water from the Coconut will be taken out into the available serving bowl. During this process the Coconut will held perfectly by the gripper (arms) After drilling the Coconut further moves for opening the Coconut completely by the use of marble cutting, here Relay-3 will be triggered by some second delay the gripper (arms) holds the coconut which will be sharply cut by cutting mechanism. On cutting the Coconut this process includes scraping by which cutting the Coconut is evacuated and collected in serving plate which will be further served to the customer. If the customer need only coconut water then the mechanism of scraping of Coconut meat is skipped. Also if the customer needs only the Coconut meat the mechanism of scraping of Coconut meat is skipped vice-versa. BLOCK DIAGRAM FLOW CHART"
"The tasks required to be perform by the bot are as follows :1. Detection of the Pothole.2. Calculating the Dimensions of the Pothole using Image Processing.3. Squaring the edges of the pothole.4. Calculating the amount of material required to fill the pothole.5. Successfully patching the pothole.the bot will be programmed to perform the detection of potholes during free hours(when there is less traffic). The detection of the pothole will be done by using a LiDar sensor. The detection of the pothole will also analyse the depth of pothole and send the depth of pothole to the R-pi. Once the pothole is detected the next task is to find the dimension of the potholes. Now the camera placed at 90 degrees and perpendicular to the pothole comes into action and will capture the of the pothole. This Image will be fed to the Rpi and processing will be done for calculating the length, width and area of the pothole. Python Opencv will be used for this purpose.The calculation of dimensions of the pothole in the will be done by applying filters and morphological transformations such as applying median filter, converting into binary, morphological erosion and dilation .After which the dimensions will be calculated with the help of component labeling and chain coding techniques. A threshold will be applied to the area, as per which smaller road deformities captured along with the pothole will be neglected and only the dimensions of pothole will be obtained [4].After getting the dimensions, the dimensions will be given as input to the Computerized Numerical Control (CNC) machine. the Computerized Numerical Control (CNC) machine will then perform the trimming of the edges of the pothole and convert the trimming of the edges of the pothole into squared edges which is required for implementation of the semi-permanent method. The R-pi CNC board will be used to control cnc controller with r-pi. Camera and the CNC mechanism will be two separate assemblies mounted such the Camera and the CNC mechanism will be movable at the either sides of the bot. The movement of this assemblies will be controlled by a stepper motor. Now the third assembly which consists of the mixture that will be used for filling the pothole will be aligned at the top of the pothole and the stored mixture will be poured into the pothole, as per the depth and area of the pothole. Then the stored mixture will be compacted using a vibratory roller, till the stored mixture levels the surface of the road. With this the complete patching process will be completed."
"Regulating and maintaining the health of the water bodies by the following processes-1.Identifying the places with floating garbage and removing them2.Identifying the places with oil spills and removing them.3. Monitoring the temperature of the water bodyAt the beginning, the bot will be directed to the place where the oil or garbage is found. Then depending upon the instructions given by the controller, the place where the oil or garbage is found will be cleaned under constant monitoring. the bot will be controlled by the operator and will implement the instructions given to the bot. Once the tanker is found to be full, the tanker comes back to the operator for discharging at a safer place."
"A typical unmanned aircraft is made of light composite materials to reduce weight and increase maneuverability. This composite material strength allows military drones to cruise at extremely high altitudes .Drones are equipped with different state of the art technology such as infrared cameras, GPS and laser (consumer, commercial and military UAV). Drones are controlled by remote ground control systems (GSC) and also referred to as a ground cockpit. The engineering materials used to build the project are highly complex composites designed to absorb vibration, which decrease the sound produced. The engineering materials are very light weight. the project has three parts, the drone , four legged system and the control system. The four legged system comprises of 3D printed parts. The material used in 3D printing is PLA(Poly Lactic Acid). Each leg has two links providing Each leg a two degrees of freedom. Servo motors are used to achieve movement of the links. Arduino mega is used to control Servo motors .By controlling the links movement individually the robot can be moved. Four legs are attached to a common base. In a common base four wings are attached . In each wing a brushless DC motor and a propeller is attached Quadcopters make use of 4 Motors. Two of these motor spin clockwise while the other two spin counter clockwise. Motors on the same axis spin in the same direction. A quadcopter can either hover or adjust A quadcopter altitude by applying equal thrust to all four rotors. To adjust its yaw, or make its turn left or right, A quadcopter applies more thrust to one set of motors. Pitch and roll on the other hand are adjusted by apply more thrust on one rotor and less to the other opposing rotor. The device that controls the Brushless DC motors is called an Electronic Speed Controller or ESC. By using controller the desired position can be obtained. By using high definition cameras and sensors the required data can be obtained which can be processed for certain applications.Flow chart :"
"The block diagram for the proposed system is as follows:We assume that there are five parking slots in a parking area. Each slot is equipped with a HC-SR04 ultrasonic sensor whose range is 4 feet. Ultrasonic sensor has four pins: Vcc,Ground,Echo and Trigger. If high pulse is sent on the trigger pin for more than 10us, the ultrasonic wave of 8 cycle sonic burst is sent by Ultrasonic sensor. Depending on the distance of an obstacle and the time taken by the waves to hit an obstacle and come back to echo pin,the echo pin is high. As soon as a car enters the parking slot, a car will be an obstacle for ultrasonic sensor and a car will send the occupied status(Pulse high on echo pin) of the slot to the Raspberry-pi. Henceforth, there will be five sensors in a parking area sending the occupancy status of the slot to the Raspberry-pi simultaneously via wired connections to the Raspberry-pi through GPIO ports. This is the data acquisition part of the proposed system.Once the data is received, the next step is parallel processing of data to avoid any delay in real time implementation. the Raspberry-pi has a utility called MAKE FILE. a utility called MAKE FILE follows a task dependency chart or sometimes helps in parallel processing/execution of tasks simultaneously. Since the Raspberry-pi has quad-core processors, the Raspberry-pi can implement maximum four tasks simultaneously without time lag hence, the speed is fast. the Raspberry-pi will be then connected to the internet by enabling the WiFi module.the Raspberry-pi will push the data to a local server with the help of MQTT (MQ Telemetry Transport) protocol,lamp server,MySQL utility etc. On the reception of data, server side scripting should be done to find out online vacancy, car park location. This part can be implemented using Node.js, Express.js etc. Mobile application can then be linked to the local server.Mobile application can be built using react.js,ionic etc.Depending on the data received by the local host, Mobile application will show up the nearby locations of parking with spaces available in the corresponding parking area. A separate option will be visible for user to find the closest car park from the list of nearby car parking locations made available to him."
"● The basic structural designFirstly we will create a basic design of the window using horizontal slots that can be opened and closed to make an angle to maximize solar exposure and generate maximum energy. They can be opened during the day time which will allow the window to be open and the panels to generate energy.● The electrical moduleSolar panels:- In this system, there will be customized solar panels that will be connected in series and parallel combinations. Generated solar power will be stored in inverter and batteries which can be further used for household appliances.● The mobile applicationCreating an application that can help with the basic controls and also give information estimations on the electricity generated.● The IoT moduleDesign a system that will completely work on solar power. This module will contain a wifi module, motor driver circuit, and motors which will control the movement of the windows. This module will receive the data from the app over firebase, which will control the movement of the window.Flow Chart Additional FeatureDepending upon the size of the window, a customizable solar window can be made which keeps the series-parallel combination of cells in proportion."
"Implementation:Once we start the F.A.R.M. the F.A.R.M. will first collect all the F.A.R.M. data get an update about in which phase the F.A.R.M. is working and at what phase the F.A.R.M. has ended and also from which co-ordinate the F.A.R.M. has to start i.e. sowing ,watering, weeding etc. the F.A.R.M. will start the F.A.R.M. path planning and also go to the F.A.R.M. saved co-ordinates from where the F.A.R.M. has to resume the F.A.R.M. work. It will take a dry run and take s using open-CV and also take corresponding decision if decision says seeding then decision performs seeding and decision will perform this task till it is competed ,same goes for watering and harvesting and all of this is done using scheduling . The task of watering starts after completion of sowing /seeding and performs the particular task at scheduled time till /seeding is completed ,followed by the weeding process. This is done after weed detection. This also performs an analysis after every task about which task to be performed which is in synchronous to the scheduling. This also performs scheduled taking for analysis of crops regarding This health take some pictures and store the data along with particular time and date. Once crop is ready and well ripe it will be harvested using scheduling till it is completed.FLOWCHART:"
"Our project aims at predicting floods in various susceptible coastal areas. The risk of coastal flooding is increasing as a result of deforestation, untimely and torrential rains, sea level rise etc. In the event of floods occurring, a large amount of damage can be curbed if we have a model that could predict floods in advance. To avoid devastating consequences which have a major impact on economic and financial conditions of the city, our system aims to provide maximum accuracy in alerting target regions about the forthcoming disasters. This model can be extended for different locations in the future.One of the major factors causing floods is heavy rainfall, along with catchment and weather conditions before rainfall, tidal influences, inadequate drainage system, lack of reservoirs and catchment areas, deforestation, etc. With this model of predicting floods because of deforestation based on ML will provide clear and efficient output of forecasting the flood in the coastal regions. this model of predicting floods because of deforestation based on ML will take s from satellite, classify s based on the factors required and process the input dataset.our will use statistical data based on various factors, maps and s. The datasets can either be real-time data collected from Synthetic Aperture Radar(SAR) or historical data recorded before."
"The first part of the proposed model is gesture detection which uses accelerometer and gyroscope to recognize gestures made by end users, which are then passed on to the processor. Here, the gesture are identified based on the patterns recorded by the sensors and then translated into various functions such as a fan or light ON/OFF. The next part is IR. IR can be used to transmit codes to the electronic device for further processing. Once the output reaches the target device, IR is decoded to perform the required function. The entire working principle is demonstrated in Figure 1. The entire working principle also offers a way to control existing appliances without wavelet support built-in. There is a signal cloning feature that lets you emulate any other IR remote out there. Simply point the existing remote at our device, press the button you wish to emulate, and then perform a gesture. The band's IR receiver records this foreign signal and The band associated gesture. The band will then send out that exact signal, the next time you perform its associated gesture."
"1 PROBLEM DESCRIPTION :-The basic thing is to solve the road problems which occurs due to natural conditions or due to man made damage on the roads. And now a days the problem is to be resolved by the heavy machinery and a large group of workers. To correct the problem there is a requirement to block the roads and divert the path of vehicles and that gives inconvenience to the people.As well as if we use the heavy machinery for small patches then there is the misuse of the fuels and man power that gives reduction in the resources. And the process used is hot patching means a lot of work and material required to fill the small holes.2 Parts Of the Machine:-This machine is basically divider into 3 main partsØ CleaningØ FillingØ Ramming 3 Working Procedure:-3.1 CleaningØ Fistly using the air pressure the pothole will be cleaned. Ø Then using the water pressure also the pothole will be cleaned so that no pebbels will remain in the pothole after cleaning 3.2 FillingØ Then using the sensors we will meaure the deapth of the potholeØ Then after that, the system will calculate the volume required by the pothole and the system will dispatch the certain materialØ Then a leveler will level it3.3 RammingØ Finally using a combination of a ram and rollers we will level and compress it.3.4 Market Of the productMainly there are three buyersØ Government road manufacturing and maintenance departmentØ Private road making companiesØ Societies, colleges and etc."
"Our sensor is mounted on your body for 2 weeks and Our sensor monitors how your body responds to each and every food you eat. The data from Our sensor will be extracted through NFC which is present in android phones and uses high frequency wireless communication to transfer data between devices over a short range (usually about 10 cm or so). This technology makes your life easier as well as more convenient by making This technology very simple to extract data . Our Machine Learning algorithm will find key trends and prepare a simple and detailed report on effect of each and every food. Since different food items produce different effects on different individuals and doctors need time to see the effects the device will give individual results and hence a personalized diet will be planned in no time. Since, diet is the primary factor of diseases like obesity, malnutrition and some mentally challenged people don’t know when to stop eating or what not to eat some mentally challenged people are the prime focus of our project.Electroencephalogram (EEG): It is a test which is used to find problems related to electrical activity of the brain. We will track and record brain wave patterns. We releases electric waves with different frequencies. The type of frequencies depends on the several activities that We performs. For example, We brainwaves change according to what We’re doing and feeling. When slower brainwaves are dominant we can feel tired, slow, sluggish, or dreamy. The higher frequencies are dominant when we feel wired, or hyper-alert. Small metal discs with thin wires (electrodes) will be placed on different parts of brain frontal, occipital, parietal and temporal lobe. The signals will be sent to an android phone and NFC will be used to record the results. the results will then be analyzed through machine learning to determine brain related activities ,the results are compared to the standard range of a normal human brain waves and a pattern will be made to determine the behavior of the individual."
"Fig.1 MethodologyWe need a mobile application for control and operation of Defence Bot. The processing unit comprises of a mobile application linked to Internet. Processing unit is core of Wireless Control. The processing of data results in assigning a desired command to specific device. The technique of operation is based on Internet of Things which uses Cloud based Server to transfer data. The range of operation can be increased by using long-range radio frequency module. the Microcontroller present at the receiver side receives the data from the Internet Server and generate PWM Signals. The signals upon decoding will be able to drive other hardware present in the system. Motor driver ICs, geared motors and sensor shield etc. are some of the circuit elements contained in hardware unit.Fig.2. the ARM requires a power supply of 5V required to activate the ARM. We need a software for control and operation of the ARM. Input is given through software which is processed and given to Microcontroller (Raspberry) where the output is given to servo shield(arm). Fig.4. Bot Movement Block DiagramMovement of the Bot is described figure. Input is given by an app which defines the movement manually obtained from the User. the data is further processed by an app which defines the movement manually obtained from the User and then given to the Microcontroller. the Microcontroller is connected to the Motor Driver Shield which is responsible for regulating and controlling the motors as defined by the User controls. When the Bot is set into Forward otion, both the motors are switched into forward motion. For Left direction, only Right motor is activated. Similarly, for Right direction, only Left motor is activated."
"This project deals with the continuous monitoring of the patient’s data. This project also records the patient’s data and compares This project with the threshold or critical value to ensure if This project is emergency situation. If the real time value of the patient’s data doesn’t match with critical value then the real time value of the data doesn’t match with critical value acknowledges the care taker and concerned doctor about the emergency situation and sends the location of the patient. In This project we are using IOT (Internet of Things) to establish the communication between user and the caretaker. The objective of This project is to implement wearable and portable system for health monitoring which is also efficient for accuracy. The parameters that we include here are ECG, Heartbeat or pulse rate and body temperature in This project. An ECG(Electrocardiogram) is used for measuring the electrical activity of heart to know the behaviour of heart is normal or not. In human body there is specific range of normal body temperature the range is set with higher and lower value if body temperature of patient crosses certain level it will be sensed by temperature sensor by temperature sensor and sent to the cloud server for the purpose of measuring these parameters, we are using different modules and sensors. To store the data obtained we are using cloud-based server since cloud-based server provides security and facilities to access the data available anytime which is very useful for doctors to analyse the data at the time of treatment. If the emergency situation arises the emergency situation will inform the caretaker/doctor about situation and state of the patient. This system also generates alert notification for time of any critical condition. We are using fall detection to know the place of incident. It is seen that finding the location of incident is complex hence we are using the GPS tracking to get accurate location."
"Wind turbine and Solar Panel are connected to a Charge regulator circuit andthe charge controller circuit is connected to a battery. Charge regulator circuitwill show if solar panel and wind turbine is working properly or not. We canattach different types of LEDs on ESP32 and collect the data. Using ESP32 thedata collected can be sent to the server, and can check the working status ofsolar panel as well as wind turbine, also we can check whether the LED isglowing or not. we will also mount temperature sensor, in case of any highheat (temperature) it reduce the damage to LED. we will also mount a voltageregulator sensor, so that voltage supplied doesn’t exceed the required amount ofvoltage."
"This project deals with detection of seismic activities which occur due to the movement of tectonic plates. Our system detect the seismic activities if Our system occurs violatenly causes earthquake. System will on alarm at the instance it detects earthquake. it sends an alert to the Disaster Management teams So that the Disaster Management teams can take quick action for the rescue work. it also alerts the residents tell the residents about safety path how to rescue the residents causing less damage. it connects the major Hospitals by alerting the major Hospitals through SMS/Mail. So it is helpful to the hospital staff to manage the injured people. Our system will not only attempt to save human lives, but will also store the data for later use by professionals working at this sector.This device focused on the support of the residents for the safety."
"· An airtight closed chamber for storing the grain, which will prevent the grain, which will prevent it from exposure to climatic condition from exposure to climatic condition.· Adherence to FIFO(FIRST IN FIRST OUT) will be a major feature· Providing pre-storage facilities as following:1. CLEANING THE GRAIN-Air blow technique will be used to remove the remaining impurities.2. WASHING THE GRAIN:-Washing the grain with water splash and reusing the water for future use.3. DRYING THE GRAINS-High and low temp drying using solar heated air."
"Drone Design PlanFig 1Drone DesignHex-copter drone will provide great stability even when one of the motors fail and withstand high winds.Components including GPS, MicroSD, and Controller will be mounted at center of the drone.Sensors will be kept away from the vortex of the drone by extended arms. Battery will be mounted the other side of extended arm for weight balance.Block DiagramFig 2 Block Diagram Fig.2 shows the basic block diagram of the project. STM32F103C8T6 will be the brain of the project. Block DiagramFig 2 Block Diagram Fig.2 will get the data from the sensors, process Block DiagramFig 2 Block Diagram Fig.2, convert Block DiagramFig 2 Block Diagram Fig.2 to engineering scale and transmit Block DiagramFig 2 Block Diagram Fig.2 to IOT data server. Block DiagramFig 2 Block Diagram Fig.2 will also store the data from the sensors in the SD card which can be used if real time monitoring is not required. the data from the sensors will be plotted on a SCADA screen. There will be options to plot the graph between different parameters like altitude v/s PM 2.5 dust particles, location v/s temperature, and so on."
The proposed solution is a model which involves three levels:1) Data gathering2) Controlling3) Analysis4) Monitoring Data gathering: The water flow meters would be installed on several locations of building. Monitoring Data gathering: The water flow meters would be installed on several locations of building will align with pipelines. Monitoring Data gathering: The water flow meters would be installed on several locations of building would collect flow rate of water consistently and will send Monitoring Data to the control system (BeagleBone). The installation of such taps has to be done strategically so that The installation of such taps must be cost effective. Controlling:The data gathered from water flow sensors will be processed by the control hub which is the beaglebone black. The control hub would send Monitoring Data to the AWS server. Machine learning algorithm to be used would be Support vector machine based on the type and size of data.This trained model would be deployed on beaglebone black..The leakage could be detected and predicted based on Monitoring Data. The user would be notified on a web dashboard.
"The following are three sections of our project are- 1. Detection: Biological impurities in water consist of living organisms. These include algae, protozoa, pathogens, bacteria, viruses, microbes, and parasites along with parasites cysts (eggs) in contaminated water.[5] Colloidal impurities in water include organic waste products and amino acids. This occurs when suspended matter and elements like sand, rocks and organic matter flowing in rivers, streams, and lakes get in contact with water which render water undrinkable or non-pure.[5]It is important to detect Colloidal impurities in water before non-pure.[5]It consumption. Sensors would be used to detect impurities like residual chlorine, total organic carbon, turbidity, pH sensor, etc. After that exact quantities of constituents of impurities will be determined by ML algorithms. This would be a major part of our project.2. Supply: While supplying water there is a possibility that water can get wasted due to leakage. Impurities can also get added to clean water. Hence it is important to monitor the flow of clean water by checking whether any impurity is getting added or not and also to check whether water is getting wasted or not. This will be done by a leakage breakdown sensor. Water quality will be continuously monitored by a leakage breakdown sensor. 3. Monitoring: The following are ways in which water is getting wasted in houses:-[6] 1) Using your toilet as a trash can: Every time you flush a facial tissue or feminine product, you waste five to seven gallons of water. Also flushing something other than human waste and toilet paper is bad for pipes and drains.2) Taking baths and long showers. The average shower uses 17.2 gallons of water that can last up to 8 minutes–that’s a lot of water.3) Conventional showerheads you should consider switching to a low-flow showerhead, which uses about 2 gallons of water per minute. This means the average 8-minute shower would approximately use 10 gallons of water.4) Leaky pipes. An average household can leak more than 10 thousand gallons of water per year. 5)Washing dishes with running water. 6) Conventional Toilets. If you have an older toilet, an older toilet could be using up to 2 gallons more water than a newer low flush or high-efficiency toilet.7) Overwatering your lawn.8) Running running water while brushing your teeth. These are some ways in which water is getting wasted at houses. In our project, our can use a water flow control sensor to monitor our project flow and limit our project accordingly."
"Now exactly how the idea is going to be implemented. the idea very simple the idea starts with the waste acceptation once the waste is accepted in the lid has a dotted mesh which is connected to a heater circuit now once the use throws the garbage in the dustbin in the form of polythene wrapped covers so basically this wrapped covers gets accumulated over the mesh and due to heat this cover gets shrieked. And now the waste inside this cover falls inside the dustbin. Here three sensors attracted to the inner side of the lid if dustbin, which is connected to the plank and connected in the linear format and the plank is connected to the servo motor this servo motors rotates as such the sensors covers the whole part of the dustbin to check the status of the waste collected inside. After this accordingly the wastes gets separated in to their respective containers and at the end user will get a paper bag to encourage the user to lover the use of plastic."
"Initial RegistrationWhen the user registers for the first time via the app, a secret key, unique to the user is saved on the device locally and also entered into the database on the back end. the device can fetch this key from the database.UnlockingWhenever the user clicks “UNLOCK” button on the mobile application the secret key for that user is hashed with current timestamp as the hashing key. This hashed data is appended with the UserID and then encrypted before transmitting to the device as a Chirp (Near Sound Data Transfer technology). This data/string is decrypted by the Raspberry Pi and the UserID is obtained. The secret key corresponding to this UID is fetched from the database and is hashed with the current timestamp. These two hashed values are compared and if equal, the user is valid and the door unlocks or the door stays locked, a buzzer sounds and the homeowner gets an alert on his phone. Additional functionality can be notifying the nearest police station.DatabaseThe database is constructed such that a single user can have multiple homes and each home has multiple occupants. The secret key for each user and house relation is unique."
"Raspberry plays a key role in this project used to plugs into a computer monitor or TV. The navigation system is used to gives an effective parking area. Here IoT is simply used to make all the electronic components as a network, by using this we can collect and exchange the data. The ultrasonic sensor is used to give the exact distance between the citizen and the parking area. The ultrasonic sensor used to measure infrared light radiating from objects. The pi camera is and 15mp camera to capture the objects used to measure the traffic density."
"The robot can perform different operations like cutting, digging, seeding, leveling, and spraying fertilizers. By using this we can save a lot of time.The different operations can perform by using The robot. We can save labor also. By giving the commands through 8051 Microcontroller it will work. it can perform various operations like digging the soil, seeding and leveling the soil, spraying the fertilizers or water. The directions of a robot can be changed by giving commands according to that the 8051 Microcontroller changes the 8051 Microcontroller direction as well as the 8051 Microcontroller operations. While moving The robot in paddies The robot continuously captures the pictures of plants' growth levels plants and put in the cloud.MONITORING: For every end of the month, the data can be analyzed with the help of bar charts and pie charts. the data is useful for future purpose. Globalization, agricultural policy reform, and trade liberalization all affect agriculture. The aim of agricultural policy was to increase productivity in agriculture .Technologies that manage nutrients more efficiently in food production how much amount of fertilizers that have to be needed to increase the crop yields. so that crop has to maintain the nutrients.Integration Points with Other Systems:Firstly the System will integrate with farmers mobiles and then the System will integrate with LED display for the monitoring purpose and the System will integrate with IOT module.GPS help the farmers to harvest the farmers fields i.e. we navigate The robot and we determine the position of the robot where The robot locates with the using of GSM. So that we track the movements of Robot the System integrates Motor divers. Different types of Sensors like ultrasonic sensor, moisture sensor placed on robots. the System will integrate with GPRS."
"Quality education is a universal goal. Quality education is common to hear arguments that instructional technology will be the key to educational quality as we enter the new millenium . Investment in educational technology is urged upon policy-makers as the path to educational quality . In fact, enthusiasts for educational technology argue that quality has and will continue to increase rapidly, creating a ""new educational culture"" . Whatever problems exist are seen as ones which can be handled through better administrative and technological planning - that is, technology believers perceive no intrinsic obstacles to total quality assurance using information technology in higher education.1. EDUCATIONEducational organizations use to describe EDUCATIONEducational organizations high –level goals for the future.2. DIRECT EFFECTSCOGNITIVE SKILLSIt is an important aspect of overall chain development.PROBLEM-SOLVING SKILLS3. Link errors to misconceptions.4. INDIRECT EFFECTS5. POVERTY REDUCTIONPoverty Increased access to education can contribute to reducing"
"The power consumption monitoring can be done by using IoT, Rasberry Pi3 and sensors like PIR sensor, IR sensor, LDR sensor. By using different types of sensors we can easily monitor the power that we are consuming without we interference. Here the sensors are connected to the electrical appliances to control the electrical appliances without the man interference.If the devices are leftover with ON state, even if the person is not there then the sensor senses the data and the Rasberry pi3 executes as the per the given program. By using this method most of the power can be reduced and the cost of the bill can also be reduced. This makes the devices most efficient in the devices working. If the devices are not working properly, then Rasberry pi 3 sends the message through the mobile of the master via GSM Module, then the master can make requirements to the electrical appliance.GSM module helps to send the messages to the master whenever required. By using Rasberry Pi3 we can make an effective connection with all the available electrical appliances.All the data that is collected by the Rasberry Pi3 is uploaded to the cloud by using IoT. IoT know as the Internet of Things is the platform that is used to post the data in the cloud and analyse it as per the given program.Here we are interfacing PIR and LDR sensor to the Raspberry Pi3. PIR sensor is used to sense the person or not. LDR also is known as the Light Dependent Resistor is used to detect the change in light by change in the value of the resistance. These detect All the data that is collected by the Rasberry Pi3 and send All the data that is collected by the Rasberry Pi3 to the Raspberry Pi3 and All the data that is collected by the Rasberry Pi3 posts All the data that is collected by the Rasberry Pi3 into the cloud with the help of IoT. This process is clearly explained by the below block diagram."
"Implementation: This project is used for monitoring the industrial environment and to increase This project operational efficiency. To get more efficiency in the industries, the industry working conditions should be good. By using This project we can monitor the temperature and humidity and also detect the combustible, flammable and toxic gases in indoor and outdoor respectively of the industry. Moreover, This project also monitors the employees who are working in industries whether industries are in good working condition or not. In This project, we are using ARM LPC 2148 Microcontroller to control all the interfaced devices. The temperature and humidity values are sensed by the temperature and humidity sensor-DHT11. The gas concentrations are sensed by MQ2 flammable and smoke sensors. To check the employees working condition alcohol sensor MQ135 is used. The temperature and humidity values are updated in the cloud periodically with GPRS. The Simcom 900 A used as a GPRS module, this module post the sensed data in the cloud server as Packets using the HTTP server. this module should be inserted with at least a 3G sim card.All the sensed values will be displayed in the cloud to all the employees in the industry. Based on All the sensed values the actions will be done using IoT. Like ON &ampOFF AC, ON &amp OFF FAN, ON &ampOFF and OFF."
"The implementation includes that how we implement the circuit to pure the water that comes from the supplier .The water may be clean or may not be clean , this can be observed by the result obtained in the output .Based on the output obtained we can give the water to purifiers or directly to the suppliers 1.sensor probeThis probe will connects the sensor and the microcontroller .There are many types of sensors like temperature ,ph ,oxygen level etcThese sensor converts the analog into digital information .The measure value is stable and reliable .This does not change with surrounding temperature. measure value can directly connect with the analog sensors2. THE SENSOR IN CONTAINERSThe three current output sensors are from Global Water, provided by the supervising lecturer. I use temperature, pH and dissolved oxygen level sensors in this project. Unfortunately, the dissolved oxygen level sensor is faulty.the dissolved oxygen level sensor is a turbidity sensor, which output a voltage level proportional to the amount of suspended solid particles in Global Water the above sensorTurbidity is just the cloudiness of water. just the cloudiness of water typically comes from particles that are suspended in the water that we can’t see individually. particles that are suspended in the water that we can’t see individually could be algae, dirt, minerals, proteins, oils, or even bacteria.Turbidity is defined as the reduction of transparency of a liquid caused by the presence of undissolved suspended matter. The Global Water Turbidity Meter combines the turbidity sensor (described above) with a handheld meter that has a six digit LED screen, 4-button control panel, and an internal 9V battery. The Global Water Turbidity Meter can be used for enivronmental or process sites that do not require permanent monitoring. The Global Water Turbidity Meter will display readings directly in either nephelometric turbidity units (NTU) or parts per million (PPM). The Global Water Turbidity Meter also includes an automatic shutoff feature to conserve battery power.3 .A7 MODULE CONTROL CIRCUITGSM (Global System for Mobile communication) is a digital mobile network that is widely used by mobile phone users in Europe and other parts of the world. GSM digitizes and compresses data, then sends GSM down a channel with two other streams of user data, each in GSM own time slot. GSM operates at either the 900 megahertz (MHz) or 1,800 MHz frequency band."
The above block diagram shows that the Sensor senses various variables and the collected data is send to the ARM processor. Then the ARM processor process the data and corresponding output is given. For example the temperature sensor senses room temperature and the values are given to the ARM processor. Then processor process thst data and stores the data in cloud. According to the room temperature AC will ON/OFF automatically. By the same way remaining home appliances will operate automatically by user requirement that is controlled by mobile app which is connected to cloud.
The basic working of the project is based on the conveyor mechanism which is responsible for collecting the waste and debris from the water bodies. The belt is being driven with the help of the micro-controller which is connected to the motor driver. the motor driver is responsible for the working of the motor &amp the signal is given to the motor driver with the help of the controller. In this we used boost XL_DRV8848 for the motor driving. The motors used in the project model are the D.C motors which are responsible not only for conveyor mechanism but also for the moving of the boat in the desired direction. the project model is controlled with the help of WIFI connectivity &amp the whole functioning is done with the help of the app connectivity using wifi module.The power supply to the boat is given with the help of Li-ion battery &amp we will be using the solar panels in order to charge the batteries. Thin will be done using Boost XL-BATPAK-NK.the whole waste is collected using conveyor and will dumped into the container placed in the boat.
"In this project, we present the real time monitoring of water Pollution based on IoTusing Android App. The block diagram of the proposed method is shown in figure. In thisproposed method consist of several sensors like temperature, pH, turbidity, flow ConductivitySensor, Oxidation Reduction Potential Sensor and Dissolved Oxygen Sensor is connected toArduino microcontroller. The Arduino microcontroller is used to collect the sensor data andprocessing The Arduino microcontroller and upload the data through internet to cloud. The sensed data can be viewedusing Android APP."
Here we implementing this by three phases: Phase 1: this consists of selecting suitable components which are listed above.Especially hardware components.Phase 2: In this phase the different hardware components in a proper way for good working condition.Phase 3: In this phase we concentrate on the coding part to work automatically.Finally we deploy the code in to this.Below diagram shows the overview of this and Flowchart shows the flow of actions. FLOW CHART
"From the above figure drip irrigation system is done by various components like raspberry PI, soil moisture sensor,DHT11 (Humidity &amp Temperature sensor),water sprinkler and GSM module.First Soil moisture sensor senses data from soil that is moisture level of soil and DHT11 sensor senses the humidity and temperature at fields. This data is sends to the Raspberry Pi3 micro controller. Here controller process the collected data and controls water sprinkler and water pump motor as per requirement.This data is posted on cloud.The farmer checks the data in mobile app from anywhere.At the same way farmer can operate the drip irrigation from anywhere from farmer mobile.Here GSM module operated as a GPRS services that is Internet services."
"1. The ECG wave of the patient’s heart is to be observed using ECG sensor and we need to monitor that ECG signal.2. ECG signal is passed through the ECG Amplifier of gain 1000 to amplify the signal strength. 3. Then ECG signal is passed through a band pass filter and extracting only PQRST waveform. 4. Then ECG signal passed through the comparator to check the amplitude of the QRS wave.5. Based on the comparator output the electric shock has to be adjusted either manually or automatically and is to be given to the patient. 6. After this process, we will check the ECG signal, if the ECG signal is normal, the defibrillation is completed and if not, this process is to be carried till the ECG signal is not proper. Different units used1) Patient Interface: Connect ECG electrode to the patient’s body.2) ECG sensor &amp Amplifier: Amplify ECG signal make it computable3) QRS band pass filter: Extract the QRS wave from the signal4) Trigger Circuit: Comparing the R peak with threshold value and trigger the capacitor storage. 5) Energy Storage: Capacitor bank which can discharge when trigger signal is reached."
"1. The block diagram contains a medicine container, microcontroller unit, GSM module, IOT cloud unit and motors.2. First patient place the prescription in the form of RFID card in medicine container then the prescription in the form of RFID card in medicine container is scanned and the corresponding medicine is come out from the corresponding medicine container.3. The data which is scanned by the controller about prescription is placed on the cloud send by the GSM module.4. The patient got the remainder message from the cloud send whenever the patient medicine taking time is over.5. Finally by using this machine to get the corresponding medicine very fast."
"The above figure demonstrates the applications of smart health care, which start from fitness monitoring on one end of the spectrum to vital sign monitoring in hospital. Based on the applications of smart health care, which start from fitness monitoring on one end of the spectrum to vital sign monitoring in hospital, the quality of health care systems is improved with additional machine learning algorithms and artificial intelligence.Creating sensitive and responsive digital environments has made the smart healthcare domain a multi and interdisciplinary domain research area.Heart rate monitoring and remote ECG monitoring through wearables have offered cost effective solutions in smart healthcare.The fitness tracking through a smart watch along with parameters such as number of calories burned, steps taken, active hours etc..In smart watches, it is also necessary to keep a track of the previous monitoring analysis It is also important to track the ph sensitivity of sweat, oxygen intake of body, heart rate monitoring etc. Environmental management applications help in establishing communication between the hospital and the patient . monitoring the first responder’s health status in an endemic or epidemic out break getting ambulance assistance in case of emergency, developing evacuation schemes for disaster management in hospitals, maintaining active data base to ensure correct delivery of organs /blood to the users in need, accurate billing of surgical procedures ."
"Road layout:For the implementation of this design, the Abak road, Udobio and Udo Eduok Street axis in Uyo, Akwa Ibom State, Nigeria was considered. The road layout for this design is the “+” road intersection represented in Figure similar to the road layout used in [12-14]. The trouble spot was chosen and a model developed, because of The trouble spot constant traffic log-jamb. The trouble spot was observed that smaller streets like Udo Eduok and Udobio which often times had little traffic were allotted equal ‘GO’ time when compared to the Abak Road a major expresswayInfrared Sensors Arrangement and Implementation: Since the design is focused on sensing the traffic level on each of the lanes of the road depending on the density of each lane using infrared sensors, the arrangement of the infrared sensor on the road layout was positioned to perform this function.Raspberry pi: The Raspberry Pi board supports all the features required by the proposed system. The switch is connected to the GPIO pin. The speakers are powered by a USB power source and are plugged into the 3.5 mm audio jack. The webcam is connected to one of the two USB ports available on The Raspberry Pi board. In the prototype developedThe RFID Technology has created a central importance among the companies associated to clothing, automobiles, pharmaceuticals and so on. RFID technology basically uses electromagnetic fields, which is for the automatic identification of the objects having connected all the tags for tracking RFID technology. Several companies are contributing a lot into the technology and the technology is rapidly evolving as adopters know how to use and deploy the technology. Radio-frequency identification can solve real world business problems."
"1) Collection ,detection of thermal paper: The railway ticket will be collected from consumers. Then thermal paper will undergo testing to detect weather thermal paper is normal paper or thermal paper. 2) Separation and storing of paper: After detection the papers will be separated and stored in different compartments as there will be two compartments one for normal paper and other for thermal paper. In storage compartment it is detector mechanism to found out weather storage block is full or not. 3) Concession: After successful collection of paper ) Concession will provide concession to the user in E-wallet.4) E-ticket booking:User can book a ticket on their phone else machine also provides an E-ticket booking option . All this data is get stored on online server. All this data can be seen by authorized person like TC or railway officer . block diagram of TCETM"
"Braille is used by thousands of people throughout the world. Braille helps the blind to read the texts in a way which they can understand and form an opinion of the text on they own. But not all books are available in braille which restricts they to be able to read and explore more through books.Our Next Gen Vision Kit allows the user to be able to read any printed book. Our Next Gen Vision Kit scans the pages and converts the pages into speech. Since all books aren’t available as e-books. Like many of the popular apps like Camscanner, we will add a feature to auto crop the to capture only the area where the text is available. we are converting text from (or poster or book or any other form) in front of the user by using camera. It is very simple as user have to just pass the voice command via mic to capture the in front of him, then we program will use Tesseract-OCR API to recognize the text in the captured . Then the text in the captured will be converted into speech using Tesseract-OCR API with an add on feature to save the text in the captured into text files which can be easily accessed later as per the requirements.The visually impaired people have difficulty in recognising faces and objects. The Next Gen Vision Kit allows the user to be able to recognize faces and objects. The Next Gen Vision Kit helps the user to locate objects and also allows the user to figure out the number of people present in a room or the area where The Next Gen Vision Kit is. The Next Gen Vision Kit is able to recognize multiple faces in front of the user. This is done by first loading face of the person in different angles and orientation to prepare a model using Haar-Cascades present in Open-CV library in python and then at the time of recognition, the model that we made earlier is used to recognize the faces distinctly. the model that we made earlier is trained with the help of a video capture which captures 100 frames and extracts the distinguishing features from the model that we made earlier so that the model that we made earlier could be used later to recognize faces. We can train individual models of different faces which can be used to recognize the corresponding face and hence the person so that We user can easily recognise the person in front of him.A blind person often suffers from the long-distance problems like obstacles and traffic signals as short distance problems can be detected by white cane also. So, there is a very strong need of object detection in this modern world. For the working of Object Detection, we first capture the frame via the camera and then process the camera with we pre-defined models present in YOLO library to detect the position of objects in front of him. YOLO uses a single CNN network for both classification and localising the object using bounding boxes and gives the coordinates along with the score. The approach used by YOLO is in such a clever way that The approach used by YOLO looks at the only once and divides our into a grid of 13 by 13 cells. Then in each of the cell, it would be responsible for predicting 5 bounding boxes and describes the rectangle that encloses an object. The processing step will be done in our server in which we will upload we live video’s frame to our server where the actual recognition will take place. From our server in which we will upload our live video, our will get the recognised object in form of response which will be used to guide our user."
"Step 1 : Designing the ContainerThe container we intend to make would be foldable and portable, with wheels and a handle. Keeping the ContainerThe container we intend to make foldable would make the ContainerThe container we intend to make easy to clean and transport as well. the ContainerThe container we intend to make would have dedicated slot for placing the temperature control unit as well. Moreover, the ContainerThe container we intend to make would be insulated to prevent any heat loss.Step 2 : Designing the Circuit for Temperature and Humidity Control UnitArduino would act as a Microcontroller with the temperature and humidity sensors connected to the same. The thermostat would be responsible for setting and changing temperature as per the requirement, and switching the Cooling Circuit for cooling on and off as required, with the data taken from the Temperature and Humidity sensor. The temperature can be set through the LCD Screen connected to The thermostat. Temperature would be maintained using Thermoelectric Peltier Modules that would be powered by a 12V battery. a 12V battery can be recharged using Solar Panel through a Solar Charge Controller as well. The required temperature and humidity could be set through the LCD Screen which would in turn be controlled by the thermostatStep 3 : Programming the Temperature and Humidity Controlled UnitMicrocontroller needs a set of Instructions, according to which it would function. The programming for the same would be done through Arduino IDE. Algorithm used would be to turn the Cooling Circuit on and off as per the external conditions and the temperature set by the userStep 4: Setting up Solar Panel and Solar Panel Charge ControllerThe Solar Panel could be connected with the battery placed inside the container.It would be movable, with no fixed placing on the container, so that It can change It direction as per the sunlight. It would come with a charge controller to ensure proper control over charging the battery of the container Step 5: Final Product and TestingThe main aim finally is to provide Mobile Temperature Controlled System that can be installed easily on any vehicle during transportation as well ensure that the container is able to maintain temperature customised to every variety of Fruit or Vegetable to Transport. For this, the final testing of the product would be necessary, and checking if the expectations match and modifying the expectations if necessary, would be even more important to deliver a final product that satisfies the main goal."
"The wet and dry waste is placed in separate dust bins in apartmens. Whenever separate dust will full,that is sensed by the ultrasonic sensor which is placed top of the bin. That sensed signal will send to micro controller.Then the controller processing the data nd activates the GSM Module to send the location of the bin to the municipality workers through SMS.At the same time dust bin Full status will placed on the Cloud,so that the Municipality higher authorities frequently monitor.If the bin is empty that data will also updated in cloud."
"The approach consists of using Cloud technology, IoT/Arduino devices with appropriate sensors, completed with interfacing using APIs and respective protocols along with a Machine learning Model to develop a fully-functional integrated system that periodically collects data for a location and predicts the probability of wildfire based on this data. The system sends an alert for the same if the probability of wildfire exceeds a threshold. The methodology for the same is as follows:Primary, using historical data, gathered from satellite, training of the model is carried out. We train We model for prediction tasks to predict the probability of forest fires based on parameters such as Humidity, Temperature, Soil Moisture, Pressure, Altitude, Latitude, and Longitude. Real-time data will be acquired with the help of various sensors like DHT22 Temperature &amp Humidity sensor, BMP280 Pressure &amp Altitude sensor, YL-69 Soil Moisture Sensor, Arduino with LAN module or Raspberry Pi 3, Optional GPS sensor, ESP8266 WiFi Microchip. A circuit is formed using the sensors used.The real-time data collected by A circuit will be sent to cloud storage that will provide the storage for the data from different sensors in collaboration and enable remote access to the data from different sensors in collaboration. of respective parameters. While the existence of all the factors is not necessary, a combination of some of all the factors will determine the likelihood of the fires.The real-time data accessed with the help of the cloud will be provided to the model trained which will perform the prediction. The result will be from one of the four categories which are low, medium, high, very high according to some threshold values that determine the intensity of Fire.From the real-time data, the likelihood of fire for the existence of certain combinations of factors will be determined.An alert would be given for prediction results provided by the or device.Block DiagramMachine Learning Model - Deep Neural NetworkOur implementation approach involves using a Deep Neural Network (DNN) that takes in two kinds of data as input - climate factors and a historic trend of wildfires. Since there are multiple inputs to be dealt with, we will use a Functional approach to build we DNN. The output of our DNN will be the probability of wildfire based on the real-time climate factors and historic dataset. and the structure of the model has already been built. Moreover, we only need to one-hot encode we data and split our data into the training and testing set. Sensor Network- IoT Sensors:A network of sensors measuring parameters like temperature, humidity, soil moisture, altitude, pressure, and location, will be installed to record the changes in the environment. This real-time data will be sent to the cloud for enabling collaborative storage and remote access of data. This real-time data then will be used by the model to make predictions. The circuit diagrams and the connection of IoT Sensors can be visualized with the help of the following diagrams.DHT11Temperature and humidity sensor): BMP280Pressure and Altitude sensor):YL-69Soil Moisture Sensor)GPS Sensor:ESP8266 Module):"
"Implementation: In proposed system a DC/DC boost converter while the battery bank uses a bidirectional DC/DC converter to control the charging and discharging processes. A centralized inverter is installed to interconnect the DC and AC networks. The proposed scheme and algorithm implemented for control of power flow between the one direction to another direction. The proposed CAPMS is a centralized power management system is implemented in proposed system. The islanding mode detection scheme is implemented for detect the fault and isolate the fault in proposed system.ADVANTAGESØ High power managementØ Reduced voltage lossØ Power lossØ High voltage stability BLOCK DIAGRAMSOLAR MPPT For extracting maximum power from the solar a MPPT has been used. Here Incremental Conductance method is been used instead of Perturb &amp Observe method. In the incremental conductance method, the controller measures incremental changes in PV array current and voltage to predict the effect of a voltage change. the incremental conductance method requires more computation in the controller, but the incremental conductance method is able to track the condition changes more fastly than Perturb &amp and observe method (P&ampO). FLOW CHART Following are the flow chart for two different conditions i.e. Grid connected mode and islanded mode."
"The proposed design tends to implement the smart street light management system which tends to controls, monitor and detect the faults in the street light in the cities and highways. The purpose of this system is to provide a better system for the street light to the locality and the general public.Figure 1: Block Diagram of the SystemIn this system, we are using Solar Panel for generating electricity in order to reduces the consumption of electrical energy which is produced by the non-renewable source of energy.A current sensor which detects the value of live current and voltage which helps to detect the fault in the street lightA light-dependent resistor i.e. LDR sensor which helps in switching off street light LDR has a variable resistance that changes with the light intensity that falls upon LDR.And the Wi-Fi module which is used for transmitting the data to the serverEvery Wi-Fi is connected to the hub and these hubs are connected to the main server. A HUB is a basic common connection point for devices in a network.From A HUB, the main server collects the data and then checks the values and if there is any fault in any street light then the fault is detected automatically. If there is a fault, the main server stores the information of the street light and send the information of the street light to the government portal and the contractor portal for resolving the problem.Every day on a specific time schedule, the main server sends request each unit for the measured value of Voltage and current, if the current of a particular street light gets high or low beyond the current of a particular street light fixed reading then the system catches the fault of the street light.Figure 2: Flowchart of the SystemWhen the main server receives information of street light in which fault has occurred which will be identified by the main server unique number. Than the main server will stores the detail of faulty street light in the main server and sends the details of the street light with location to the contractor and the Government which is responsible for this.If the contractor and the government which is responsible for this did not solve this problem in the given period, then the information of the street light is transferred to the higher authorities of the Government for knowing the performance of the contractor and the government which is responsible for this. This process is repeated for every street light."
"Initially, the farmer will drive the robot with the help of a remote control till, the starting point of the very first row of crops(furrow). Depending on the average height of the farmer will adjust the height of the robotic platform with remote control, and will initiate the operation of the bot with a command, this will put the robot in autonomous mode. An onboard camera placed under the platform will be switched on. An onboard camera placed under the platform will be parallel to the ground and will take multiple s of the vegetation underneath as the bot traverses forward. multiple s of the vegetation will be processed by an onboard processor, which will perform the operation of the identification of weeds and crops using a Convolutional Neural Network by labelling the weeds and crops accordingly. The coordinates of the weed will be estimated by the processor and enabling signal will be sent to a delta arm equipped with a gripper, a gripper will try to pluck the weed out of the ground. If a gripper is found that the complete removal of the weed along with a gripper roots is not possible then a gripper will spray the herbicide directly on the weed. This operation will be continued for the whole row of crops.Once the feed of the camera stops receiving the s of crops, the bot will come to know that the bot has reached the end of the whole row of crops and the bot will turn around by 180 degrees and continue the bot operation in the next row. A physical marker has to be placed at the end of the very last row so that the bot will stop the bot operation and notify the farmer by sending a message on the farmer/the farmer registered mobile number.Convolutional Neural Network:Convolutional Neural Network is a special case of deep neural networks used specifically for s. Convolutional Neural Network will be implemented on a processor. Here Intel NUC i5 will be used as a processor. Images taken from the camera will be pre-processed and then Convolutional Neural Network will be given as an input to CNN. CNN CNN will be already trained on a dataset containing s of weed and crop. The output of CNN will be labelled s as weed and crops.Delta arm:Delta robot/arm is a type of parallel robot used in industry for high-speed operations [11]. Its concept is based on a parallelogram which restricts the motion of base/end effector to only translational i.e. only in x, y and z-direction. Delta robot/arm used here consists of three linkages that are connected to base/end effector. The gripper mechanism is attached to the base/end effector for weed removal, also a sprayer is attached to a sprayer for spraying herbicide. the base/end effector for weed removal will go to the estimated coordinates and pluck the weed using gripper and if the weed is facing any difficulty in removing weed, a sprayer will spray a precise amount of herbicide directly on weed.End of Operation:A GSM module is used for communication between microcontroller and GSM network, A GSM module allows wireless communication with other devices such as a mobile phone. When the bot reaches the end of the last row and stops the bot operation, the onboard microprocessor will send a command to A GSM module through microcontroller. A predefined message will be sent to the farmer’s mobile number in English as well as in their native languages so that their come to know the weed removal operation is over. Then controls will be switched from autonomous to manual mode again and the farmer’s will drive the bot from that location to the shed."
"This smart device is portable which can be used anywhere at any time, which helps in providing quality education to students using processing technology. This smart device basic concept is that initially the input stay is captured by a camera interface. a camera interface is raspberry pi camera board. a camera interface captures the and sends the information to digital processing system. This consists of programs and codes in python and then checks the enhancement algorithms. At the end the VGA cable is connected to the raspberry pi which sends the processed on a monitor or projector screen as an output"
"When the suspicious hot spots are detected by thermal equipment (front-end equipment), the analysis module sends immediate feedback to end user and makes alarm. The thermal s are automatically sent to forest fire department with all the imaging sources associated. When the suspicious hot spots are observed by the thermal camera, the analysis module calculates the temperature, rate of spread/hours &amp intensity. The data is recorded, stored and sends the statistical data to end user (fire forest department).The module is designed in such a way to make analysis of fires by using continuous processing and timely detection of suspicious objects in the monitoring area and can be used to view real time s. The Thermal camera and long range normal vision camera are placed together so as to both detect the fire and monitor the forest."
"For the implementation of our idea “PlastiSell”, our believed that it should not only be secure enough, as capital is involved, but also, our made sure that the overall process is completely easy and accessible to anyone who wants to contribute. It is very well observed that people don’t tend to do something for the better good due to the following reasons.1. Ignorance for doing something better for the environment.2. Not enough information/knowledge.3. Inadequate resources. our took into account all of this and implemented this idea accordingly. There are 2 sections to this, (a) The Automatic Machine &amp (b) User’s Smartphone.Automatic MachineThe machine will look a tad bit similar to an ATM machine, but will serve the purpose of segregating and sorting the contents as per our requirement. Automatic MachineThe machine will use on- screen instructions and helpful guides to provide the user with information regarding which type of plastic to be inserted in the chute, or how to insert it, etc. This process may take some time from the user end as they have to read/ listen and follow.After this, Automatic MachineThe machine will generate a total cost that has to be paid to the user based on the amount and type of plastic plastic deposited. This will be calculated on a per day/ per month basis in regards to the total available plastic for recycling and several other minute factors.To pay this amount to the user, the app comes into play.The Application The app which we plan to develop will have a login id and password system to track individual user. The account of the user will have to synced with The account of the user bank account for money transfer and security. Once the user signs in, The account of the user can select when to be reminded about his/ her contribution towards a healthy environment based on The account of the user time and schedule. All of this will be set up well in advanced and now as the user completes the aforementioned steps on Automatic MachineThe machine, The account of the user will take out The account of the user phone and open the app.Synergy between the Two Now the app and Automatic MachineThe machine will have to send and receive data regarding the payment amount. To achieve adequate security in the area, we used a QR scanning system. the user will scan a QR code from the app in this hand and an OTP will be generated which will be sent to the user’s phone. This method will ensure a sort of two- factor authentication to the entire process and will keep This method simple for the user at the same time. Now all that has to be done by the user is conform the payment on all that has to be done by the user smartphone and within a minute, the money should be transferred. The use of a QR scanning system is based in such a way that the user collects/ stores the plastic that the user collects/ generate over a period of time instead of throwing The use of this system. Then within regular intervals, all that has to be done by the user uses this facility to completely use the waste that they are generating and earn some extra money on the side along with helping the cause of saving our planet from the plastic that usually ends in dumping yards, or worse, the oceans. Basic Block Structure of the System"
"The implementation of the proposed system can be divided into 3 modules:Primary Detection Module : This module is responsible for the detection of objects. This module determines which objects are friendly and those which are not by getting the parameters to the Arduino UNO through various sensors, such as proximity and distance measuring sensors. various sensors, such as proximity and distance measuring sensors detect if there is an obstacle in various sensors, such as proximity and distance measuring sensors given range. On detection of an obstacle, an electronic signature differentiates if the detected obstacle is an enemy tank or our own tank. If it turns out to be an enemy tank, This module sends the coordinates of the tank to the rover (kept at the base) with the help of This module.Fig.: Interfacing of first stage modules with the Arduino UNO microcontrollerRover Movement Module : This module is responsible for the movement of the rover to the nearby location of the enemy tank with the help of the coordinates received through the radar using the communication module,movement of the rover to the location with the help of the motor driving bridge and the obstacle detection module which helps the rover to pass through an optimal route with any obstacles in the rover way. Fig.: Interfacing of second stage modules with Arduino UNO microcontrollerAiming and firing This module: Once the rover reaches near the coordinates, the Arduino sends a signal to the Raspberry Pi 3B+ indicating that the rover is in near proximity of the enemy tank. This module is responsible for the elimination of the tank which it assures by getting the parameters in the Raspberry Pi 3B+ model by using various sensors and sub-modules such as a camera which performs a secondary level detection of friend or foe through processing and object detection algorithms,velocity measurement module telling the Raspberry Pi about the speed by which the enemy tank is approaching, The aiming and firing modules which start acting once the trend of the motion is known to the rover and thus the rover can attack the enemy tank and keeping an element of surprise for the enemies.Fig.: Interfacing of third stage modules with the Raspberry Pi 3B+ microcontrollerFlow Chart :Fig.:Workflow"
"The implementation is divided into three major functionalities:उत्पादन की पूर्व सूचना : Helping the farmer for crop yield prediction.फसल वर्ग : Expert will grade the crop based on the details entered by farmer.मंडी व्यापार : the farmer for crop will sell the farmer for crop crop to the highest bidder to ensure maximum profit. Steps to be followed: To help the farmer for crop yield prediction :Considering all the factors like Temperature, NPK ,Humidity , the best five crops will be listed to be grown on the farm. This prediction will be done using KMeans and RANSAC algorithm.Grading This is the first phase of Marketing. Expert will grade the crop based on the details entered by farmer. farmer most of the times is cheated upon the grade of the crop they are selling as they are gullible. farmer can check the grade of the crop that farmer is growing and accordingly rate farmer yield. After entering the details of the crops farmer product is graded and now farmer has two options either to exit the app or go ahead with the bidding of the crops. Bidding of yield:This is the second phase of marketing. Here, farmer has to enter the minimum crop rate farmer wants. After this, the bidding starts and several marketers can bid the crop based on the grade of crop. Now, farmer sells the yield to the highest bidder in order to ensure maximum profit. User Interface :The UI will comprise of 4 portals viz. Crop Prediction, Grading, Bidding, Querying.Data flow Diagram:DFD Level 0 For Prediction:DFD Level 0 For Grading:DFD level 1:Use Case Diagram:"
"The proposed system is mainly focuses on two major problem of waste management. 1. Classification of waste into bio-degradable and non-bio-degradable. 2. Smart and Automatic movement of bot. Current State of Waste Management: In waste management, Segregation of recyclable waste not done properly at source. Initial waste collection not done at place of waste generation. Design and location of municipal waste storage depots inappropriate, resulting in littering of garbage. Street sweeping is not done every day. Waste processing partially practiced in 35 ulbs only. The final disposal is done through crude dumping. Waste pickers collect recyclables from municipal bins. Solution by Providing Smart and Automatic System: If we need to meet the goal of a “Clean India” by 2019 then waste management issues should be dealt with India urgently. Most recyclable waste ends up in a dump yard due lacking of efficient waste management. The proposed system would provide an intelligent solution to make this tedious job of waste management facile. With the help of Infra-red sensors and Ultrasonic sensors The proposed system is able to detect object and obstacle. If the object is detected then the object will move towards that garbage using shortest path finding algorithm. Once the object reach towards garbage then by taking real time s of that garbage processing will done at background. Classification of garbage will be done using Convolution Neural Network (CNN). Segregation mechanism will play a key role in The proposed system to pick that garbage and placed that garbage into respective dustbins.Design Details-System Flow-Fig gives us the overview of The proposed system, here the inputs are taken from cameras, Ultrasonic-sensors, Infrared sensor and the inputs are sending to the raspberry pie for the processing. On the basis of input i.e. whether the basis of input object, obstacle, garbage, the commands are given to wheels for movement taking bot closer to that garbage. On the basis of path finding algorithm the bot will move towards nearest garbage. The input from the camera will be given to raspberry-pie for classification into two classes i.e. bio-degradable and non-bio-degradable - using CNN model with the help of datasets. According to the output of the classification the commands will be sent to robotic-arm from Raspberry-pie, robotic-arm would segregate that garbage into two separate bins.Use case diagram- Figure gives the description of the overall system’s modules and their functionalities together. The whole system will be monitored automatically. The input from the camera will be from sensors for object, obstacle and garbage detection. After identifying the possibility of the garbage bot will move accordingly i.e. towards garbage or object. After reaching to the desired position the desired position will identify the garbage i.e. the desired position bio-degradable or non-bio-degradable by the help of datasets. If the garbage is identified the garbage bot will collect and segregate the garbage into two separate bins."
"1 .Working of Algorithm:Figure 1:Working of Scheduling AlgorithmThe system is using Priority based Longest Queue First Scheduling Algorithm for making the timer dynamic .Figure 1 shows the overall working of the algorithm. In the algorithm first the count of each lane at the current junction will be computed. The count of incoming traffic will be given to the system of a current junction. the algorithm will compute the average count of the junction using formula given in Figure 1.Once the average count is computed, the green time for each lane will be calculated considering three factors :-Density of vehicles at each laneTotal vehicle count at the current junction.One cycle Time.Thus green time will be allocated according to the density of each lane. Lane with highest density will get highest green time.Note: - In the figure 1 the count of vehicle is assumed for the explanation of the algorithm. the count of vehicle can vary in real time system.2 .Class Diagram:Figure 2 depicts various classes such as Haar Cascade, Signal Time Calculator, Signal, Analyzer and Emergency Vehicle Application.The Haar Cascade class consists of two modules Feature Extraction and Feature Mapping which are key features for processing. It will be able to detect, count and track the vehicle from the real time video. Signal Time Calculator is based on scheduling algorithm which is able to calculate the green time for each lane. The Emergency Vehicle module also consists of two modules Windows and Maps. In Windows class driver sets source and destination location and send to server of Regional Traffic Control Room. With the help of Google maps system is able to track the location of vehicle and will turn signal green prior to the arrival of vehicle at the junction.Figure 2 : Class Diagram3 .Methodology/System Flow Diagram:Figure 3 is the system flow diagram of the proposed system. the proposed system mainly focuses on three major problems:-Static Timers of existing Traffic Signal.Clearance of Traffic prior to the arrival of emergency vehicle.No communication between the junctions.the proposed system will be using deep learning concepts to adapt and recognize density of traffic at each lane and further manage the proposed system. Haar Cascade Algorithm will be used for processing. For making timer dynamic and giving priority to the lane with the highest density of traffic, this task will be done using “Priority Based Longest Queue First Scheduling Algorithm”. Traffic clearance for emergency services will be implemented using android application. Emergency vehicle will send Emergency vehicle source and destination location to Traffic Control Room through application server. Thus will help clearing traffic in advance. There will be communication between the junctions which will share information of incoming traffic to and from the junction.Figure 3 : System Flow Diagram"
"The complete system is divided into three parts: Device (Flow Meter), Communication, website portal for User Interface.Water Meter: Water Meters are fitted at each household and the starting of society. The Water Meter contains three parts: Water Flow sensor, ESP8266, and a Battery. A water flow sensor that will measure water flowed through the pipe in which it is fitted. Measured data about water will be sent to the ESP8266. ESP8266 is powered by a battery and the ESP8266. ESP8266 will send data in a specific format to the web server by calling API of a web server. ESP8266 sends data to the webserver at a regular interval of 12 Hours. Water Meters are fitted at household and society level for checking of water consumption and water leakage.Communication: There are several ways to communicate between esp8266 and website i.e MQTT, API Calling, etc. We are calling API of Web Server that is programmed to make an entry in Database with Unique Meter ID, Amount of water Flowed, and DateTime of entry made.User Interface: Web Application in terms of User Interface: is specific for two users. One for Local Government and One for end Consumers of water i.e House Holders. Local Government uses a website to monitor how much water is used by Particular House Holder. Combining results of Household and Society Meters website will show accurate Details of water flow and leakage at Household, Society, and Area Level. Local Government uses the website for setting rate of water per liter, area wise water usage limit. Residents use a web portal to monitor Residents water uses. website will show Residents uses in the current month, water uses still now, Residents limit, Residents charge of the current month and rate per liter. website shows red alerts to Local Government and Householders if Local Government and Householders have used water above Local Government and Householders limit. website generates reports for local government regarding the area, household and society wise water usage and growth rate of water usage."
"Data about land, temperature, moisture &amp requirement of minerals/vitamins for a particular crop is measured using sensor module.Measured data of the soil is then sent to the cloud through node mcu or GSM module. And is stored in the server for the further calculation. This will help us to find which type of crop should be grown on particular soil.By this system, we can get the proper selection of the crops, depending on weather, soil &amp the other conditions.For that we will be using the different sensors with microcontroller."
"The product have mainly two functionality: 1. two functionality: 1 is short term and we can earn money faster . in these if industry is facing any problem then these will give problem statement of industry and some materials will provide(if required). If any of the user is having solution for that these will give solution for particular problem statement. User who is giving best and cheapest solution for problem will get the money.2. It’s a long term process but you will get the job as per the agreement. two functionality: 1 is some how time consuming. In these ,user have to pass some exam and give solution of the given assignments. After passing these process you are eligible for interview. If you are passing in interview you will get the job.Function 1:Industry have Function 1:Industry own login id. Through this id, we will allow industry to put some problem statements to the users. Problem statement will be shown in the “golden opportunity “section. If user is having the solution for the particular problem statement then he have to submit user is having the solution for the particular problem statement if the idea is cheap , reliable and suitable for industry then user is having the solution for the particular problem statement will give money for the idea. Function 2:In our product there are two separate user section . one for student and another one for industry. In student register area ,student have to fill the full name, contact no , email id ,password security, last education status, any other certificates( i.e. sports(at least national), heckathon, etc.), student area interest. In industry register area, industry have to provide some information like: name of industry since, current working of project , government authorized industry certificate, another collaborative industry,industrial websites.The main use of this function is that the industrial requirements is matched with student area of interest. If it is matched then , student will get the task,. The task / assignment is given by well knowledgeable / experienced tutor. In the given time period ,users have to complete users assignments. their assignments will be checked by well experienced and knowledgeable tutor. If the assignment / task is not according to their assignments requirement, their assignments will not selected for upcoming round.Assignment /task which is given by tutor is according to their assignments requirement and selected for upcoming round, we will provide information to users to how to behave in interview, Does and Don’t’s of interview.As we assume that ,this much training is enough to pass the interview process so that our user can get job easily and educational unemployment will be solved ."
"Start system. First of all "Start system will check trolley is at bottom position or not by input of limt switches at bottom. If it is okay then start water pump and spray on solar panel then trolley moves on upside and all panels will be sprayed with water. Check upper limit switch is detected then cleaning wheel /roller is started while trolley stop to move upwards. After some times trolley starts to move down while running the Cleaning wheel water sprayer is still on. When it detece the bottom limit switch motion stops, water sprayer stops"
"Once the simulation tool is started, various parameters (e.g.total energy consumed, total cost, time elapsed and operational status of the appliances) are calculated and updated in realtime. The functioning of the tool is depicted in the form of a flowchart shown in fig 17. Once the simulation tool is launched, the simulation tool verifies if a cost rate program is already selected by the user. If the simulation tool is not, the simulation tool alerts the user through a pop-up window and facilitates selection of a program. During the cost rate program selection, the various renewable sources of energy are also selected.The next step for the user is to select and configure all the household appliances. Upon finalizing such selection:• the simulation tool evaluates the set of appliances that have to be operational at a given time of the day based on a set of defined rules and the cost rate at that particular time• the simulation tool calculates the total energy consumption of all the appliances operational at time• the simulation tool retrieves real-time solar insolation (radiation) data and wind speed data from the data base.• Based on the various modeling techniques, the simulation tool evaluates the total renewable energy available from various resources.• The optimization algorithm determines the distribution of available resources.•All the above parameters are evaluated every 10 seconds and the GUI is updated. The process continues until the user terminates the tool operation"
"We use the Arduino which will be working as an interface for user and the 3D-printer We make. The code to control the Arduino will be requested from Marlin frimware software. Using Marlin frimware software We can command the Arduino directly. Then the user uses Marlin frimware software to draw the object. The plastic waste(bottles, cans, polythene covers etc,.) is to be converted into the object using 3D printer. Pronterface software used to the object design created from Slic3r and then this is directly connected to arduino. arduino sends the user about the conformation message to start printing using the device or not. If the user input is to print then arduino tells 3D printer to print the conformation message as per the blueprint provides. If the user input is to retrieve then the process is stopped and the blueprint is terminated. The control board is placed on arduino and we use A4988 Stepstick driver motor. we use 4 Stepstick driver motors and 4 stepper motors. Stepstick driver motor is used to control stepper motors. The input for Stepstick driver motor is given by control board which receives Stepstick driver motor input from the arduino itself. The control board directs how 3D printer should move. A hot end is used to melt the waste plastic and the melted plastic is used for shaping the product. Here two frames which are perpendicular to each other. At the center of hot end is placed. Here two frames which are perpendicular to each other are controlled by stepper motors in all direction to give the 3d model."
"Fidget Cleaner consist of 2 arms. 2 arms consist of suction mechanism created using vacuum pump. On mounting this device on ceiling the Arm 1 and 2 vacuum will be turned ON. Vacuum 2 voltage will be reduced and steeper motor 1 starts Vacuum 2 voltage rotation. Arm 2 will start moving and cleaning the area around 180 degree. After rotating 180 degree the rotation is reversed and rotating 180 degree rotates negative 135 degree. Now Arm 2 vacuum will be turned ON and Vacuum 1 voltage will be reduced and stepper motor 2 will rotate 45 degree and Arm 2 will be parallel to arm 1 at this stage. This procedure is repeated till the ultrasonic sensor detects an obstacle. On detection of an obstacle, the cleaner will use the same algorithm to move sideways by 180 degrees. And the exact opposite procedure begins. This will help cleaning the celling upside down in 2 dimensional aspects."
"Our proposed system acquires inputs from various sensors which detect air quality showing percentage of gases present in the atmosphere. inputs from various sensors which detect air quality showing percentage of gases present in the atmosphere are given to controlling unit for processing. Then these sensed parameters are sent to users via cloud using Node-MCU. inputs from various sensors which detect air quality showing percentage of gases present in the atmosphere warns user if pollutant gases cross the specified limit. Preventive measures are suggested to the users present in that locality based upon the air quality index.Our proposed system will be developed using Arduino Uno and Node-MCU due to low cost and ease of implementation. Node-MCU consists of Wi-Fi module ESP8266 which will be used for sending sensed parameters to users using IoT. MQ-7 which measures Carbon Dioxide present in air, MQ-135 used to measure ammonia, G-37 for sensing oxygen present are interfaced with controller boards and inputs from various sensors which detect air quality showing percentage of gases present in the atmosphere is given to users. inputs from various sensors which detect air quality showing percentage of gases present in the atmosphere is also sent to pollution monitoring bodies like CPCB and MPCB for taking appropriate actions on industries and companies. Users will also be able to see the air quality index using mobile applications.Block Diagram:Flowchart:"
"A machine which is operated by the sewer cleaner, is taken and installed in the track which is develop in the drain. After fixing A machine which is operated by the sewer cleaner in the track which is develop in the drain, an aluminum bucket is ready to dip in the drain to take all the waste out. After doing this A machine which is operated by the sewer cleaner is ready to clean the drain. When an aluminum bucket is filled, an aluminum bucket moves 90 degree and an aluminum bucket came out from the drain. After coming out the sewer cleaner make an aluminum bucket an air tight container. And the bucket an air tight container is taken up, to produce methane gas from all the waste as by product. After producing methane gas, the residue is used as manure. And the plastic material often from all the waste is used to build roods."
"• A plywood of 60*60sq. cm and 1 inch thick been used for base as box needed to tolerate large weight. • Cardboard used for walls of the box because Cardboard are light weighted and Cardboard are fitted using fevicol, to support cardboard plywood strips been used.• Holes have been made on wall for exhaust fan, cardboard door from upper and front side been made to check plants condition. • Front door has transparent window to look inside the box. • From inside box is coated by aluminium foil as it is good reflecting material which will insures equal distribution of light. • A red and blue light been fitted inside to provide required spectrum. • A pvc pipe16 cm diameter 70 cm length used as growth chamber over it holes of 6.4cm diameter been made and over those holes a pvc pipe piece with one sided closed with net fitted to support plant. • Growth chamber fitted inside water/nutrient container which has fogger to supply nutrient. Inside chamber temperature sensor been fitted. • Over Growth chamber fitted inside water/nutrient container which has fogger to supply nutrient there is humidity and temperature sensor installed. Growth Chamber:• Coco Peat: • Coco peat used for seed germination and early stage plant support as coco peat absorb water very easily and can remain wet for longer duration as well as it is light weight."
"Implementation: The advent of nanotechnology enables to detect ammonia by depositing a thin film of nanofibers on glass substrate. cleaning process plays an important role for removing impurities from the substrate. The interdigitated electrode mask is deposited on the substrate to create electrical contacts which enables the substrate to convert as an output device. cleaning process is carried out by placing a substrate inside the thermal evaporator. Sol-gel preparation 0.4g of SnCl2.H2O and 5 ml ethanol is mixed (transparent solution), and to the solution 2-4 drops of acetic acid is added, which acts a catalyst thereby increasing the speed of reaction. The mixture is stirred with magnetic stirrer for about 2 hr at room temperature. Later poly-vinyl pyrrolidone is added to The mixture. PVP, to enhance the surface stabilization which is a non-conducting polymer again the solution is stirred for about 2-3 hr using magnetic stirrer at room temperature (RT). The gel prepared is now kept for aging for about 24-36 hr. Electrospinning -Process Setup consist of high voltage power supply, syringe, needle and a collector plate. A polymer composite solution prepared is drawn into the syringe. the syringe is placed on the holder, the needle is connected to the cathode and substrate is assembled on the anode collector plate. The distance between the collector plate and the syringe should be 12-15cm. The electrical contact points must be covered, and the remaining surface are deposited with nanofibers. A polymer composite solution prepared the syringe is injected on to the substrate under the influence of electric field and this process is carried out for 20 min. Annealing -The annealing is a process of providing a heat treatment to remove the internal stress and roughness of the sensor surface. Gas sensing parameters The tin chloride is kept inside the gas sensing unit. Screw adjustable two-point probes are connected to the contacting points of the interdigitated electrode to measure resistance. Data acquisition unit (DAQ) (Key sight 34792A LXI) is connected to analyte sensing probe station Further, small piece of aluminium foil is placed on the sensor and analytes such as ethanol, acetone, ammonia and two-propanol are injected in different concentration in ppm (like 2ppm, 5ppm, 10ppm, 100ppm) onto the sensor at room temperature. Change in resistance during exposure and recovery of the analytes are measured using two wire resistance mode of the DAQ. The sensor resistance is measured for different analytes."
"It all starts with extracting common cellulose from wood. Wood is made up of small cellulose fibers, bound together by a polymer called lignin. Lignin can be removed by chemical means, so that only cellulose is left normally, the result will look much like a wet towel. Apart from processing the many types of plant matter (from wood to marine flora), cellulose can be obtained from certain bacteria that secrete cellulose.After we have the cellulose, the next step is to break the cellulose down to nano fibers that are about a thousand times smaller than cellulose fibers. As result, we get hydrogen bonded chains of cellulose molecules some of such clusters of molecules are separated by non-crystalline regions. If we dissolve hydrogen bonded chains of cellulose molecules, we obtain the cellulose nano crystals we’ve been talking about usually, this is done with the help of strong acids."
"The UAV will scan the entire disrupted area using The UAV optical camera module and onboad thermal sensor will be used for human detection. The sensor data acts as a input for the system. The drone which also consist of global positioning system will geotag the location of detected humans on the map and the information will be send to the search and rescue team on Mobile Application through server.the system is broadly divided into 5 parts:Drone System.Human Detection.Obstacle Detection.Geotagging.Mobile Application.Drone System: Using The UAV/drone for searching affected people in disastrous situations is more efficient than manual searching. Drone can reach particular areas where people/rescuers can not. UAVs are faster than manual approach, UAVs can monitor the area from a different view in a precise way. UAVs are lower in cost and UAVs also come handy. UAVs are lighter in weight. Drones are controlled by a wireless remote controller, so there is no threat to the lives of rescuers. Constant monitoring using cameras and sensors increases the success of rescue approach.Human Detection: Sensors such as optical, thermal and infrared are fast, accurate and detects the humans efficiently. Human detection becomes more precise due to sensor data.This module consists of a thermal sensor for detecting humans by the infrared radiations that are emitted via the human body.Geotagging: The location of the victims, majorly affected and stuck in life threatening calamitous condition can be found easily using the onboard Global Positioning System (GPS) on Drone. The exact location of the detected humans can be tagged on the map sent to the rescuers.Obstacle Detection: Disrupted area consist of lots of obstacles for a UAV. a UAV can collide and collapse resulting a damage to the onboard Global Positioning System (GPS). Ultasonic sensors can be used to detect obstacle in the path of a UAV. a UAV a UAV will change a UAV directions accordingly.Mobile Application: Mobile Application is the user interface which will be majorly used by rescue team. The location of the detected human will be sent on Mobile Application and can be tagged on the map sent to the rescuers. The location of the detected human is also very useful for live stream the disrupted area for planning further search and rescue operations. Sequence Diagram:"
"Fig. 1: Basic block diagram showing control and working of a bionic armEach and every movement of the body is controlled by commands given by the brain. When the brain gives the command for a person to for example, fold a finger, the muscles present in a person elbow contract and relax indicating a finger to fold. For a physically challenged person who has lost a person hand, even in the absence of a person arm, the muscles near the elbow contract/relax thinking his hand is present even though it isn’t. When the muscles contract and relax, there is a small voltage produced due to this in the order of micro volts. These signals are picked up by the surface electrodes of the Electromyogram (EMG) sensor placed at specific parts of his arm. the surface electrodes of the Electromyogram (EMG) sensor placed at specific parts of the arm pass on the signals to an amplifier which amplifies These signals for further processing since the signals produced are not often detectable by normal instruments. the signals are then passed through an adaptive filter which removes noises produced by nerve stimuli and blood flow. the signals only passes the signals produced by muscular activities. The filtered signal is an analog signal and needs to be converted into a digital form for further signal processing. This is then passed on to the feature extraction where the signals only produced by muscle contraction and relaxation are extracted and small voltages produced due to the nervous system and blood flow is blocked. an analog signal is then classified by a classifier about which part of the hand was the action to be performed was given by the brain. This is where the part of the hand where the action is needed to be performed is determined.These signals are then passed to an Arduino Uno microcontroller board where an analog signal is analysed and the action of folding the finger is performed by rotating the servo motor present in the bionic arm. The brain after sensing the action has been performed by any of the sense organs like the eyes, gives the subsequent actions to be performed by the bionic arm."
"The proposed system will consist of a gesture-controlled glove/band connected to various controllable electrical devices such as lights or fans and even doors or windows. This will solve the issue of mobility to a great extent. The glove will also have a smart band component that keeps track of heart rate and pressure sensors to check if the user has fallen down. The current location of the user in the house will also be tracked using the gloves. This would be particularly useful to keep track of the person and personalize the behaviour of electrical devices.An AI agent will monitor the activity cycle generated by the user in the house daily and determine the next course of action. An AI agent will serve as a base for all other modules. The data will be stored on the cloud and an application to access and monitor the knowledge gained from The data will be developed. The main function of the application is to notify the caretaker and/or family members in case of emergencies, be it any injury or illness.The proposed system consists of the following modules:Gesture Controlled GloveThe glove consists of various sensors, which will be connected to the hub. The proposed system will then map the readings of the gesture performed and accordingly perform the task. The proposed system will contain other sensors to detect abnormal heart rate, falls etc too.AI Agent for ADL and Activity Recognition An AI agent monitors the activity cycle generated by the user daily by using fuzzy logic and then determining the next course of action. An AI agent also helps users with Alzheimer's by keeping a check on users with Alzheimer usual day to day activities and reporting anything out of the ordinary.Human activity recognition is concerned with identifying the specific movement or action of a person based on sensor data. We divide the input signal data into windows of signals, where a given window may have one to a few seconds of observation data. A given window of data may have multiple variables, such as the x, y, and z axes of an accelerometer sensor. One window would represent one sample. We extract informative features from each time window. For each time window, We extract a single feature vector f with acceleration vector of an axis X, Y, and Z, respectively as follows: The feature vector of the time window is used as the input to the classifier. Along with location coordinates, we can classify the activity as sitting, standing, sleeping etc.Mobile App and Cloud StorageThe data will be stored in a centralised database on the cloud, Firebase, which will provide data to the AI agent and application. Mobile App and Cloud StorageThe data will be in the form of raw sensor readings along with time stamps. Mobile App and Cloud StorageThe data will also contain logs of the electrical appliance activities, i.e. when and what was switched on/off.An application will be built in Android to access and monitor the knowledge gained from Mobile App and Cloud StorageThe data will be developed. An application will send regular updates and alert notifications to the caretaker and/or family members in case of emergencies, be An application any injury or illness.A.I.D.E HubThe AI agent is present in this centralised controller for the entire system. Any enhancement or modification to the raw data received from Cloud will be done at the hub. the hub will also have Temperature and Gas Sensors attached to the hub. All the controllable electrical devices will be connected via WiFi module to the hub."
"Different Parts Included In The Project And Different Parts Responsibilities : -1. Driver App :• To Send Geolocation Of Nearest Red Light In The Destination To The Web Server .• To Trigger The Transmitter To Send Signal To Specific Light2. Web Server :• To Store Data Of All Smart Traffic Lights Such AsLocation(Latitude ,Longitude) And Corresponding ID Of RF Reciever In The Light In The DataBase .• To Send Back The ID Of Reciever Of The Red Light Whose Geolocation Is Received By The ServerWorking :-Step 1 : The Diver Should Login To The Driver App And Choose the Destination .Step 2 : Whenever The Siren Of Emergency Vehicle Starts The Driver App Will Start Sending The Geolocation Of The Nearest Smart Traffic Light In The Destination To The Web Server The Web Server .Step 3 : The Web Server The Geolocation Of The Light From The Driver App And Search For The ID Of RF Receiver That Corresponds To That Given Geolocation And Send Back The ID Of RF Receiver To The Driver App .Step 4 :The Driver App Recieves The ID Of RF Reciever That Is To Be Triggered .And Transmits Signal To Reciever With Corresponding RF ID.Step 5 : The Reciever Than Responds And Turn The Corresponding Traffic Light Green ."
MULTILEVEL PARKING AREA This section consists of multifloor building with multiple parking spots at different floor with sensors installed at all parking spots. The top floor will be reserved for VIP user which have already registered and allow to park with RFID access.WEBSITEAccount: Complete profile and record of user will be maintained on the website. Parking spot availability: On website user can know about availability of parking spot and can plan accordingly. Reservation: Through website user can reserve a parking slot beforehand.v Confirmation E-mail: After successful reservation user will get confirmation mail with spot no. and password. ENTRY GATE There will be a proper brigade system at entry for security. There can be 3 types of users- NEW USER: - When a new user comes at entry gate he will Have to pay for parking and a temporary id will be created and a password will be generated which will be used to take the car out of the parkingRESERVED USER: - Same process will be followed for a reserved user only difference Is that he is already registered and will be having a password which will confirm he identity.VIP USER: - For a VIP user we will use RFID access.PAYMENT METHOD: For VIP there will be 6 months or annual subscription plans. For reservation there will be online payment method on website. For new user there will be on the spot payment method available.
"For implementation of our idea the first thing is to find a right place to fix the sensors so that the sensors can be safe and secure at the same time can work properly. our idea is to place sensors on the dividers of road so that they can sense the vehicles easily.the sensors will collect the data and send the data to our Arduino chip wherein the number of vehicles from all the 4 direction will be given to our algorithm and a time of green light signal for each side will be calculate and send to the traffic signal and when the current cycle is implementing the sensors will start working for the next cycle. For ambulance and emergency services we will set a sound sensor along with other sensors this will differentiate the sound of ambulance siren from rest of honking and at detection the current signal cycle will break and a green corridor will be provided. Other features are smart street light, since we already have sensors sensing vehicles we can use sensors sensing vehicles for making smart street light when the car is detected the street light will turn on and next lights where the car is moving will also turn on saving power. Also all the data collected about the traffic in a junction will be collected and uploaded on a app which will be for common people wherein common people will be able to check the traffic at each signal and plan common people route accordingly.ALGORITHM WITH EXPLAINATION:1) The data collected form the sensors will be n1,n2,n3 and n4.2) N1 and N3 can have green time together same with N2 and N4.3) A=n1+n3, B=n2+n4 4) Other variables…X=Rate at which vehicles move during green lightY=Rate at which new vehicles are added at A i.e. n1 and n3.Z=Rate at which new vehicles are added at B i.e. n2 and n3.K= A constant time which will be decided so as to provide efficiency.M= Time we will calculate.5) How to obtain values of variables:For A and B we can calculate with help of sensors.X is a constant rate which we will set to provide more efficiency.Rates of Y and Z will be calculated from the history and pervious data during different hours of the day.6) Considering A&gtB We will allocate a green time of K to A and red signal to B and during this green time We will proceed for further calculations…..We want time M such that after M seconds We will have equal traffic at both A and B.Equation for this can be given as:A – MX + MY = B + ZM M = ( A - B ) / ( X + Z – Y ) where A &gt B, X &gtY 7) Using the above equation we will calculate a time M such that traffic will get balance after M seconds. So We will provide a green signal to A of further M seconds making a total green time of ( M + K ) seconds. And then a orange signal for buffer followed by a red signal of ( M – K ) seconds wherein the other side i.e. B will have a green signal.8) After M seconds the traffic will be equal and after further K second the traffic at B will m=now be more than A making A &lt B so We this time We will allocate extra M seconds to B by calculating b with formula:M = ( B – A ) / ( X – Z + Y ) Where B &gt A, X &gt Z9) This process continues and tries to make balance of traffic density at all directions by giving more green time to high traffic road and low green time to less number of vehicles.10) To prevent starvation of low traffic road during the worse case scenario of A and B we will set a minimum and maximum time which can be allocated.11) Further each signal will be connected to each other and will provide information about vehicles approaching to other signal which help to get a better value of Y and Z.12) The cycle of signal breaks when an Ambulance is detected and information of ambulance approaching can be send to the next signals which will be a part of future scope of the project."
Food Quality Checking: Placement of xbee shield over arduino uno. Then soldering of headers into Xbee shields for connection with arduino board. Placement of Xbee shield over arduino. Remote node after placement of allthe sensors and Xbee radio with battery supply of 9volts.Remote node with 9volts battery supply get real time readings from sensors.Connect base node with laptop using USB. Test range of Xbee radio which works when at a distance of about 100meters
"Our project is based on augmented reality app. Our will design an app which uses AR technology. Location based AR app works without marker.Firstly we will identify and collect the targets. Target are real world objects that will be the various pictures of flood prone regions. Our will create user defined targets.Content will be 2D or 3D , 3D if AR headsets are used. Then start the vuforia forum and login.After create a database and add targets. After doing the required procedure, Our will develop the app using android studio.the app using android studio will be used by the rescue team. the rescue team will target the camera to the real world objects, getting the 2D or 3D view on the rescue team screens and finding paths and hence rescuing people."
"Implementation:Impure water from houses and industries will be collected through pipes to water reservoir chamber. From reservoir impure water will be sent for filteration process. After being water filtered filteration process will be transported to a boiler chamber to kill bacteria and microorganism for cleaning water. Then water will be sent for cooling chamber where water will be cooled by natural process such as earthen pot(a prototype).Now water will be sent to copper plate chamber and left there where TDS level of water will be maintain(which will good for health) with the help of copper plate chamber, as we know that in old days people used to drink water in copper utensils which was good for health. Sometimes people also pour water in copper made utensils in night and left people for morning which makes water mineral enrich which again good for our health.PURE WATER FROM COPPER CHAMER HELPS IN:1. Kills bacteria 2. Aids digestion 3. Anti-ageing and boosts skin health 4. Aids weight loss 5.Promotes heart health 6. Combats thyroid 7. Wounds heal faster 8. Brain stimulator. PLC AND SCADA: All these transportation process from one chamber to another will be done by this automation software. SOLAR PLANT: Used for power generation for boiler chamber. Now the impure water would be pure with mineral enrich and then send for distribution to homes and industries.All these implementations would be cost-efficient so everyone can afford it, as many middle class and every poor class people can’t afford cost-expensive purifier system such as RO. SEQUENCE DIAGRAM: FLOWCHART:"
"Our model will be first trained to detect abnormal behavior. This is done with the help of Machine Learning. Pre-recorded videos of abnormal activities will be provided to the model in the training phase.This can be made possible with the help of Support Vector Machine classifier also known as SVM classifier which will further help to classify abnormal behavior from normal ones.Next, Our will use the feature of Histogram of Gradient model for feature extraction from the data-set. Once the feature extraction process is complete Our will split training data and testing data.Every patrolling officer will be given a device that will help notify Every patrolling officer.Once the abnormal activity is recognized or detected Our model will notify the nearest patrolling officer. This will ensure the emergency services as soon as possible on the site."
Load cells are placed on wooden board on which plastic bottles were kept. Color sensors are placed on the rack to distinguish among the bottles. load cell is connected to arduino mega which receives the measured data to give present weight of bottles. The data of the sensors and load cell can be accessed through an app which has dashboard reflecting different bottles with the ingredients in The data of the sensors and load cell with its present quantity.
"Main Elements:The project contains the following elements like mechanical arms, proximity sensors, thick tyres, solar panel, sensors, batteries, joystick etc.Objective:The machine collects plastic which is toxic and ultimately contaminate the air water and soil. Thereby, helps in reducing the pollution.Use:The machine is controlled by remote which sense the plastic and hence collect The machine, keep The machine in the container which is attached to The machine. The project is a part of implication that can be used to improve the pollution level produced by plastic.All the technical aspects have been thoroughly designed keeping all the constraints in mind. The project is a model of the large-scale application which contribute in making smart city. The machine will cover the areas of town like railway station, bus stand, industries etc. collecting the plastic from the place by marking The machine clean. The machine is used for the collection of plastics from different areas and hence contributing in making the cities smart."
"PIR Sensor: Passive InfraRed sensor is a passive sensor which will not emit any signal but only receive the radiation signal from the object. In our project our used this PIR sensor form detecting the moving vehicle. Whenever Passive InfraRed sensor detects a moving vehicle Passive InfraRed sensor generates a signal which is given to Arduino 1.Arduino 1: An Arduino is a single board device consisting of microcontroller ATMEGA and An Arduino input output peripherals. The program is dumped into An Arduino using Ardunio IDE software. The program is stored and whenever input of 5V is given, The program starts running. In our project, when the signal is receiver from PIR sensor An Arduino processes the signal and gives an output signal to the HC-12(1) communication module.HC-12 (1) : It is a multi-channel wireless transceiver used as transmit and receive the serial information. The output signal given from Arduino 1 is communicated between two HC-12 modules. HC-12 (2) : The communicated signal received by HC-12 (2) is given the Arduino 2. Arduino 2: The process taking place in the Arduino 2 2 is different from the Arduino 2 . In Arduino 1, the sensor input signal is processed and output is given to HC-12 (1). But in Arduino 2 is vice versa i.e,the sensor input signal from HC-12 (2) is processed in Arduino 2 and output signal is given to traffic light.Traffic signal: When output signal from Arduino 2 is given to traffic signal, the light switches from low to high.---------------------------------------------------------------------------------------------------------------------Future Scope: We can also modify this project based on the requirement and use IMAGE PROCESSING through camera instead of PIR sensor. As we know, now a days RASPBERRY PI is most used and developing platform so instead of the Arduino 2 we can replace RASPBERRY PI. And we can send automated message, mail alerts to a phone when an accident happens. By doing this we can reach the spot of incident as quick as possible and rescue the people."
"Initially the total number of parking space lot a store in a variable value called parking lot number. The controller is a key component of the circuit the three ultrasonic sensors are connected to this controller and an output Display Board is also connected to The controller. The ultrasonic sensor one gets constant power supply from The controller and The controller gets from power supply board. The ultrasonic sensors two and three gets power supply after ultrasonic sensor one detect the vehicle. If the receiver in both the receiver of ultrasonic sensors two and three gets the signal then the signal is assumed as a big vehicle. Else the signal is considered to be a small and compact vehicle. Then according to the size of a big vehicle we have distributed the parking lot into two types for big vehicle and for compact one. The parking lot with the lowest value is given in an output Display Board. And the count is decremented. Eventually this process is repeated until the parking lot runs out of space. To indicate the vehicle owner about their parking lot number we have provided Display Board an output Display Board Display Board display the parking lot no. according to the count of value we have decremented. To avoid error cases, after parking lot number is displayed in Display Board for 10 to 20 seconds we reset the whole process in The controller for making The controller ready for new vehicle to detect and allot."
"The heat air that generates from the condenser reaches Thermoelectric Device through a pipe. The first end of a pipe is attached with a scroll compressor. Scroll compressor converts the low pressure air into high pressure air. a pipe is made up of copper and thermally coated from inside and this layer prevents the contact of heat air to the environment. Thermoelectric device collects heat energy from the condenser and applies Thermoelectric device on the heat sink i.e., connected with the hot side. There is a N-type or P-type region between these two plates • N type contains electrons as major charge carriers • P type contains holes as major charge carriers When heat air is applied on the heat sink the heat sink temperature increases and due to this the N- type or P-type region also gets heated (as the region is attached with the hot side).This sudden increase in temperature excites the electrons and holes which tends major charge carriers to move towards the cold side and due to this movement a current will generate. the cold side is connected to a bulb with a wire and when the current passes through the cold side a bulb with a wire starts glowing . The current produced is of very less amount (3-5v) which is not desirable that’s why a mini voltage stabilizer is assembled to increase the current output. The electricity produced by the thermoelectric device is used to charge the battery . A display screen is assembled on the top of the thermoelectric device. This display screen is used to tells us about : • Temperature of heat air produced by condenser. • Electricity produced by thermoelectric device. • Charging status of battery in % There is an automatic relay switch system which cuts off the current supply when the battery is charged or if there is a problem in the system and after that the walls around the condenser opens to pass the heat air."
"The approach proposed in this project is presented as a multilayer simulation model where each layer represents one of these components: (a) The urban environment, (b) the waste management infrastructure, and (c) the actuation layer.THE URBAN ENVIRONMENT• The urban environment is modelled according to publicly available demographic data and considering a trade-off between the proper representativeness and the complexity of the scenario,THE WASTE MANAGEMENT INFRASTRUCTURE• On top of the urban environment layer we have the waste management infrastructure , which employs Trash Bins (TBs). TBs are geolocated and arranged beside the roads. Each TB has an RFID tag containing a unique ID and the current amount of waste inside Each TB .THE ACTUATION LAYER• The actuation layer is composed of a swarm of robots in charge of carrying the waste from Each TB TB to the closest collection point. In order to increase the feasibility of our approach, our decided to model our robots using a real- world platform with specifications suited for the task."
"With sensors and CCTV when a user/person enters in a hall the data will be read and sent with the help of IOT and server. then, as per the data like the sitting, number of peoples, current time, weather of location if available through net and darkness of room the, right lightand right fan will be switched on. When the room is left and readings are zero the fan and lights are automatic switched off automatically.The system is taking data every 10 minutes to adjust the light and fan with minor luminance.All the adjustment will be recorded as the form of log and report will be sent to the server.We are using tensorflow and opencv with python3 for object detection and video tracking over the real time observation.For real time object detection and live tracking We will use threading an multiprocessing python libraries.Threads are removed for video processing as with thread it is not possible to use video processing for which frames are used.This auto-learning model will be trained by 100 cases in advance and continue learning the Right luminance and speed of fan for accuracy to provide the perfect environment in the room. Modular switching is also one of the advantage of autonomous switching"
"The flow diagram is shown which represents the work flow of the Implementation of the project flowThe implementation of the project idea starts with the LED light panels the restructured light panels which the is designed in two layered panel top and bottom layer, the top layer has low count of light modules compared to the top layer. There is a hollow space between the LED panel and the frame. the frame has the solar panel which is mounted on the frame and the inner surface contains reflecting panels or sheets or a polished surface which reflects the LED light back outside. The structure which is energy efficient and it spread the LED light more efficiently and widely. The glass covers the bottom side is which is the converging mirror type The glass allows the LED light to emit outside the frame and the making wider frame spreads more light and by the variation in heights that LED placed in the post makes the LED intensities varies. The camera sensor is not used for the environmental surveillance, The camera sensor is used to know the physical condition of the post and general surveillance (The car crash in post, sticking posters in the post, chain snatching etc,.. )"
"Loss in oxygen level is detected regularly if there is any problem it will be immediately sent to the website portal. If there is any serious case problem occur then the information will be passed to a certain government body who is undertaking care of the environment. All-time the information is available as the information is automated. According to the complaints, actions are going to take because oxygen is very important for our survival. This system is broadly divided into three parts- sensing process, analysing method and data verification. Sensing process: In some areas where large industries or buildings present that is selected and by placing our ECOGEN sensor our ECOGEN sensor will provide an accurate value of how much oxygen is lost from that particular area. our ECOGEN sensor helps in the sensing process and gives correct value our ECOGEN sensor transmits the value to the sensing process and by programming function, our ECOGEN sensor will appear in the display. By this method, oxygen loss is going to be reduced and if we consume more oxygen then we want to pay for this method.Analysing method: this method helps in analyse the oxygen loss in a particular place that takes place in the processor. Then the transmitter helps in transferring the information to the display so that we can take certain actions. All the terms involved in doing some algorithm and programming in software as a raspberry pi program in the system . Then the Wi-Fi module is used for transmitting the information collected from our ECOGEN sensor.Data verification: The last part of the system involved data verification to determine the precision and accuracy of the system. Reports generated by the system involved in two types: graphical and statically reports. Graphically visualizing the data that was present in theoretical form the data is represented in various forms like graphs and pie charts these will help us in determining the priority for calculating the oxygen level. User interface: There will be a separate web portal available for complaints and attending official staff. Complaint side web portal would provide facilities for complaints and checking the status. Attending the official staff web portal would be provided with the facilities like taking action, putting fine for that activity, help us in telling what to do in oxygen regeneration."
"· · The main aspiration of our project is to detect the early forest fire in the neighbourhood. The project which our proposed here enables the public to be aware of the early forest fire in the neighbourhood. Technical implementation· The mechanism which we have implemented in Technical implementation· is by using the cloud services which helps us to acquire the data, statistics, Big data analytics, file storage offering remote access to any work-related data. · The Zig-bee module is used to increase the transmission range, with the help of mesh structure we can monitor a wide range of area. · The Bluetooth and GSM module to used to send the text messages to the people when the early forest fire in the neighbourhood breakout nearby and to alert the public about it. it also enables the government to take prior precautions and measures. The alarm eye is a visual and infrared camera system to detect the early fire in the neighbourhood. · The LIDAR technique is used to measure the distance to a target and measure the reflected light with the use of sensor. These are the techniques which motivated us to implement our project so far.General implementationWhen the early forest fire in the neighbourhood breaks out in the forest, the temperature sensor, the gas and smoke sensor and humidity sensor help to detect the fires and alarm the people by sending messages using the Bluetooth, GSM modules which also has GPS and LIDAR which measures the distance and displays the location."
"To reduce the inconvenience caused by the traffic, the Traffic Light Controller (TLC) is used which minimizes the duration of waiting of vehicle and also manages traffic load. The approach combines the distance can be measured between the emergency vehicle and an intersection using visual sensing methods, vehicle counting , transmission within the sensor network. Along with visual sensing techniques, the appearance of emergency vehicle information can be collected, it is very important to have a Medium Access Control (MAC) protocol to deliver the emergency vehicle information to the Traffic Management Center (TMC) to decrease the duration of waiting. The traffic light control plays an important role and The traffic light control leads to the intelligent traffic management system and the intelligent traffic management system can reduce the traffic congestion. An increased no of vehicles not only increases the response times of emergency vehicles, but An increased no of vehicles also increases the probability for them to create the accidents and increases the time delay. The emergency vehicle entering in the traffic congestion at a high speed when the signal is red light poses danger to traffic on other roads and to other vehicles waiting in the road and can cause accidents. There should be smart traffic management systems based on priority and traffic density to improve the transportation efficiency and response times of emergency services and decrease the accidents."
"The proposed design intends to implement the dispensing machine to provide ease to users.The system has an automatic dispensing machine for dispensing medicines to patients. Figure 1 Block diagram● Prescription: Prescription contains the information of the patient and the doctor. Prescription also contains the content of the medicines which are prescribed to the patient. ● Doctor’s Interface System: the doctor can directly input the patient’s name and the other information into The system along with the details of the the medicines and the dosage. The system is connected to the local server through the Wi-Fi to update the data on to the local server. ● Wi-Fi: Since the system and machine are dealing with real time data so the Wi-Fi used for connecting the systems to the local server.● Server: the local server is the local host server which is used for the data traffic between the doctor’s interface system and the automatic medicine dispensing machine. the local server keeps the record of the information of the patient and updates the local server whenever needed. ● Automatic Medicine Dispenser: The automatic medicine dispenser(AMD) is a automatic machine which receives the patients information and the medicine prescription from the local server through the wifi in the real time and dispenses the slot of medicine with the name of the particular patient.● LCD: LCD will serve as output indicator displaying the name of the particular patient.Figure 2 Flow chartWhen patient enter the hospital an RFID card is allotted to patient, then the doctor upload the prescription on the system. Figure 2 Flow chartWhen patient needs to scan an RFID on the dispensing machine. an RFID will check whether the medicines are prescribed or not,if Yes, then the medicines will be dispensed.Otherwise, a pop message will be displayed on the LCD screen to notify the user that doctor has not prescribed the medicines. If there is a shortage of medicines than a pop message send to vendor to fill the dispensing machine."
"At the beginning we will approach the village after that my team is going to talk to villagers about the problems villagers are facing about electricity and power.Then we will establish we Power Generation systems. To do so we need to know about the total area of the village and number of houses of the village, so that we can provide maximum power efficiently.After all the research work my team will start installing the devices that are going to generate power. The power will be generated in many ways those are mentioned below:GENERATIONGENERATION THROUGH HYDEL GENERATORSGENERATION THROUGH SOLAR PANELSPRODUCTION OF LIGHT WITH WASTE AND HARMLESS MATERIALS GENERATION THROUGH BIOMASS The power will be generated by multiple sources in which some are installed at (near) house and some are installed at the periphery of the village.HYDEL GENERATORS will generate electricity through small river streams We will produce light without electricity, this method uses bleach. The bleach when added with little water amplifies and scatters the sun light and produces light of 100 watts.Next We have We solar panels which are going to be installed on every roof. Since, these are flexible solar panels we can use these anywhere. DISTRIBUTIONAccording to We idea there is small scale distribution. The methods We will use will provide power to single house or the whole village. The idea is to transform every house into a generating station. Or a separate connection for village hospital schools"
"The basic requirement of the model is to take pictures from the crop field in order to process pictures for segmentation and classification. The robot then needs to either predict, if the segmented leaf matches the previous dataset or should add The robot to the dataset in order to further train the prediction model. The RAW will carry a camera to take pictures in multiple frames and imply Image processing to segment the s. Once segmentation is done, the leaf is ready to be fed into the classifier for prediction. After extracting all the features, we apply ML algorithms (kNN) to prepare the dataset and calculate the accuracy of predictions for the training purpose. Once the model is trained, detecting the weeds and removing the weeds from the crop field using a robotic arm would be the prime focus.The task of destroying weeds is done is 5 stages - 1) Image Acquisition - In this stage, The robot travels through the crop field and captures the s which are processed and used to identify weeds. 2) Image Segmentation - The from the previous step contains a lot of background details which is not useful. In this stage, we train a neural network to implement an instantaneous segmentation technique which removes the background from the , and we get the useful part only. The output of this stage will only contain leaves without any background details.3) Feature Extraction - The segmented is passed to an algorithm to extract unique features from each leaf. We calculate the following geometric features - 1) Perimeter to Area Ratio 2) Foam Factor 3) Rectangularlity 4) Narrow Factor 5) Perimeter to Diameter Ratio 6) Eccentricity 7) Perimeter to Length + Breadth RatioThese features are used to identify leaves, as different species of leaves have different parameter values.4) Classification - In this stage, the parameters calculated are used to classify the leaf as weed or crop. We use machine learning with the calculated parameters as a feature list to classify the leaf. A kNN model is trained with a huge dataset of leaf s and is used to predict the class of leaf.5) Removal of Weed - If the input is classified as a weed then we calculate the coordinates of the leaf with respect to a given point, which is the origin of the robotic arm axis. The robotic arm with a blade end-effector is instructed to move to the calculated coordinates to destroy the weed with the help of the blade."
"Implementation:This aerial system could be used for many purposes, like delivering food autonomously, any package /medicinal drugs, providing help in disaster prone locations, surveillance of larger forest areas. Considering delivering food using the drone, a system is designed where the houses/buildings or any place will be registered with unique code which is generated on a landing pad in a QR code format visible to drone from a particular height. When the order from the customer is generated the food delivering company updates the path of the customer's location to the drone, which will be that unique code on the building, or house that is registered with the food delivering company. The food package is attached to the drone (weight carrying capacity of our drone is 2.5 kg) and after getting updated with the delivery point the drone takes off,the way points are achieved with the help of GPS and the live tracking of the drone could be done at the customers side on mobile application. When the drone arrives near the delivery point the where the landing pad with the unique QR code will be presented. the drone will be enabled with the obstruction detection sensors in-order to detect unusual obstacles act according to the logic developed. Here precision ails to provide precise coordinates, so the vision based system would scan the QR code and adjust the QR code to maintain the same axis and land on the landing with QR code printed on the QR code and leave The food package there once the person is verified by entering the one time password to the drone. Once package is delivered the drone accurately move towards the hoe position. In this delivery the flight controller and the raspberry pi plays a very vital role,normal autonomous flights can be achieved by only using the PIXHAWK flight controller but to make the system more efficient and accurate ROS (robotic operating system) is used to program the raspberry.OPEN CV is used for 3D visualisation for scanning the QR codes and acting according to OPEN CV. LIDAR is also an option for 3D mapping the environment and avoiding the unusual obstacles. For high precision more than one GPS can be used but the system gradually increases the cost and also does not have more precision that vision based systems only for accurate landing. Image Processing :The problem with the GPS when landing at the given landing coordinates is that the GPS doesn't have precision so when landing at some complex location this may prove fatal,hence vision system proves much efficient as vision system is able to analyse the environment and the landing pad where the GPS has to be landed, the data base is already created and know the system like,when the drone is above the building the drone tries to search for the landing pad and when the drone detects the landing pad analysis is done to decode the QR code printed on the drone once the drone recognises it,the drone slowly starts to descend maintaining the axis of the centre of the landing pad with it. simultaneously is checks for any obstacles in its path to avoid collision. FLOW CHART: autonomous delivery the drone is designed to function for the operational time between 45-60 minutes depending upon the payload and environmental conditions like winds. Rescue teams can easily deploy this drone and control the drone manually as the drone is highly portable due to the drone Fold-able structure and can so surveillance operations to save the people in the affected areas similarly the drone can be used as platform for aerial mobility."
"Firstly there will be web page where there will be two types of registration that is registration as a scrap dealer and as a scrap seller. For this ,there should be a valid proof for the scrap dealer to make the scrap dealer registration.Now the scarp seller has to specify the approximate weight of the scrap and the type of the scrap so nearest location of the scrap dealer will be allocated ,if there are more than one so the scrap dealer can also tell about the price that the scrap dealer would provide to the scrap so that highest bidder would get the benefits of the deal.The input will be taken from the strain gauge here Arduino will be used for taking the input of the weight so that no manipulation can be done in weighing the scrap. If need the scrap dealer can also send the picture of the scrap.the Application will be directly connect to API on the backend which will directly interact with MongoDB on the server. On the Application we will be giving two types of registration one as user and another as dealer. The location of the scrap dealer or recycler will be taken at the time of The location of the scrap dealer or recycler registration. The Location we got from the dealer will be stored in MongoDB with help of the Geo Spatial Feature in MongoDB we will give the nearest location of scrap dealer or recycler to the user who is willing to give the scrap."
"The main objective of this work is to track the sensors for obtaining real-time data for real-time data monitoring and management and it can be used for the analysis of the sensors. The information is stored on a cloud server database and can be displayed through an online web-app by authorized personnel only TCP Server and Client Communication module implement data transmission, Sensor Network Configuration and Gateway Configuration realize the gateway and sensor network management, Data Analysis and Statistical support for control management. The people operating the system can get all relevant details of sensors like when the system will become defective, the system working and all necessary details about the installed sensors can be easily obtained in the system. The lifetime of the system can be predicted with the help of supervised learning. The model would find the best fit for the data obtained and will accurately predict the lifetime of the installed sensors. We would be using a linear regression algorithm to predict the data points. The location of the systems will be shown in the form of a map, which would accurately show the real-time location of each and every sensor. This would be done with the help of Google Maps API.User Interface: User Interface of the system will have the following components : -1)Login: end-user logs in the portal on a Web browser. 2)Map-view: floor map of the organization where all the sensors deployed with all the sensors location will be shown here.3)Details of the sensor: when the user clicks on a particular sensor, all the information about the properties of the sensor devices is displayed on the screen.4)Management of sensors: users can even manage the installed sensors with this software which includes a change of threshold values of the sensor(eg. temperature sensor) and changing the brightness(eg. light sensor) of a sensor.5)Prediction: The battery life of sensors can also be predicted by the user here and alerts/notifications will be provided as well.Block Diagram :DFD Diagram :"
"Proposed Model: Block diagram:1.Surveillance Camera: The surveillance camera contains an infrared camera that has the feature to provide a normal color frame as well as infrared s to detect heat emitted from entities. Color s are useful to detect the presence of entities in the forest in daylight. Infrared s provide heat signatures of entities at night time or to detect camouflage.2.Raspberry Pi + Intel Movidius NCS Module: Raspberry Pi is a single-board computer that helps to process the transmitted frames from The surveillance camera with the help of a Vision Processing Unit. Intel Movidius NCS is a Vision Processing Unit that accelerates the performance of Neural Network to provide output without any delay. This helps in increasing the precision and accuracy AI algorithm with a low power supply that can be supplied via a USB output. This module will be attached to the camera unit wherein frames are transmitted in the neural network which performs the processing on frames and transmits data to the server.3.Centralized Server: A centralized server acts as the heart of a system wherein the data transmitted from the device reaches to raise any alarm with the help of Socket.io technique that provides real-time communication between Module and Server and also between Server and Android Devices. Also, the centralized server helps in storing data regarding the historic information that is transmitted from the device to make further analysis increasing the scope of the project.4.Android Application: Android Application helps the forest authority by providing real-time updates in case any suspicious activity taking place in the forest. Android Application will provide location updates of the suspicious activity. This helps the patrol officers to get to the location quickly to take necessary steps before any mishap.Flowchart:Steps :1.Monitor Surveillance through the camera : The input from the camera is color frames during the day or the heat signature emitted from the infrared camera (so that camouflaged entities can be detected within daylight or at night). 2.Process the input frames using the Intel Movidius NCS Visual Processing Unit (VPU).3.Ignore any frames in which no human or animal is detected.4.Detect any presence of human and classify as poacher or forest ranger : Within the given frame, the processing unit will first detect a human along with the processing unit pose(so that the processing unit can properly estimate the activity) with the help of a deep neural network and then predict the activity of the entity. a.Determine whether the object encountered is human or animal b.If it is human, then identify it as a forest ranger or poacher.5.Identify the pose of the poacher: a.Bending b.Sleeping c.Crawling d.Standing e.Also, If a person is perceived to be standing still and observing something continuously for a longer period of time (2 minutes or more) then it will be considered a suspicious action6.Determine the action performed :Suspicious activity involves: a.Holding a gun b.Setting up traps c.Throwing a bait7.If activity is classified as suspicious, track the target by location and notify the back-end server8.Upon receiving notification regarding suspicious activity, the Back-end Server issues an alert notification to the Android Devices of any Forest Rangers in the vicinity of the target area."
"MQ135 gas sensor , Humidity and temperature sensor is interface with the Raspberry pi 3 micro controller to get the measurements. Controller monitors Air Quality,humidity and temperature over a web server using the internet. When the measurements goes down below a threshold level, the measurements sends the signal, and will trigger an alarm. Then we can take certain actions regarding."
"The aim to develop a Firefighter drone is to assist the firefighting marshals by providing assistance in planning the firefighting marshals plan of action during the fire situations.This will be a semi-automated Quadcopter drone that has various sensors and camera on it(Thermal sensors,Heat sensors,PIR sensors,etc) for the purpose of generating data and This also has a robotic arm attached to This which carries the fire extinguishing balls. This contains features required to detect the casualties and fire in a particular area. Moreover, This will help to reach places where firemen cannot reach easily.For this, the concentrated domain is IOT &amp Image Processing. Hardware and software technologies are integrated to tackle the situation.The following functionalities have been included:Detect humansHumans should be detected in the presence of fire and smoke using cameras (Thermal and Normal).Creation of Area MapDrone should be able to map environment, placement of objects and also locate best exits inside of a structure.This can be done using a camera.Creation of Heat Map using Thermal CameraDrone should be able to create a heat map. On the basis of this, Collision Drone would be able to figure out the regions with higher temperatures and would be able to cater to Collision Drone on a priority basis.Detect and avoid Collision Drone should be able to avoid hanging objects and objects that get in close proximity to it.This can be done using camera,Thermal Camera,UltraSonic Sensors and IR SensorsMaintain Stability using Gyro Sensor.Collision Drone should maintain Collision Drone position and stability in raging flames. Adjust movements by using gyro sensor.Fall DetectionAccelerometer and Gyro Sensor will detect when drone has fallen and become immobile.Detect toxicity of the area with the help of GAS sensors.Accurate temperature reading and toxicity levels should be reported to drone operator using onboard appropriate sensors.Fire extinguisher ballEffectiveness of extinguisher ball on different types of fireDetermine the best location for dropping it. The above figure shows what exactly the proposed solution is about, that is, what exactly are the functionalities of Collision Drone. As shown in the above figure, Collision Drone will be deployed at the site of fire outbreak. When Collision Drone reaches the accident zone, Collision Drone starts Collision Drone’s job which comprises of human and explosive detection, area map generation to help the firemen, heat map generation which helps to detect humans even when the area is occupied with smoke, generate toxicity reports and drop fire extinguisher ball where it is impossible for the firemen to reach. toxicity reports will be seen directly on the system from which the bot is being controlled or can be generated on some other linked system."
On minisubmarine device there are several sensor placed with this sensor minisubmarine can do this sensor minisubmarine work without any disturbance or avoidance. minisubmarine device can work no interruption due to battery loss. This proposed system is worked on autonomous algorithm. The device having support GPS and accelerometer for navigation under water.
"The proposed system will be implementing on the already established drip irrigation system. The proposed system consists of three subsystems namely controlling unit, sensing unit and valve unit.In a drip system, the pipes are already fixed along rows with the valve opening for each plant. The solenoid values are fixed in the pipes for each row which is connected wirelessly to the controlling unit through GSM-GPRS module.Farmer has to place the robot at the starting point of the first row. As soon as the power is supplied, the robot will be ready to work in autonomous mode.At the same position, robotic arm equipped with soil moisture sensor is inserted in the soil near the plant. soil moisture sensor will measure the moisture content present in the soil near the plant and store the data. soil moisture sensor will move next 'x' meter distance and again test the moisture content by inserting the sensor in the soil near the plant. soil moisture sensor will collect the data throughout the first row by testing the moisture 'n' times and calculate the average moisture of corresponding row. Then the data is sent by the transmitter to the controlling unit. If moisture content is found to be less than threshold moisture level then the controlling unit will estimate the amount of water required to the plants in the first row based on received data and send a signal to open the first valve for water supply. Solenoid valve will control the flow of water.This process will be continued for all the rows and required amount of water will be supplied to every plant.the robot is equipped with soil testing kit which will estimate the quantity of nutrients in the soil and display the results on the screen of the robot. Health monitoring system can be implemented in parallel with soil testing system which can detect the diseases of the plants and help to monitor the health of plants regularly."
"In this project, we present the real time monitoring Health of patient through internet. The block diagram of the proposed method is shown in figure. In this proposed method consist of Temperature sensors and Heart Beat Sensor connected to Arduino Uno microcontroller. Arduino Uno microcontroller is used to collect the Heart beat rate and Body Temperature data from sensor data and processing sensor data and upload sensor data through internet to cloud."
"Implementation:The implementation of our solution will be carried out with the help of a quadcopter named FireBird. FireBird would be a semi-automated drone. FireBird would be loaded with various sensors such as ultrasonic sensors, temperature sensors, MPU sensors, PIR sensors etc. various sensors such as ultrasonic sensors, temperature sensors, MPU sensors, PIR sensors etc would be used to collect data based on which various functionalities would be provided. various functionalities would indirectly help firefighters to prepare a better and efficient plan of action. Our solution is an extensive blend of both hardware and software. The functionalities incorporated in the drone are as follows:Detection of Humans:Due to the presence of dense smoke, it would become difficult for a camera to detect the presence of humans. To overcome this problem a sensor-based approach is required. Our drone would use a combination of motion and audio sensors to detect the presence of humans in the region of casualty.Creation of Area Map:Our drone should be able to map environment, placement of objects and also locate best exits inside of a structure.This can be done using ultrasonic sensors and gyro sensor.Creation of Heat Map:Once Our drone is present in the structure, Our drone should be able to create a heat map of the region of casualty. Based on this, Our drone would be able to figure out the regions with higher temperatures and would be able to cater to Our drone on a priority basis.Collision Detection and Avoidance: Our drone should be able to detect nearby objects and ensure that Our drone maintains a safe distance from nearby objects. This would help in ensuring the safety of Our drone.This functionality can be implemented with the help of ultrasonic sensors.Maintain Stability and Fall Detection:Our drone should hover properly and maintain Our drone balance when Our drone's under operation. To ensure the above, gyro sensors would be used.Now there might be instances in which Our drone could fall on the ground and become immobile. During such a situation it would be important to notify the firemen about the occurred incident.To detect the fall of a drone, accelerometer and gyro sensors would be used.Detect toxicity of the area with the help of gas sensors:It is important for knowing the concentration of the various gases present at the site of casualty. To achieve this, gas sensors present onboard would be used. The data collected would be represented in the form of charts and concentration maps to the firefighters.The above diagram depicts the complete flow of the procedures which would be carried out once a fire outbreak would be reported to the fire station. First, Our drone would be deployed from the fire station. Once Our drone reaches the site of casualty, the drone enters the area through a safe point. Once the drone enters into the infrastructure, Our drone finds the nearest wall with the help of the ultrasonic sensors on board. Once the nearest wall has been found, the drone hovers towards it. When Our drone reaches the nearest wall with the help of the ultrasonic sensors on board, the sensors responsible for distance calculation are reset. Now the drone traverses along the wall of the room and collects data such as the amount of distance travelled, the temperature of the area which it is traversing through and toxicity levels of the area. All this data is being sent to the server and the area map is being generated over there. The fire-fighters have access to the server from where The fire-fighters can get the required area maps, heat maps and toxicity reports. As Our drone is traversing in the room, a check of the surrounding temperature is being done simultaneously. As soon as the temperature of the surrounding exceeds the set cut-off value, the drone initiates an exit protocol. This would ensure the safety of Our drone as Our drone would prevent Our drone from entering regions with extremely high temperatures. Exit Protocol :There might be instances in which the drone might lose contact with the server or maybe one of the server sensors might get damaged. In such a case Our drone would activate Our drone emergency protocol. its emergency protocol would make Our drone to hover to the coldest region of the room or exit the room through the nearest exit point."
"The implementation of the project begins from creating a suitable design for the product.Testing of the created 3D model in analysis softwares. Then the next step will be the collection of the required hardware parts.Making the assembly with hardware parts.Adding electrical units such as motors, propellers, pumps, power source.Adding the electronic circuits like arduino, motor drivers, circuitry.Testing in real life conditions.The design of the product consists of a long boat like structure having top and bottom surfaces bulged and the sides are ellipsoidal.The entry section is a rectangular opening from where all the plastic will enter. When structure moves forward, the water will enter the opening along with all the plastic. Just after The entry section, we have placed the plastic crushing and cutting mechanism. mechanism consists of two crushers (cylindrical rollers/ Helical gears). When all the plastic comes near two crushers (cylindrical rollers/ Helical gears), all the plastic will be pulled in by two crushers (cylindrical rollers/ Helical gears) and will be crushed. Just after two crushers (cylindrical rollers/ Helical gears), there will be two rotating blades which will cut all the plastic in small size. This whole crushing and cutting process will cause to plastic to be stored in less space. Hence more amount of plastic can be collected increasing the efficiency of the rover.The whole remaining part behind two crushers (cylindrical rollers/ Helical gears) will be used for storage purpose of plastic. Also some part of this section will be used to mount motors (for propellers) and pumps.There are two triangular sections just at side of the crushing mechanism which are totally sealed and will have only air. two triangular sections will be used to place all the circuit boards, batteries, wires etc. Also since this part has only air, this part will also help in achieving the buoyancy. Similar section are also placed at the rear side.Two fins are also placed at two sides of the rover to make the shape more aerodynamic. Also the rear of the design has tail like end.Three propellers are placed at the rear of the design, two on each side and one at tail like end. Three propellers are connected to motors which are placed inside in the above mentioned triangular section at the rear of the design.Since along with plastic, water will also enter the rover, all other parts inside the rover other than the sealed sections will be half filled with water. To pump water out, three submersible water pumps are placed inside water. And the outlet of three submersible water pumps is connected to the centre of Three propellers so that when water comes out water will provide further thrust for the motion of the rover.The upper surface will be a little bulged over which the solar panels will be mounted. Also, the rear portion will also be open to reduce the water drag resistance.Solar panels are the most important part because most of the power will be provided from the solar panels. To protect the solar panels from strong winds and waves, they will be covered when not required or when there is stormy atmosphere in the ocean.The GPS module, motor driver and the microcontrollers will also be mounted in the sealed sections."
"Capturing the hand gesture of deaf and dumb people by camera and processing the video by converting the video into frames and then processing the frames using the processing methods and comparing the processed s with the saved database s and printing the appropriate message saved with highest compared s.Flow diagram❖ Video processing❖ Image processing❖ Image comparison between processed and s stored in database• First the video of the hand of deaf and dumb people is captured for a short duration ofthe time. He can press any key to stop the recording as an interrupt.• Now the video is sent for processing which is converted into frames with the help of OpenCV library.• the saved database s are processed and the irregularities such as blur, contrast, resize and normalization is done.BEFORE NORMALISATIONNORMALISED IMAGE• One by one the is compared with the database.• The boundaries of the are drawn using the Contours Algorithm and ConvexHull Algorithm.• Database and processed is compared using algorithms1. Earth Movers distance: The earth mover distance is method to evaluatedissimilarity between 2 multidimensional s2. SSIM (Structural Similarity Index Mean): The Structural Similarity Index(SSIM) is a perceptual metric that quantifies quality degradation*caused by processing such as data compression or by losses in datatransmission.3. SFIT (Scale Invariant Feature Transform): SFIT is a method of extractingfeature vector that describe local patches of an not only are thesefeature vectors scale invariant, but local patches of an not only are also invariant to translationrotation and illumination.• The with highest similarity percentage, the corresponding message will bedisplayed on the output of the screen.Block Diagram:"
"A web-app based H/W is designed for tracking a transport vehicle and time-locationcalculations along A web-app based H/W route. Tracking System involves the installation of anelectronic device in a vehicle, with the web-app enabling all, the Administrator/Userto track the bus location and estimate the arrival and departure time. By theapplication, the management or any authorized individual can check the validity andeligibility of the passenger entering the vehicle. There are two applications serverand client. Tracking System shows where the vehicle is on a map and providespassengers and management staff, the updated information at different timeinterval. It is a real-time system. PIC16F108 micro-controller is used toprogramming for interfacing the S/W and H/W module. PIC16F108 micro-controller is connected to the cloudand hardware through the application. the application can be easily extended forthe central GPS to keep track of all the vehicles. Different queries and efficient routemanagement can be easily done through Tracking System."
"Implementation:Once the machine is in position with the human body(The person is currently sitting), the machine will start working and help the person to stand.· After proper balance is achieved, the person can start walking with the help of the machine.· the machine has high torque motors for legs for proper movement of the legs along with the machine.· the machine will have a metal exoskeleton on which high torque motors for legs for proper movement of the legs will be mounted.·An EEG sensor will be used to take the brain signals.·These signals are then fed to a microcontroller, and the controller will give the appropriate signals to the motor drivers.·Motor drivers will drive high torque motors for legs for proper movement of the legs in different directions. For example: If the person wants to move forward, the drivers will enable the forward motion of the machine is also provided with a safety protection circuit. If the machine fails and there are some mishaps, the machine will automatically switch off and will go back to the machine original position. Also, a switch is provided when pressed the machine will shut down and will go back to the machine original position(when both legs are straight).·The system is also provided with object detection using processing to calculate the distance of the object from the person and to stop the person if the distance becomes less than a certain parameter.system will have the following things:1) Brain Senor using EEG :After measuring the signals, the machine converts these signals into a suitable form of data, and this data is then transferred to the controller of the device. So by measuring these signals, we can automatically give the command to the machine in which direction to move and where to stop, etc.2) High Torque motors:the machine will have high torque motors for both the legs. After the signal from the brain is received by the controller, the controller will drive High Torque motors accordingly. As High Torque motors start moving, High Torque motors will push the legs of the person and will help the person to walk. Proper synchronization of both the legs is mandatory and will be achieved by the controller with proper safety precautions.3) Image processing :Image processing is a method to perform some operations on an in order to get an enhanced or to extract some useful information from ) Image processing. ) Image processing is a type of signal processing in which input is an , and output may be or characteristics/features associated with that . Nowadays, processing is among the rapidly growing technologies. In the system, we are achieving processing using open cv to detect the object in front of the machine.4) Camera:the machine.4) Camera will be mounted on the exoskeleton and will capture the s. Using processing, the distance of the object will be calculated. If the object is below certain parameters, the machine will shut down so as to avoid any collision of the person and to provide safety standards."
"Electroencephalogram (EEG) is used to detect the brain waves and is interfaced with a microcontroller which processes the signals and send the data to a smartphone and Electroencephalogram (EEG) will select the appropriate binaural beats (audio) and transmit the audio to the auditory device.an EEG system measures the voltage between Electroencephalogram (EEG) ""+"" input and Electroencephalogram (EEG) reference (or ""-"") input. Because of the high-input impedance of the differential amplifier, no current flows into the ""-"" electrode line, so none of its impedance elements matter (for the purpose of this measurement). Therefore, we can easily measure just the voltage drop across the first three elements -- the 5K in-series resistor, the electrode-to-skin impedance, and the impedance of a portion of the human body.R = (Measured Voltage * sqrt(2))/(Known Current) Microcontroller Board Design Microcontroller Board Design contains a voltage divider. Moreover, Microcontroller Board Design contains a +6V DC battery, power supply that provides DC power to the microcontroller and the amplifiers. We constructed an isolated +6 VDC power supply and connected an isolated +6 VDC power supply Microcontroller Board Design using Microcontroller Board Design. We cut the ground trace connecting the microcontroller ground to the USB ground. Smartphone: The signals (Brain waves) detected by the EEG and processed by Microcontroller Board Design are then transmitted to the smartphone where the application is designed such that Microcontroller Board Design uses the signals to select the Binaural beats which are stored in the device memory. The binaural beats are segregated with reference to the data received from Microcontroller Board Design. The mental states of the user will be identified by the application and according to the data received from the microcontroller received the application will select appropriate Binaural beats (frequencies) will be used to help improve the person’s mental state and will be transmitted to the auditory device (headphones).There will be two modes in the application for the user to choose between, one in which the app will automatically detect the users current state of mind and appropriately play the audio, in the second mode the user will be manually able to select the audio according to the person’s desired mood state.Generation of Binaural beats: Binaural beats are generated when the sine waves within a close range are presented to each ear separately. For example, when the 400 Hz tone is presented to the left ear and the 440 Hz tone to the right, a beat of 40 Hz is perceived, which appears subjectively to be located “inside” the head. This is the binaural beat percept."
There is no need for software requirements only thing is to separate non biodegradable wastes and biodegradable wastes. Then place only thing in underground and hide non biodegradable wastes and biodegradable wastes.The best way to separate plastcis is crushing non biodegradable wastes and biodegradable wastes and isolate magnetic pieces from non biodegradable wastes and biodegradable wastes.
"As mentioned earlier our aim is not to develop a drone but to develop multiple applications that can be developed on a drone. For this project our have taken a sample quad-copter which has a payload capacity of 4 kilograms for which we are developing these attachments. Also we are going to implement some of these attachments on a ground terrain robot. 1. ALL TERRAIN ATTACHMENTThis is most important attachment as this technology is developed only by few countries and this being the First one in India. This attachment includes 4 tanks based track belts connected to movable arms and side shaft DC motors. With the help of side shaft DC motors the attachment will enable a drone to run on any surface such as mud, staircase or hilly regions.ALL TERRAIN DRONEMOVABLE ARM MECHANISM FOR OBSTACLE CLIMBINGBOTTOM VIEW SHOWING THE DC MOTORS AND SERVO MOTORS2. POLLUTION AND WEATHER MONITORING AND MAPPINGAttachment when combined with Drone or All Terrain Drone will be capable of measuring various amounts of gases present in the air and also monitor the weather by measuring the humidity, temperature and pressure. For measuring different amount of gases we are using different types of MQ gas sensors where each sensor measures different types of gasses. For measuring the temperature and humidity in the atmosphere we are using the DHT-11 Sensor and for measuring the air pressure we are using the barometric pressure sensor. All this data will be transmitted live to the user by using either WiFi or Lora. 3. LIDAR BASED MAPPING AND MILITARY SURVEILLANCE.LIDAR, which stands for Light Detection and Ranging, is a remote sensing method that uses light in the form of a pulsed laser to measure distance. These light pulses combined with other data recorded by the airborne system generate precise, two-dimensional information about the surrounding area. 4. FIRE FIGHTING COMBINED WITH SOLAR PANEL CLEANING.In this system we are connecting a powerful water pump which will be able to shoot water with very high pressure in a single direction during firefighting mode and when used for solar panel cleaning, it will shoot water with a very less pressure and a ground robot will clean the panels using the wipes attached on the back of the robot.5. AGRICULTURAL WATERING WITH PESTICIDES SPRAYING.This attachment is similar to firefighting attachment only difference being that instead of a unidirectional water shooting we are using quad water spraying system which will ensure that the water is spread evenly over a wide range of area in a controlled manner. This will save lot of water especially during the drought conditions. Also while spraying pesticides we will spray pesticides in a controlled manner so that all the crops receive right amount of fertilizers without harming the crop growth which will lead to more productive farming. 6. SECURED DELIVERY ATTACHMENTThis attachment focuses on delivery any small or medium sized package from one place to the other without being obstructed by traffic. This system includes a barcode or QR code scanner which will be sent to the customer by online shopping app like Amazon and when the drone arrives near the customer only thing he or she has to do is scan the code using the scanner on the attachment and the electronic lock fitted on the door of the attachment will open.The 3D design of this block is given below.COMBINING BLOCK ATTACHED TO THE ALL TERRAIN DRONEDESIGN OF THE COMBINING BLOCK OF ALL TERRAIN DRONEDESIGN OF THE COMBING BLOCK USED FOR NORMAL DRONE MODE"
"Farmers will Farmers have segregated the proposed design into 3 subdivisions as follows:● IOT BASED FARM MONITORING : By using various smart agricultural gadgets, farmers will gain better control over the process of raising livestock and growing crops, making it more predictable and efficient. We will explore the use of IoT in agriculture and examine IoT benefits. We have used IoT for several processes required in efficient agriculture. The initial procedure of crop selection and crop rotation can be done by monitoring climate changes like rainfall patterns, humidity levels and incidence of sunlight by using several sensors. Also we can monitor changes in soil quality which depends on pH level, soil moisture and nutrient content. Crop monitoring is the after process for which surveillance is required. Thus our designed application allows a farmer to predict optimal weather conditions at sowing time under the availability of local networks. ● GROUND ROBOTICS SYSTEM :There are 8 major steps in agriculture. We will employ a single robot for minimum use of power to implement 3 major processes in growing of crop. The process of breaking the ground also known as tilling will be done by installing cultivator shanks beneath the robot for turning of soil and breaking of soil. A seeder with multiple centrifugal spreader is to be placed below at the center of the base. A seeder with multiple centrifugal spreader will place the seeds in the growth by pressing the base sheet towards the ground at least 3-4 inches deep. A tin sheet can be used to cover seeds with soil for proper cultivation.Second robot will be used for watering and harvesting of the crops. Second robot will have a removable cutter at the front which will be used for cutting and a conveyor belt which will put the harvest in storage tank which will also be used for storage of water. ● AERIAL SPRAYING SYSTEM :● AERIAL SPRAYING SYSTEM will have a drone which will have sprinklers attached to respective arms. Drones can spray the correct amount of liquid, modulating distance from the ground and spraying in real time for even coverage. The result will be increased efficiency with a reduction in the amount of chemicals penetrating into groundwater. This dramatically reduces the amount of chemicals used and virtually eliminates overspray. In fact, many experts estimate that aerial spraying can be completed up to five times faster with aerial drones than with traditional machinery.User Interface : Farmers will be provided user friendly software which will first help Farmers for selection of crops as per the climate change. Also ● AERIAL SPRAYING SYSTEM will monitor the soil quality, soil moisture and nutrient content. There will be one drone and two robots on the land. The land robot will carry seeds and will drop seeds to the farmland. The land robot will do the work of ploughing, drilling. Another robot complete the task of watering and harvesting. At the same time user will send aerial drone for spraying the pesticides"
"The Implementation of the proposed system will be done by integrating google handwriting input with our designed software. This will allow us to convert the handwriting of the User into text for easier manipulation. As the User writes onto the tablet, which will be the input, the User will simultaneously be converted into text and hence can be further manipulated. This data then can be saved by the User as notes or can be submitted to the teacher in case of examinations. This is done by the Network that is established within the institution and all the test papers get stored in the Centralized Server that can further be transferred to the designated teachers.the proposed system the proposed system is broadly divided into three parts: 1) Application Software: The application software will accept the data in form of handwriting of the User, written via a stylus. the proposed system will also provide with the options of selecting Note-taking/examination mode with submit/saving options. 2) Google Handwriting Input: The Google handwriting input module will convert the input given in the form of handwriting to text. Once converted, the proposed system is ready to perform the required functions based on additional inputs provided by the User. 3) Network and the Centralized Server The Final part of the proposed system consists of a the Network that is established within the institution and a Centralized server. The Final part of the system is exclusive for test/assignment submission etc. the Network that is established within the institution is a collection of all the devices using the software and the Centralized Server is used as a centralized storage. When the “Submit” option is selected, the proposed system starts the network protocol which will load the file into the Centralized Server. Further, the Network that is established within the institution can consist of the teachers’ systems as nodes that can directly provide the Network that is established within the institution with the answer files to the Network that is established within the institution computers."
"Localization System (Whycon) • Whycon is an vision-based localization system that can be used with low cost web cameras. Whycon achieves millimeter precision with very high performance. Robot Operating System (ROS) • Localization System (Whycon) is a flexible framework for writing robot software. Localization System (Whycon) is a collection of tools and libraries that simplifies the task of creating complex and robust robot behavior across a wide variety of robotic platform. No fly zone mitigation: • There are many restricted airspaces within a city. This module has been built from scratch to make Localization System (Whycon) comply with ATC and other authorities. • This C++ program is in a way a preprocessor to This module. This C++ program will check the path that a drone has been ordered to take and make sure that a drone doesn’t enter restricted airspaces and hazardous areas designated by the authorities. DJI Tello drone controller python package: • This is a python package which controls DJI drone 'Tello’. • DJI Tello drone controller python package defines functions that can be used to communicate with a drone. There are many functions defined for multiple controls. many functions defined for multiple controls take values from the user, converts many functions defined for multiple controls to the drone’s byte code and sends control packages to a drone. PID controlled command program (engine.py): • The main program that uses the library functions to command a drone. The main program that uses the library functions to command the drone uses a closed feedback loop to control the power commands to a drone and move The main program that uses the library functions to command the drone to specified waypoints. The main program that uses the library functions to command the drone gets the location of a drone in from The main program that uses the library functions to command the drone and gives control commands according to a PID algorithm."
"This device is just like a bracelet, we can wear This device. When we wear This device. The sensors in This device sense the condition of body like this• The heart beat sensor takes the heart rate of the body.• The sweat sensor take the Sweat conditions of body. • The sweat sensor helps to make medicines more predictive and personalize.• The PEGS,FPBS sense the food conditions. • The sweat sensor controls the functioning of all sensors.• The sweat sensor gives output to the user.And the app has able to analyse the conditions of body that are given by This device. And The sweat sensor gives solutions to that problems, with the help of artificial intelligence.If we want to do first aid to the victim. Then select the first aid module and mention the problem In the column. And then the first aid module gives the solution for the problem."
"This project consists of containers, ultrasonic sensors for liquid level detection, AVR family micro=controllers, LCD screen for displaying status of water level, buzzer for giving alerts regarding water level and some few software implementations .On every container an ultrasonic sensor is fixed . an ultrasonic sensor helps in sensing the liquid level present in the containers, the containers emit waves at a frequency which is too high for humans to hear. Then the containers wait for the sound to be reflected back, hence calculating distance based on the time required .A LCD screen is used for displaying the status of the current task running and LCD screen will also display the pictorial representation of the task running. LCD screen will also provide a color combination where ,when the water is below the minimum then the water will indicate red color and if the water level increases the maximum level then the water will indicate blue color.Rectifier is used to Regulate DC power supply to convert the AC supply to regulated DC voltage using bridge rectifiers.The regulating device acts like a variable resistor continuously adjusting a voltage divider network.This allows us to make The regulating device comfortable with the alternating current voltage. The regulator enables the entire circuit to function as a threshold detector thus working as ON/Off switch. Hence we will be able to know the limit of the tank at which the sensor is being installed. Transformer is used with 6V 500 mA output for power supply. Transformer provides power transmission by transforming induced current from one circuit to another.The induced current can be converted step up or step down of current or voltage.A mega 328 modulator is used to transmit many different channels on air: each has a different frequency of the carrier and each is modulated to send a different audio signal.this is specially used for buzzer. Ultrasonic sensors (HC-SR04) are used for the measurement of level. This has continuous output during measurement time. This has good sensitivity and accuracy which detects even small variations.The main implementation is to show that the water present in the container ,when exceed the limit or if the water level drops down the minimum limit then the user should get notified and the user should perform some basic tasks such as stopping the flow of water or start the flow of water. The notification is nothing but beep sound given by a buzzer .Here a buzzer plays an important role for notifying the user about the water level. Here we are using transistor (of NPN type) as a Switch. Initially there is no voltage applied to the base of the Transistor Q1 and the transistor is in OFF state and no current is flowing through the collector and emitter and LED is OFF . The water level reaches to Point A in the tank, the positive side of the battery gets connected to the base of the Transistor Q1 the Transistor Q1 through the water. So, when a positive voltage has been applied to the base of the Transistor Q1the Transistor Q1, a positive voltage gets into ON state and current starts flowing from collector to emitter. And RED LED glows."
"Since we are moving towards Digital India and to ensure the conservation, restoration and sustainable use of terrestrial and inland freshwater in agriculture and also to ensure the good health and well-being of our community, our farmer community can be provided with reliable assistance with the help of an Intelligent Quad-Copter. This system can interact with every individual farmer in the farmer community. This system can give appropriate suggestions based on the analysis made on the field and also guide the farmers. The suggestions provided by This system will be 60%-70% accurate. Such suggestions are made mainly based on the available water and the soil conditions. Since This system is going to assist the farmers from starting to ending of the cultivation, This system will periodically inspect the land like checking the growth of the plants, water requirements met, etc., and produce a detailed analysis of This system. This system will make that report available to the farmer. Since we all know that farming involves four phases like ploughing, sowing, irrigation and harvesting, This system will assist the farmers during all these phases. During the ploughing phase, This system will check the fertility, climatic conditions, etc., and suggest the farmer about the variety of crops that can be cultivated to increase the yield than ever before. Since This system supports verification technologies like Facial Recognition, etc., This system will get all the information about the farmer stored in the database after verification. So, This system will update the database about the feedback given by the farmer then and there. After the ploughing phase is started, This system will also suggest the farmer about the type of sowing, the farmer/he/ can proceed based on the crop selected. he/ will even suggest the distance between each crop and the depth in which the seed should be sowed and the seed will even display how to do the seed. In the ploughing phase, This system will provide a detailed schedule for irrigation which makes sure the efficient use of available water throughout the ploughing phase and also suggest the farmers about the possible ways to increase the growth based on the analysis made. In harvesting phase, This system will provide a correct period of time to start harvesting since there is a verge of wastage of yield if there is not much demand in the market."
The system consists of two parts.1. Drone2. Control UnitDrone:The drone is the major part of the proposed idea. The drone goes underwater and takes the live video from below surface. The drone consist of seven major parts such as1. Primary tube2. Balance tube3. Foot4. Vertical Propeller5. Horizontal Propeller6. Camera7. Led lightThe primary tube is the main structure of The drone. lightThe primary tube consists of the battery and other important things such as microcontroller for controlling the propeller. The balance tube and the foot are directly connected to lightThe primary tube. The LEDs are placed in lightThe primary tube to give more quality to the video that is taken underwater. All the structures are air sealed so that water cannot penetrate into All the structures. The foot and lightThe primary tube are used as stabilizers for lightThe primary tube. The navigation of The drone is controlled from the surface using the control unit. Arduino mega is used as the controller of The drone with 12V battery as Arduino mega power supply. A 12Mp digital waterproof camera is used for video recording. The live feed of the video is transmitted by USB cable from A 12Mp digital waterproof camera to PC. A 12Mp digital waterproof camera is also powered by the same 12V battery. Three dual H-Bridge LP298N Motor drivers are used to run the propellers and The LEDs. To maintain a constant voltage supply the motor driver is also used to control The LEDs. The motors used for the propellers are 12V DC boat bilge pump motors. These are underwater pumps which can also be used for the movement of The drone using the propellers. The figure 1 represents the front view of the drone and figure 2 shows the side view of The drone. Figure 1: Top View of Drone Figure 2: Side View of DroneControl Unit:the control unit is the part which controls The drone from the surface. the control unit has two joysticks to control to navigation of The drone. One joystick is used for the control of depth of drone underwater and other is used to control the forward and backward direction of The drone. The video feed is not included in the joystick The video feed is done separately in the PC. The USB cable is responsible for the transmission of video from drone to PC. The LEDs present in The drone is also controlled by the control unit. The block diagram of the drone and control unit is shown in figure 3. Figure 3: Block Diagram
"we are implementing a swarm master robot. a swarm master robot consists of a micro controller unit, motor drivers, DC motor, Servo motor, Planting mechanism, Vehicle movement module, Transmitter, obstacle sensor, Position encoder and a DC power supply.The paddy field is prepared for the transplanting by dividing the whole plot into several rectangular areas and the whole plot is ploughed using tractor. After that , The paddy field is filled with water for about 5 days. Then The paddy field is levelled by clearing the obstacles like small stones, roots, small twigs etc.. The paddy field is kept uninterrupted for some days till the sand is settled down. a swarm master robot is placed in such a condition.When the power supply is on, a swarm master robot starts moving forward in a straight line and checks whether there is any obstacle on the way. The straight movement of a swarm master robot is made possible by engaging and disengaging the clutch. Each tyres are having separate clutch. So that this mechanism can also be used to turn a swarm master robot by disengaging single clutch at one time. If we disengage left clutch, a swarm master robot turns to left and if we disengage right clutch, it turns to right. The engaging and disengaging of clutch is done according the algorithm and programming. Turning mechanism is done by incrementing a counter in the programme where, a swarm master robot turns to left when the counter is an odd number and the robots turns to right when the counter is even. The obstacle sensor is used for detecting the obstacles. If the obstacle is at a distance greater than 20 cm a swarm master robot starts planting and continues to move until The obstacle sensor detects any obstacle in the way. When there is any obstacle in the way a swarm master robot immediately turns and continues planting according to the program. The obstacle sensors are placed in different heights. If the obstacle is having a height equal to or greater than the mentioned height and the distance to the obstacle is equal to 20 cm it means that a swarm master robot is at the end of the field section. The obstacle sensor neglects the obstacles with heights lesser than the mentioned height.We are implementing the model in such a way that all the mechanical parts are less power consuming. a swarm master robot is having a sliding part at the front and two tyres at the back side so that a swarm master robot requires less amount of energy. The tyres are connected using a shaft. There is a chain connecting the planting part and the shaft as a shaft rotates a chain connecting the planting part and the shaft rotates at the other end of a chain connecting the planting part and the shaft we are connecting a planting system so that the plant is planted as the tyre moves. A tray is at the back end to load the paddy as the tyre rotates one cycle the planting system plucks a plant from the tray and the plant it in the muddy water.The energy required for running this poduct is given using solar panels which are placed on the top of these robots. We know that these days energy conservation is an important factor because of the decreasing amount of fossil fuels and the pollution caused while burning these fossil fuels. So the best solution is solar power because the best solution is a renewable energy source."
"The entire project will be made with an effective combination of hardware and software. The major heads in the implementation part are users, a web application, google map, database, a parking system and an admin. The User Interface:The User Interface is connected and can communicate only with the web application, this could be done for registration or login purpose, verification, location access permission, usage request or for sharing parking information and selection.Database: The entire detail of The User Interface is then stored in Database and there is a bidirectional communication between web application and database for transferring information. After getting the permission to access the location, user’s location can be taken with the help of google map and then is stored in Database, thus database now stores every useful information of the user including contact number, email, vehicle registration number, and few more. Database also contains the information and details of the parking systems in the covered zone, and is connected bi-directionally for exchanging updated information.Admin is also given a bi-directional connectivity with the parking system for providing him/her the status updating.Finally, the user is connected with the google map and can find directions towards the parking easily. Hardware StructureA well-structured parking slots would be made with sensors placed at every slot either in the middle of a slot or according to the available place, each of sensors placed at every slot either in the middle of a slot or according to the available place are connected to a micro controller. Every lane will have a common micro controller connected with sensors placed at every slot either in the middle of a slot or according to the available place. each of these sensors work on power supply therefore the sufficient amount of power supply is also provided to each of each of these sensors for each of these sensors proper functionality.These micro controllers are connected to the internet, basically our database so that the internet can transmit updated details to the database for proper functioning of this parking management system.The implementation part with the hardware is cheaper and will provide the best of the ways to solve the parking issues in effective as well in economical ways."
"Our topic uses technologically advanced methodologies for data analysis and predicting outcomes based on feature extraction. The approach in implementation makes use of the state of the art technologies like the Internet of Things(IoT), Artificial Intelligence and various data visualization, data manipulation with a Cloud-Based Server to store the results of the same.Objective &amp Data Collection :The objective of this methodology is the design of the deep learning model that could predict whether the slum should be rehabilitated or not using the features extracted from the data collected over time by using various sensors that would be located at the points of concern inside the slums.The factors that affect the quality and well-being of the residents are mainly environment, health, sanitation, and water quality. The data collected with the assistance of sensors, the demographics of each and every resident, which comprises of the education level, marital status, gender ratio, number of children, etc would be taken into account. Environmental data would play a major role in determining if the place is habitable or not. The environment data not only includes the level of Carbon-dioxide and oxygen but is also determined by the level of harmful gases like Methane, Butane, LPG, Smoke, Methanol, Carbon Monoxide. The LM35 sensor would assess the overall air quality. The readings of the sensors would be sent to the cloud server over time. Another dataset is the health record of patients which includes the most recent disease that the patient faced, the patient age, blood pressure, glucose levels, etc to detect the spread of epidemics and see which diseases are prevalent in which sections. The water contamination module would check the quality of water if water is clean enough to be used to daily activities, is water potable, are there any harmful bacterial present inside The water contamination module. Analysis :All of this data would be combined together in a .csv file. Once this data is obtained the next step is cleaning this data. Using appropriate measures to fill the missing values, removing the outliers. As there can be various categorical variables, we need to encode there can be various categorical variables using one-hot encoding to convert there can be various categorical variables into numerical values for the Deep Learning model to use. The ordinal variables need to be encoded using Integer encoding. We need to identify what are the input and output variables. All the features need to be normalized, in order to avoid underfitting similarly, we need to consider what variables are worthy to be selected as features to avoid overfitting. The values of the output variable are normalized to a specific range (Data Cleaning). All the data obtained is now ready for detecting the features. The appropriate features would be identified by observing the correlation matrix, the covariance between variables, data visualization and carrying out statistical tests. Two predictions are made-one for IoT module data and the other for the health records. Deep learning models would be deployed for the same. All the data obtained would be divided into train, test and validation tests. The model would be trained and evaluated by tuning in the hyperparameters like the learning rate, batch size and the number of epochs. The results would be evaluated by metrics like loss, confusion matrix, and F-Score. For the health records, a class of diseases would be predicted whereas the sensor data would decide if any changes are required.User Interface :The end product would be shown on an interactive and dynamic website and an app that can be accessed using a simple Log-In by the government authorities.Flow Chart :"
"Hydrogen is produced by the Electrolysis reaction from the water by giving minimum amount of power supply.Ideally, requires a potential difference of 1.23 volts to split the water into Hydrogen &amp Oxygen. Then, Hydrogen is given to Fuel Cell Stack. Fuel Cell converts Hydrogen and Atmospheric oxygen into Electricity and Water. Hydrogen is the cleanest energy solution. Hydrogen is ecologically positive life cycle and Hydrogen is zero impact. It’s emission is only pure water. the water is given back to the Electrolysis Chamber. As a result of this, enormous amount of electricity is produced from the Fuel Cell drives the rotors of the Drone. It has longer flight time compared to conventional drones that runs on battery. The Uniqueness of our idea is that the Design. the Design is made in such a way that, in the event of failure of any 1 rotor out of 6, the Drone can able to land safely. In our project both cathode and anode used are graphite electrodes with the electrolyte being water with a desirable amount of salt.Electrolysis Reaction Chamber and Fuel CellThe amount of hydrogen can be calculated using:Hydrogen [water(quantity) + salt(quantity) + volt + ampere] * timeFuel Cell Stack Parts : Flow Chart :"
"Working of Life Saver Drone:First we set Life Saver Drone in remote controller mode or in UAV mode as per requirement and set the required temperature of the organ container, set the starting point and the ending point (destination) of the flight. Then the organ container will carry the organ safely with the minimum vibration. Simultaneously the organ container will send the live path coverage and the video and maintain the temperature of the organ container. the organ container will send the voltage of the battery of the drone and the organ container when the wind pressure is more that time. the organ container will hold the passion with help of GPS system when the drone reaches to the organ container destination point. the organ container will land very safely and slowly with no damage and detach the organ container from Life Saver Drone with the help of hinges and servo motors. After that the organ container will follow the returning path and the organ container will come back at the starting point with the help of return to launch position.Working of Cooling Mechanism:The life saver is a semi-controlled UAV drone which is specially design for organ transportation from 1 phase to another place within a minimum time.First we set the temperature of the organ container according to which organ we have to transport. When the temperature of the organ container is set at a particular oC the temperature of the organ container can maintain the temperature of the organ container as well. If the temperature of the organ container increases the sensor send the signal to the microcontroller which turn on the relay module which act as on off switch.If relay get the signal from the Arduino then the Arduino turn on the cooling fan and turn on the thermoelectric peltiers till the temperature is equal to the set temperature when the set temperature is equal to the container temperature then the relay turn at the fan and peltiers accordingly."
"Energy harvesting technology from the movement of vehicles is an attractive approach that captures the wasted energy produced on the highway to obtain clean, sustainable electrical energy that can be used to power street lights. Piezoelectric energy technology is new technology and has not applied on a large scale in roads. Therefore, piezoelectric energy awareness and expertise in this sector are very limited. As the movement of the vehicles is everywhere, the ability to capture the wasted energy produced on the highway at the lowest cost would be a significant step towards greater efficiency and cleaner energy generation."
"Block Diagram of Proposed System:Proposed System is basically providing a total remote access to the Wheelchair. The main entities or blocks of Proposed System are The EEG sensors, Arduino Uno and the Wheelchair. The working of each of the block is as follows: Figure 3.1: Block Diagram ProposedEEG Sensor:The function of electrode sensor is to sense electric field changes due to the neural activities in the different lobes of the brain when person’s body part moves. electric field changes due to the neural activities in the different lobes of the brain can also be sense even when a person think soft a person body part movement without moving actual body parts, just through imagination. More probably, the range of brainwaves is from 0.5 Hz to 40 Hz. The EEG data captured with sampling rate 512Hz. This EEG sensor made by three electrodes: Ground, Reference and EEG. This will basically extract the EEG signals and pass on to Arduino Uno.Arduino Uno:A Brain Computer Interface or BCI system is a system which consists of various subsystems such as Amplifiers, Analog to Digital converters (ADCs) and a Controller section. A Brain Computer Interface or BCI system is used to process a raw data or we can say a Brain signal and A Brain Computer Interface or BCI system will convert A Brain Computer Interface or BCI system into a control signal in order to control a wheelchair. This all Processes are done by Arduino Uno and hence the wheelchair is being controlled depending on received control signals.Wheelchair Body:Wheelchair body consists of a Chassis, a Battery, a Ball bearing, a motor driver circuit and two motors for moving the wheelchair. As a control signal has come from BCI system, it is given to the motor driver circuit. Motor driver circuit consists of a motor driver ICL293D which can drive two motors at a time. A battery of 9V is used to provide power supply to motor driver circuit. Now according to the control signal which has come from BCI system, the motor driver circuit will turn on the motors forming various movements like Forward, Reverse, Left, Right and Stop with respect to the corresponding control signal.Flow chart: Description:Initially it will check whether the device is connected or not.If the device is connected then the device will retrieve the data from FTnS mind link EEG sensor via Bluetooth module.the data will be processed to generate or determine the mental command i.e. forward, reverse, left, right or stop.This determined signals will be sent to the Arduino Uno and this will pass the control signals to the wheelchair.According to the control signals received wheelchair operation will be performed.If the device is not connected, the device will be in the scanning mode.This process is continuously repeated."
"Sensors and Actuators: Soil fertility sensors is used by the computer managing the whole process to check the fertility of soil and the fertility is compared to database of various plants and appropriate range of plants is suggested to the farmer. various plants and appropriate range of plants are suggested to the farmer because various plants and appropriate range of plants are the plants that are capable of providing high yield in that range of fertility. Temperature and Humidity sensors are used to sense the weather and soil drench level for the well being of plants and these details are sent to the computer to decide on the work of the actuators such as pouring plants through setup and etc… All the decisions taken by the system comparing it to the values for the nature of the plant and appropriate steps are taken by the actuators by looking at the data from the sensors, so that the yield is enhanced and the health of the plant is not compromised. The data that the system compares from the real time data to perform appropriate situations can be world standards or the data’s provided by the farmer. These are the things that makes the system highly customisable. Automobile Robot: A fully functional and automobile robot will be used to maintain the plants physically. This will be controlled by the automated system so that the external and physical activities can be done using this and other things can be done by the farmer as the farmer will also be provided with the controls for Automobile Robot. Physical activities such as plucking, cutting , harvesting, cleaning etc… Application: A web or mobile application would be provided to the farmers that requires an internet connection. This application provides the farmer with the information of different market rates in which the farmer is eligible to sell things. As the farmer requires external helps during farming that can be utilised by the farmer by hiring, This application helps the farmer as well by giving the farmer the information of hiring it in the correct price. Thus, This application provides the perfect prices for the services and products that the farmer hires and gives perfect selling prices for the farmer products considering the markets."
"This section discusses the system modelling, process and theoretical design of the Smart Plastic RecycleMachine. This section also describes the design flow which was used to implement the design.A. Process of RVMIn this block diagram we explain the step procedure of proposed Reverse Vending Machine(RVM) working.In A. Process of RVMIn this block diagram we explain the step procedure of proposed Reverse Vending Machine(RVM) working waste plastic materials acts as an input and then check by several sensors. First machinecheck through the sensors that Is the plastic material received? Is the material made of Plastic? Is the plasticempty? According to that, weight sensor weighs the received plastic item and give output to user in form ofcoins as per the weight of item [6]. Output criteria is discussed in table I.The operation of proposed Reverse Vending Machine has three main steps (Input step, Process Step, OutputStep) operation as follow:•The user Can insert plastic of any shape in Reverse Vending Machine.•After inserting the plastic, I.The operation of proposed Reverse Vending Machine is checked by Three Sensors First checked by Capacitive proximitysensor, then by Infrared Photoelectric Sensor and at last checked by the strain gauge weight sensor.•After that he will get coins on the basis of Weight of Plastic.Capacitive Proximity Sensor: - Infrared Photoelectric Sensor is used for detection of metallic and non-metallic objects (plastic,tin, Aluminum, wood, etc.). Capacitive Proximity Sensor: - uses the variation of Capacitance between object and sensor.Infrared Photoelectric Sensor: - Infrared Photoelectric Sensor is used to detect the presence of non-ideal thing as an input i.e.water, non-water-based fluids, stones etc. Infrared Photoelectric Sensor uses standard visible LEDs that pass-through water anddetect Infrared Photoelectric Sensor using 1450nm wavelength.Strain Gauge Weight Sensor: - Infrared Photoelectric Sensor is used to determine the weight up to 1Kg of items. Infrared Photoelectric Sensor is in theform of straight bar and translate Pressure or Force into an electrical signal.B. Flow DiagramThe flow chart of the Smart Plastic Recycle Machine. B. Flow DiagramThe flow chart of the Smart Plastic Recycle Machine starts by receiving the input, which is theplastic bottle or any other plastic thing. Infrared Photoelectric Sensor then detects the Plastic. If Infrared Photoelectric Sensor does not detect anyPlastic, B. Flow DiagramThe flow chart of the Smart Plastic Recycle Machine comes to a stop. If Infrared Photoelectric Sensor detects a Plastic, Infrared Photoelectric Sensor sends Plastic to next sensor forwater based liquid detection after Infrared Photoelectric Sensor check plastic weight and give different output accordingto weight range.After doing lots of literature study about Reverse Vending Machine(RVM) we foundThe input item will be sensed if it is desired plastic pet [4] bottle. The sensor type used are the industrial laser and detection system. When we foundThe input item is in, The sensor type used will make the crusher motor to run for 3 sec and after crushing the output granules will be deposited in the collector. At the same time the vending system will be activated by the controller and a candy will be delivered to the user. the vending system will monitor the level of the crushed plastic in the collector. The advertisement display will display the advertisements of the benefactors. The Algorithmic State Machine Diagram consist two main states in which The Algorithmic State Machine Diagram receives returned item as an input. In the second step, Infrared Photoelectric Sensor checks that containers are received or not? In the third step, The Algorithmic State Machine Diagram detects if plastic or not. .If Infrared Photoelectric Sensor detects the plastic PET bottle then Infrared Photoelectric Sensor gives a candy as an output. National Conference on ""Emerging Research Trends in Electrical, Electronics &amp Instrumentation"" 27 | Page (ERTEEI'17) Plastic Recycling Vending Machine Plastic Recycling Vending Machine After deciding to create the Plastic recycling vending machine, we had to decide what electronics to use and which sensors we would incorporate into what electronics. After a lot of searching, we found an idea about the electronic circuits, the working structure and software components suitable for making the Plastic recycling vending machine. Motivated by the problems due to health issues, we believed that the Plastic recycling vending machine would be a good design and a good model to the problems due to health issues. So the Plastic recycling vending machine would need sensors to detect the plastic bottles, motor, claw blades for crushing. This project has set out the vision of making a clean environment free of littered plastic pet bottles. The existing system has no detection technologies so we are planning to include the detection system in we . The existing system will be soon beating the market which mainly can be introduced at public places such as shopping Malls, Airports, Railway stations etc. In future we are planning to in co-operate the plastic as well as metal and glass bottles can be inserted in Plastic recycling vending machine"
"The proposed tracking system is designed to track and monitor the school vehicle at real time environment using web page in smart phone, The proposed tracking system is an integration of several modern embedded and communication technologies. To provide location and time information anywhere on earth, Global Positioning System (GPS) is commonly used as a space-based global navigation satellite system. The location information provided by us GPS systems can be visualized using Google Earth technology. In wireless data transporting, Global System of Mobile (GSM) and Short Message Service (SMS) technology is a common feature with all mobile network service providers. Utilization of SMS technology has become popular because Utilization of SMS technology is an inexpensive, convenient and accessible way of transferring and receiving data with high reliability. The proposed tracking system consists of: inThe GPS Receiver. The users of this application can monitor the location graphically on Google Earth. The proposed tracking system can be used to monitor various parameters related to safety, emergency services and engine stall. The first module is the tracking device which is attached to the moving automobile. This module composes of a GPS receiver, Microcontroller and GSM Modem The GPS Receiver receives the location information from satellites in the form of latitude and longitude real time reading. FLOWCHART:"
"Implementation of this table top wet grinder required following hardware as normal table top wet grinders, current sensor, viscosity sensor, temperature sensor, micro controller, control valves, water spray, tilted motor, vessel which attach at bottom, funnel for storing grains such as lentil grams(urad dal), rice etc. At first rice and lentil grams (urad dal) is to be sock in water for 2 hours. After that first rice and lentil grams (urad dal) should be loaded to the separate respective funnel type storage container. At every separate funnel container exit valve is present. At first solenoid valve in rice containing funnel get opened. Previous process is to spray water to empty drum of grinder. Then rice gets released in drum. The motor get start to run. First the current sensor check the current and if the current level is exceed the standard value then the water pump start to spray water to drum by simultaneously checking the viscosity using viscosity sensor. Check the time by using the 555 timer. If the time is greater than or equals to standard time then the time goes to stop mode. After that the exit valve at bottom of drum got released and the rice flour which is grinded is stored in the vessel which is attached at bottom of grinder for storing purpose. After that the exit valve at bottom of drum got closed and the solenoid valve of the lentil gram (urad dal) funnel container get open. Then little amount of water is sprayed in drum. Then the lentils grams (urad dal) get poured into drum by solenoid valve. Then the lentils grams (urad dal) get grinded into fine particle. fine particle senses the current by current sensor and if the current value is greater or equals to the standard value then the water spray pump get open. fine particle sprays water to the rice flour which is grinded to avoid the jamming of flour in drum. Viscosity sensors sense the viscosity of flour simultaneously with current sensors. After grinding the lentil gram, the rice flour which is grinded got poured into the same vessel which is attached at the bottom of vessel. After the grinding process some of flour in drum got drained by the tilted mechanism. Now drum is tilted to certain angel. Fin type structure with up and down motion gets inserted into to the inverted grinder. Now the inverted grinder start to rotate and the fin structure begin to move up and down. So the rest of the rice flour which is grinded in drum got taken by the tilted mechanism. Our proposal involves the tilted mechanism too. So now water is sprayed very fast and the flour which gets clogged in drum is removed. Now place the inverted grinder close to wash sink. Now taken out the solenoid valve and put the solenoid valve into sink. Now the water which is used to clean drum gets disposed to sink via solenoid valve. Now it takes it own time to dry drum. Now the salt and ready made yeast is mixed with flour in collecting vessel at bottom of drum by using the fin type structure."
Our device name sis snake bot because of Our movement like snake. Our is an bio-inspired project. Snake is the animal which can travel to any surface. Snake can move horizontally as well as vertically which will help as well to climb any surface. Similarly we are trying to make a device which can help Snake to climb any surface. The whole movement of the device is fully inspired from snake either the device is a rectilinear motion or the device is serpentine motion. Our project can be divided into two main parts:1. Motion part2. Live tracking part The motion part consist of the motion with which it will be able to climb any surface. Our main motive is to achieve the motion like snake which can help it to move on any surface. for this Our have designed the 3d part which can help this move like a snake. this will consists of different part which help to connect servo motors to servo motors for servo motors movement. Each 3d part will be connect with servo motrs for Each 3d part movements. The servo helps Each 3d part to acheve the motion of snake. Each servo motor will be controlled by microcontroller which help to control the motion of snake. Motion is the main part of the device which will give Motion’s a ability to go on any surface..The second part of the system is regarding the ability of live tracking of the situation. The device will be equipped with IR camera which will help to track the situation in real time. The rescue team can see the whole video live which will help The rescue team to track that whether anyone has been left or not. It will help The rescue team to save more and more life. We are also using GSM module for sending the video live to the user and minimize the delay.All the function of The device can be easily controlled by the user remotely using remote controller which will help All the function of the device for efficient tracking of the environment.The above is the picture of project on which we are working and it will look more beautiful after completion.
"The mine detecting robot works in dual mode, which means that, the robot can be controlled in both manual mode and automatic mode. This is the distinguishing factor while compared to the other kind of robots, as the most of the bots work in manual mode. the robot is programmed within the embedded chip and the robot makes the robot to act as human beings. the robot is mainly defined by the factor named Artificial Intelligence. The second distinguishing factor from the other robots is that, the robot is capable of sensing humans, who are trapped inside the coal mines. This is done with the help of sensor (PIR) which help in detecting obstacles. The fig. I block diagram gives an idea of how the robot works. the robot shows how the system circuit works and how the current flow goes through the system circuit. The wireless communication used is Bluetooth which helps in transferring the data and messages. In the proposed system, the system circuit can be implemented with the help of a block diagram which includes the sensors, modules of Bluetooth, camera, buzzer unit and the power supply. These devices are interfaced with the help of Arduino microcontroller. All of These devices are directly connected to the Arduino micro-controller which have All of these sensors own default program according to All of these sensors use.Flow Chart:The above block diagram shows the working process of the robot. If the hazardous gas is detected by the MQ-3 sensor, they send the message to the Arduino micro-controller .The Arduino Micro-controller give the command LCD for displaying the temperature and indicate gas leakage through the Buzzer."
"Living standards in rural areas can be significantly improved by promoting a shift from direct combustion of biomass fuels (dung, crop residues, and fuelwood) or coal in inefficient and polluting stoves to clean, efficient liquid or gaseous fuels and electricity. Although consumers tend to shift to thesemodern, higher-quality energy carriers as theirincomes rise and the carriers become more affordable, the process is slow. Yet a shift to such carriers can reduce the damage to human health and the drudgery associated with continued reliance on inefficient, polluting solid fuels. Economic benefits will achieved as a result of improved energy services for rural livelihoods.Basically if there is availability of proper energy in villages than education system will also infused. Agriculture can have a major role in supporting rural livelihoods and community development through provision of locally sourced biomass energy.Improved rural energy services contributes to international development goals, including poverty reduction, better access to water and sanitation and protection of the natural environment.For poor rural people to escape from poverty, poor rural people must be able to improve poor rural people livelihoods in ways that can cope with, and recover, from stresses and shocks, while maintaining and enhancing poor rural people material and social assets and opportunities, both now and in the future, and while not undermining the natural resource base.One element of this sustainable rural livelihoods approach is to have better access to basic and facilitating infrastructure, and energy is a key component of this infrastructure. Improved energy services can assist more broadly in rural development as well as in food security.Now a days technologies are developing so far and under this project with help of these technologies we are going to work on GREEN ENERGY , NANO AND MICRO GRADE MANAGEMENT , this project prospects for improving the technologies used to cook with biomass as well as the development of clean, non-toxic cooking fuels. Progress in rural electrification—using both centralized , grid-based approaches and small-scale, decentralized technologies—is also described and thorough this project we want to implement TEG sensor effect use in gas chullahs to generate electricity .One of the aims of this project is to explore the technological ,economic, social, and institutional prospects for more rapidly introducing modern energy carriers using IOT and artificial intelligence into rural areas—which would allow households to move quickly to the top of the energy ladder, ideally skipping (leapfrogging) some of the energy ladder rungs. Accelerating the introduction of modern energy, then, is a key strategy for promoting sustainable development in rural areas."
"When there is a landslide, there would be a total internal reflection of the IR lights in the optical wire extended over the landslide area. The two IR sensors attached at the two ends of the optical fiber would detect the change in IR light. With the help of the microcontroller, the sensor would trigger the buzzer to sound an alarm in the landslide area. the sensor would use a GSM module to send a message or automate a call to the registered users as a warning.The system consists of an optical fiber, sensors, Microcontroller, Buzzer and GSM.Optical Fiber: The optical fibers are popular due to The system flexibility, small size and The system ability to exhibit total internal reflection. The system are transparent strands of very pure glass and have a core surrounded by a cladding layer made of dielectric material. The light that enters from one end of the optical wire, undergo total internal reflection and is received at the other end of The light that enters from one end of the optical wire. (Optical Fiber, n.d.)IR Sensors: An IR sensor has two parts the transmitter and the receiver. The transmitter transmits an infrared light, which will travel through the optical fiber, and the receiver receives that infrared light and will generate an electrical signal to be transmitted to the microcontroller to be processed. Microcontroller:For testing purposes, the Arduino UNO R3 would be used to process the signal received from An IR sensor. The signal after being processed will trigger the alarm and the GSM module. In the real application, cheaper microcontroller would be used. Buzzer:the microcontroller would power Buzzer to sound when The signal after being processed is received. The buzzer/ aarm would cover only the area where the system is installed to warn the incoming drivers or people walking by.GSM: the microcontroller would also send a text message to the registered SIM cards by using a GSM module.Future plans:All the features mentioned above would be launched in the first version. In the following versions, an app would be designed which will have a “marked safe” feature which will make use of IoT to store the data of each registered customer and notify the necessary individuals whenever landslides occur to check if the person is safe."
"In this system, there are three phases –1. Detection of Waste – For the detection of waste, the camera is installed in the systemso that user can easily monitor the location of waste. The output screen is built in theremote controller that is used to control this system in every possible direction.2. Extraction of Waste – waste is then carried to this system by usingconveyor belt fixed with the net that will segregate the waste and water.3. Collection of waste – waste is then traveled to the external net that isadded at the back of this system, so that there is no effect of the weight on this system.Additional Features:1. Battery indicator will indicate when the battery is exhausted.MODEL VIEWFLOW CHART"
"Since this device is for disaster management purpose so this device will be stationed in the potentially risky lakes. And from that the device would be capable of extract the data such as location, the predictions on the disaster time at an average and the warning and its possible early precautions to be taken. The data collected will also be received by the service provider, where this data will analyze to learn about the different possible combination for different situation. For this purpose a range of knowledge should achieved about the disaster faced earlier and should be analyzed by an expert.The data collected is initially stored in the cloud which is passed down to the algorithm for Data Analysis and the decision is been made and the decision is then displayed in the application with the possible predictions for the near future.Data Analysis.Using multiple algorithms The data collected is evaluated and through the concept of probability The data collected analysed.Level Measuring device (for the station)Disaster monitoring headquarters (for service provider).Storage of data.There needs to be a large storage system for this design and also the data authenticity should be taken into consideration. The data collected is directly interfaced to a storage syatem through the internet.The data collected by the devices will send through the IoT module from various sensors. Where The data collected by the devices will be send to the authorized service provider where The data collected by the devices is analyzed using algorithms and experts working on The data collected by the devices probable predictions.The data collected by the devices will also be stored for the service provider for them to research on the water level’s abnormal behavior for disaster management studied. Because there are statements by the observers during disaster The data collected by the devices will be the key to cracking multiple risks originating substantial proof. Also the data acquired by Level Measuring device (for the station)Disaster monitoring headquarters (for service provider).Storage of data will also be sold to the researcher’s organization who also research on the rise in levels and other fields.Constraint at which product may fail.Physical damage at product station.If the devices backup system fails.Level Measuring device (for the station)Disaster monitoring headquarters (for service provider).Storage of data getting rugged over time.Since Level Measuring device (for the station)Disaster monitoring headquarters (for service provider).Storage of data’s a sensor, there is no grantee for Level Measuring device (for the station)Disaster monitoring headquarters (for service provider).Storage of data life span with optimal operation"
"The website or app has four main sections-RegistrationMedication CheckContact Online pharmacyRegistration- Initially the user must register into the system through The website or app. the user can register the user as either a doctor or as a patient. The users registered as a doctor will be appointed to the patients and have a dashboard where the patients can request an appointment with the patients-online or offline. If the user is registered as a patient, the patient must fill in the patient medical profile which will include all the patient allergies, current medications, etc. Medication Check- In this section the symptoms and problems will be asked for. The patient can also enter the medicine they are currently using or are asked to use. Using the medical profile and based on symptoms, the medicine accuracy will be provided and the alternative medicines will be listed out. this section will also provide seriousness of the patient based on the symptoms. the system can also be added with a feature of machine learning in which the future problems of the patient based on the symptoms can be predicted based on the patient based on the symptoms current behavior and lifestyle.Contact- The emergency contacts of the patient based on the symptoms will be provided which will include a column where the patient based on the symptoms can provide the patient based on the symptoms person doctor’s contact and the patient based on the symptoms family’s contact. In case a patient does not have a doctor already, the app can suggest doctors that have registered into Med Check. For the case of emergencies, we could also add a ‘Call Nearest Doctor’ option where the nearest available doctor will be contacted.Online Pharmacy- Through this section, medicines can be sent to the patients directly. This will be useful for the people who use rare medicines, live far away from the pharmacies, those who aren’t in the state to travel, etc."
"For real life implementation of the project we will build a refrigeration type of vending machine which will have food articles arranged inside it.How the food gets in there?That’s are first step which involves the local residents of that particular area where the machine is placed. We can have 2 machines within an area of 10km.The local residentthere?That’s database is created using their phone numbers. ’s database can be a collective record for various members of family or ’s database could also be individuals record. So, when a person puts food into the unit (which has certain dos and don’ts) the points are added to the unit (which has certain dos and don’ts) registered phone number.So, this is how our reward-based system comes into action. our approach certain brands initially and our give promotional articles or small tokens of appreciation to certain brands after the particular person owing the record has crossed a fixed number of points. This kind of a process encourages more customers to contribute towards the betterment of the society.The second step involves the consumerist. All the people who actually need our reward-based system should register All the people who actually need this system with the administrator of our reward-based system, also unregistered members too can use our reward-based system.Consider a person comes to pick food from our unit. First a person has to scan a person fingerprint. Then our reward-based system will check if a person has accessed the machine twice already in that day or know, if no access will be granted. Also, the fingerprint scanning system will be linked with the Aadhar (similar created) database. If the fingerprint scanning system’s a child or youth between the age 5 to 20 then the machine will display a video clip for a minute a will let the food item be out. If the same person comes to access the machine for second time during the month then a question will pop up regarding the same person comes to access the machine for second time during the month. the same person comes to access the machine for second time during the month’s not a hard and fast system but tries to impart basic information at a micro level.Flow Chart:"
"The Robot is fixed with a camera and kept The Robot some edges of water. The Robot detects the plastic through that camera and large amount of plastic is collected through the net by The Robot. the plastic is dumped into the trash bin which is arranged at the sea shore. When the trash bin is filled ,the message will be sent to the municipal corporation to collect the plastic. the plastic can be done by camera through artificial intelligence .The The Robot is fixed using robotics technology .The robot is trained to collect the plastic through artificial intelligence and machine learning. The total data is stored using the cloud .The message to the municipal corporation will be sent using Internet of things ."
"Generally, we thought to use this technique on all animals but It’s possible only when government collaborates with our project and that can be happen when our make this first implement on pets. This is not only for pet animals for all animals our just have choose a word pet that doesn’t mean only pets. When our talk about marketing, the person who loves their pet surely buys this because their don’t want their pet getting hurt. And the other side of our project is separating waste and plastic that is done an efficient ROBOT which is trained and tested how it must be separate the plastic from waste. When our discuss about marketing many stakeholders form a queue for this kind of robot which separates plastic from other things. Product design is"
"The architecture diagram of the Agrobot application. The user inputs the query in the user interface in the form of text or the can be send to get relevant response. The query can be in any language. The user interface receives the user queries and then forwards The user interface to the Agrobot application. In the Agrobot application, the textual query undergoes a pre-processing stage. Preprocessing steps include Tokenization where the query sentence is tokenized into words, then the stop words are removed, and then the stop words are stemmed to their root words. If the query is classification based, the query would undergo classification using the neural network classifier, which uses the knowledge base to retrieve the relevant responses. If the query is prediction based, the query would undergo prediction process using the ARIMA algorithm, which uses the CSV file containing the legacy data. The appropriate responses will be provided to the user in the form of text and also the textual response would be converted into speech and provided to the user.System Architecture3.4 MethodologyThe Methodology contains the detailed description of each and every module of agrobot.Text Processing The user queries are tokenized into words using the bags of words technique, and the stop words (like is, the) are removed using NLTK Corpus. The stemming process is performed to convert the words to their root words. For example, Cultivation, Cultivated, cultivate all stem into cultivate which is the root word as shown below.Text ProcessingChatbot Development and TrainingThe dataset file containing hundreds of agricultural queries and hundreds of agricultural queries corresponding responses are imported. Text ProcessingChatbot Development and TrainingThe dataset file is then processed and converted into vectored format. The Bot is trained, by building a neural network and the error values are optimized. The trained data is saved in a data structure for future usage as shown below. Development and TrainingResponse Retrieval using Machine LearningThe neural network classification is used to construct a model using Text ProcessingChatbot Development and TrainingThe dataset file. Using a model constructed probabilities is generated for Text ProcessingChatbot Development and TrainingThe dataset file. The least probabilities are filtered out using the threshold value and sorted in descending order. The highest probability is looped through to obtain the corresponding response as shown below. Response RetrievalImage processingThe given as the input get processed and then the corresponding response as shown below is given by the bot in the textual form. Example – of the crop with pest is given as the input then bot will give detail description of pest.Speech SynthesisThe textual output generated is passed through Speech Synthesis API. Speech Synthesis API gets text input and converts Speech Synthesis API into speech and provides Speech Synthesis API as output. Speech SynthesisThe textual output is heard through the speaker as shown belowSpeech SynthesisMulti LingualThis Chatbot supports multilinguality. Farmer can chat in any preferred language. Future PredictionThe ARIMA prediction algorithm is used to predict the future price of the agriculture related products. The input query undergoes the preprocessing stage where the query is preprocessed. Text ProcessingChatbot Development and TrainingThe dataset file is split into training dataset and test dataset. The ARIMA model is constructed using Text ProcessingChatbot Development and TrainingThe dataset file. Using The ARIMA model, the test dataset values are forecasted. Speech SynthesisThe textual output is passed to the graphical template and graphical responses are generated as shown belowFuture Prediction"
"The aim of this project is to cut down the manual labor in a warehouse. This will achieve by automating a warehouse. For automation in warehouse most important is getting order from anywhere for that website will be used. In this website user first find items which they want and add to cart user can see only those which are available in warehouse then after all checks all checks can place order. After placing order site also generates bill at same time. Once order is successfully placed after all checks and order orders and bills will send to administrator PC via Internet then order will update on database and data is transferred to controller via Wi-Fi. The system consists of multiple conveyor belt, which help items to reach counter from The system original place in minimum amount of time. A conveyor belt is attached in such a way that when item is push off the rack then conveyor belt pick that item, for pushing mechanism rack and pinion arrangement will be used to push items from rack. And with the help of pushing mechanism(rack and pinion, motor) and conveyor belt item will reach counter without any human involvement, both conveyor belt and pushing mechanism get command form controller whenever an order is placed by customer then both conveyor belt and pushing mechanism start working and when all items reach counter an order automatically stops. When all item reach counter then an order will be packed manually with pre-calculated bill. Main Block Diagram - Block Diagram For Data Flow - Flow Chart - Proposed Structure -"
"Overview: The Society or a particular area will collect and segregated the plastic before collection and can give us notification through the application. Then us collector will collect the plastic from that society or society can visit the distribution center and can donate the plastic. After that, our collector will transport the plastic to the distribution center. At the distribution center, the plastic is once again segregated as recyclable and non-recyclable plastic. After that, recyclable plastic will be transported to industries like textile, consumer goods, building, and construction, etc and non-recyclable plastic will be transported to the research centers, and the research centers will research the effective ways of recycling the plastic. After that, the society will receive the reward based on the society donation.Rewards: The rewards will be in the form of virtual coins on the application where the individual user can collect by donating plastic. Once the individual user collects a certain amount of these virtual coins, the individual user are entitled to purchase a variety of items within the app. the individual user can even pay the individual user bills using the coins within the app.Moto: The main idea behind this venture is to create public awareness of the non-biodegradable waste that is affecting our environment by giving them rewards for the same. Rewards on every donation will increase the no. of public participation and also the amount of plastic in the environment will deteriorate on an exponential rate."
"The IMPLEMENTATION of our project is there is one data processing centre which collect the information through cloud and the information is transfer to information system regional database and which is futher transfer to traffic control server local database which is linked to traffic police station and linked to all area traffic signals and roads. traffic control server local database which is linked to traffic police station and linked to all area traffic signals and roads used advanced communication systems based on sensors and servers to collect data and provide the information to system on current situation on the roads. The smart system will processes the information and make the decision that is we will automatically determine the duration of each traffic lights . Use of technology in traffic management is a known thing. However ,it is the use of data from different sources in real time and processing information to take immediate decision that is the key to a successful traffic management in our cities. It is the need of the hour to leverage enormous amount of data around us and create a more meaningful and smooth living for us. meaningful and smooth living for us."
"The health monitoring is depending on two methods such as direct contact (invasive) or in indirect contact (non invasive). Basically a prototype telemonitoring system consists of sensing unit and receiving unit with ESP-32, which is an highly integrated with in-built antenna switches. Implementation of this model is based on the above flowchartAfter turning ON the device further steps will be followed :- Step 1 : Gathering data from all the sensors namely:· Heart Rate Sensor:The variation in heart rate normally reflects stress, anticipation, movement, exertion and various diseases.· Temperature Sensors:Typically, core body temperature is higher than ambient temperature to ensure that heat generated by metabolism flows out of the environment. Deviation outside of this range which is relatively narrow leads to increase in resting metabolism, modifications to the biochemistry and cellular physiology as well as the behaviour of the animal. · Temperature Humidity sensor:The environmental parameters are affected by the performance and health of the animal both directly and indirectly. It is used to measure temperature humidity index(THI) and also analyses stress level of animals.· Biosensing device:It attaches to ears to measure the body temperature of animals. · Biosensing device is also used for antibiotic detection.ESP-32 : All the data gathered by the sensors would be transferred to · Biosensing device.Step 2 :The formation of database will take place with the help of ESP-32. database will be helpful in keeping a check on animals.Step 3 :database will be checked with optimal parameters and if any parameter is abnormal than the optimal value then inform the concerned authority with notification message. Otherwise, constantly checking of data is taking place.Step 4 :The data stored is displayed on the screen for monitoring the system."
"Data Gathering:Pipeline: The nature of pipeline and the length of the line is the first important dataset required. The topological data about the pipelines is collected as The topological data about the pipelines will affect the waterflow and the map of distribution is to be collected for getting data of change in direction of pipes.Waterflow rates: Every area gets water daily for fixed amount of time. water has different flow rates and pressure in different pipes. The cross section of pipe and the power of pump is the main thing to be considered to calculate water flow rate.Purity value: The turbidity of water is checked at the beginning of each branch of the supplyline so as to maintain the purity above a given threshold at all times.Supply and Demand details: The population density and industrial development affect the supply and demand of a region. We will predict the data about the supply and demand for coming time to provide datasets for our algorithm. Installing Hardware:According to the data collected about the data flow and nature of pipes checkpoints can be determined. Hardware-Hardware- will use Arduino Uno as microcontroller. The system will be wireless hence a GSM module can be used to connect to internet and export data to the cloud database. Arduino Uno will be shared by two-three checkpoints depending on the distance of the checkpoints obtained by previous step.Now at every checkpoint there will be a pressure sensor(or a waterflow sensor) and a turbidity sensor embedded into the pipe. The amount of water flowed will be calculated by the sensors and the data will be sent to Arduino Uno and hence to the database.The turbidity sensor is attached at start of new branch only.The supply line will contain some solenoid valves which will be connected to arduino and will be controlled by The system. Training the Model- On the basis of the independent variables like topology of terrain, purity of water, water flow rate, supply and demand of the region a model will be trained. a model can also accept the optimum running system data and set a preset for all the forthcoming instances. Now for all new instances The system will compare The system with the actual optimal running system to fine if there are anomalies in The system. a model will help find any anomalies like cracks in The system when a bad data is obtained. Crack and purity detection- As soon as a crack is detected on difference in waterflow data the solenoid valve of the affected area are shut off so that water is lost through cracks until cracks are treated. If the purity sensor detects decrease in purity then an alert to the authorities is generated so as to take necessary measures. Finding the deviation and reallocation:Whenever a crack is detected by the algorithm The system configures the solenoid valves according to the water flowed through the pipes. Now the main objective of The system is reallocating the water flowed through the pipes with respect to the loss of water due to cracks in pipe. The percentage loss occurred due to cracks will be calculated and The percentage loss will be divided between all the regions. The percentage loss will be divided on the basis of demand and supply of the region. Consider a situation where a loss of 2% of the total water supplied is occured due to crack in some pipe. Now in every region a supply cut of 2% will be done according to supply, thus making the fair consumption of water and equal loss of water to all regions."
"Since this device is for animal monitoring purpose so this device will be attached to the animal. And from that this device would be capable of extract the data such as location, Heart rate, blood pressure and the abnormal rhythm of the heart. Then the data such as location, Heart rate, blood pressure and the abnormal rhythm of the heart will be send to a concern individual’s mobile device in which this device will have the access to an application where this app is capable of analyzing the data provided and derive meaning information about the animal where the data such as location, Heart rate, blood pressure and the abnormal rhythm of the heart are extracted about this app health. Also the data collected will also be received by the service provider, where the data such as location, Heart rate, blood pressure and the abnormal rhythm of the heart will analyze to learn about the different body reaction with the behavior at different situation. For this purpose a range of knowledge should achieved about the animal behavior from a experienced animal behaviorist The whole working of the system is divided into three parts.1. the data such as location, Heart rate, blood pressure and the abnormal rhythm of the heart Extraction.2. the data such as location, Heart rate, blood pressure and the abnormal rhythm of the heart. i. Animal health status (for the owner). ii. Animal behavior (by service provider).3. Storage of data.the data such as location, Heart rate, blood pressure and the abnormal rhythm of the heart will send through the IoT module from various sensors such as heart rate, blood pressure and others. Where the data such as location, Heart rate, blood pressure and the abnormal rhythm of the heart will be send to the authorized mobile application through wireless means of communication. The ECG sensor will extract the data from the heart activity where we can also determine the blood pressure and body temperature. The ECG sensor is also capable of determining the abnormal rhythm of the heart.In the mobile application the data such as location, Heart rate, blood pressure and the abnormal rhythm of the heart will be received to be analyzed to present the animal health status of the individual animal, in very user friendly manner with help of graphs and records, with feedback to the owner on what to do next, also the normal conditions will also be provide so that the owner heart rate and other parameter can be compared with the normal body parameter data predefined so that proper tips to be done can be presented to the app user. Since most of the vets basically check the body temperature, heart rate and respiratory functional of an animal to check whether an animal is ill or not. So the app will display these important aspects.the data such as location, Heart rate, blood pressure and the abnormal rhythm of the heart will also be stored for the service provider for them to research on the animal behavior for disaster management studied. Because there are statements by the observers during disaster that animal tends to behave odd before disaster hit’s that spot. Also the data acquired by the device will also be sold to the researcher’s organization who also research on animal behaviors and other fields.The flow chart below express how the system would work."
We will be taking inputs in the form of real time videos from a camera module .Processing the videos to detect any intruder in the crop field. As soon as any intruders are detected in the crop field a siren is activated to scare away the intruder and a message is sent to the landlord in case the intruder is't scared .The process can be well understood by the following flowchart :The algorithms that we are using is based on YOLO Object detection and DarkFlow and python as a the current framework.is't scared .The process involves the following sub-processes Video ProcessingRecognitionAlarm ActivationVideo ProcessingThe input that we have got from the camera module is processed by the algorithm and algorithm searches for any object present in the frame .If the object is present in the database the algorithm and algorithm searches returns the tag associated with the object say an ID. Recognition In recognition phase an ID returned is mapped with the possible options available in the database to determine what exactly is detected and makes a decision that whether Alarm needs to be triggered or not.Alarm ActivationIf the value returned from the recognition phase is true than all the alarms are triggered and a message is sent to the user . Alarm is turned off as soon as the object moves out of the frame .
"First we have to get input for the RF transmitter or GSM module from the switch, alcohol/smoke detector, cell phone detector using these we can start the process. At receiver end we have atmega microcontroller which controls the engine power supply that means start and stop ignition depends upon transmitter signal. using all these we can create an interface between vehicle and helmet so that if the person wears the helmet then only the engine start off.we have also attached air cooler in the helmet which starts when the transmitter emits the signal.we haven’t used any sensors which affects the brain of the person. Next one is post accident idea in which our stakeholders are emergency vehicle here our first get the location of emergency vehicle and then stimulate the signal according to the location of the emergency vehicle. our also intimate the other vehicle which is going on the same lane. our can do this by two method by using RF transmitter and receiver and second one isby using google maps interface. our can also implement automated speed breaker so that emergency vehicle can go without any disturbance but at the same time our can also control emergency vehicle by implementing the speed breaker again. For this speed breaker we are using hydraulics suspension which produces electricity. This electricity can be used to operate hydraulics suspension or the street light near the speed breakers."
"1) Fully automated system thus reduces the human labor. 2) As we are making a fully autonomous robot which works on open architecture principle and done lot of work in farms so it reduces human labor. 3) Saves time. 4) As we are using machines which works faster than human efforts which definitely saves the time. 5) More Accuracy. 6) The system observes different environmental conditions and take actions accordingly which humans can’t do accurately. 7) Low Cost. 8) We are using sensors and drivers for making this system which are easily available in market and cheap which reduces the cost of system. The system is open architecture so any one can make this type of system using any way or path. The system uses processing to observe the leaf color which increases further accuracy of The system as The system identifies color very accurately than human. The system also observes different environmental conditions such as humidity, soil moisture and temperature which human cannot measure accurately by open eyes to decide the plant health so the accuracy of The system is high. The system also involves watering mechanism and cutting process which reduces human labor and we can reduce labor further by modifying The system further for other agricultural work such as picking, harvesting, weeding."
The system is an application which uses augmented reality to display 3D anatomical structure whenever the “target ” is kept in front of the camera.the “target ” is stored in database generated by Vuforia which is an integrated module of Unity 3D and used for storing target s that can be scanned in real-time in an application whenever pointed by the smart device. A virtual structure will be displayed over the “target ” in real time. A virtual structure are the object files created via Autodesk Maya and both the target and A virtual structure is linked with each other via Unity 3D which further helps us in development of the application.
"Our system ""Smart Garden"" is basically bifurcated into two main parts which consists of Rain water Harvesting and Supply/Usage of stored water in different ways. Our system ""Smart Garden"" can be of much use in the urban as well as in the rural areas where there are many gardens. 1. Rain water harvesting is done using Catchment Area :Catchment Area -Firstly the rain water needs to be collected in some area in which we can store Catchment Area for long term in order to harvest Catchment Area. So when Catchment Area rains, the rain water passes through Catchment Area and inside of the storage area, where the rain water is stored. the rain water can be used for multiple ways which are described below. 2.Usage :Automatic Plant Watering System -The automatic plant watering system consists of Soil moisture sensor which is used to detect the moisture present in the soil and depending on the presence of moisture the controller decides whether the plants require water or not. If the moisture present in the plants is deficient then the plants are watered with the help of pump through which the rain water is passed. 3.Features:Leakage Detection -The water storage tank consists of Leakage detection system which helps us to determine whether there is any leakage in the tank or the pipes through which the rain water is supplied with the help of the sensor and if there is any leakage then the sensor will alert the connected user about the current situation."
The main aim of this project is to convert the voice by mobile phone and print the text in braille. This requires Bluetooth module connected to the Arduino for printing the text in braille and formed dot matrix formation to print the braille according to the coding process. The methodology to implement voice to braille is modularized into four modules: · 1. Speech to Text conversion · 2. Sending Text through Bluetooth to Arduino · 3. Text to Braille conversion · 4. Formation of dot matrix (A) Speech to Text Conversion · This module takes voice from the user through mobile phone and converts the user into text using the app and the app can also give feedback at the same time before sending it.(B) Sending Text through Bluetooth to Arduino · Now Text to Braille is further sent through the app to the Bluetooth module which is connected to the Arduino. (C) Text to Braille to Braille conversion · Text to Braille is now get processed through Arduino according to the coding and converted into braille. (D) Formation of dot matrix · Now the converted braille is printed on the paper in dot form and in matrix formation.Figure 1. Block Diagram3D-Diagram:Figure 2. Printer Layout (with roller and slider) Figure 4. Header Layout (with Mini servo)Circuit Diagram: Figure 5. Circuit Diagram Flow Chart: Figure 6. Functional Diagram
"The process of the system can be classified into 2 phases. 1. Detection of gunshot[8]2. Calibration of the direction of the shot.[8]For the detection of a particular sound, the frequency of the source is analyzed and studied. And according to which a bandpass filter is designed. For instance, the central frequency of a finger-snap lies at nearly 3 kilohertz so a bandpass filter with cut off frequencies fL =2.5kHz and fH=3.5kHz can be designed for detecting snap sound. The circuit is shown in figure 1.The detection circuit consist of the following stages:1) 2nd order low pass filter2) 2nd order high pass filter3) Non-Inverting Amplifier with a gain of 1004) Non-Inverting Amplifier with a gain of between 2.5 to 55) Peak detector6) Comparator circuit with 1.5V offsetFigure 1: Finger Snap Detection CircuitThe frequency spectrum of the finger-snap and gunshot is shown in the figure below. Figure 2: Frequency SpectrumThe circuit gives response better for sounds with impulse nature i.e., sound having high amplitude for a short duration of time. For instance finger-snap, gunshot, and firecrackers, etc.For the calibration of direction, it can be assumed that the sound source is very far away in comparison to the distance between microphones. Then simple trigonometry can be used to determine the angle of from the center of the microphone pair. This is described below.Figure 3: Arrangement of microphones and the sound source[5]CalculationSpeed of sound, v = 331.3 + (0.606*T) metre per secondHere ‘T’ is the temperature in Celsius Consider the figure 3 sinθ = (delay*sound speed)/mic distance θ = sin-1(delay *speed of sound)/ mic distance θ = sin-1 ((𝜏 * v)/d)After that, the angle from the center of microphones can be calculated as π – θ in radians.Figure 3: Two microphone angle model [8]The delay(𝜏) between the time of arrival (TOA) of the acoustic signal at two microphones can be calculated with the help of the timers of the microcontroller.Figure 4: Block diagram of the systemThe data from the device will be uploaded to the cloud for analyzation. This is required because sometimes noise may also lie in the frequency bandwidth and trigger false alarm causing a waste of resources and time. the systemThe data will be analyzed first by the server. If the server gets agree that the sound detected is indeed gunshot then the sound detected is indeed gunshot then will be analyzed by the admin. After confirmation from the admin, the shot area will be shown in an android application.Figure 4: Flow chart of the systemThe 3D model of the project is shown in figure 4. The “green spheres” are the microphones and filter circuit, preamplifier circuit, microcontroller is shown protected inside a square block of grey color. The height of the device is given with the help of a tripod. Figure 5: 3D Model of the device"
"Working: Our remotely operated underwater vehicle (ROV) will have an aluminium chassis which will help Our in buoyancy under water.Thrusters will be placed in the bot to help the bot flow underwater according to different control algorithms. Light,camera and manipulators will be in the bot direct the bot underwater. Light components will be placed in the front and heavy components will be placed in the back this will give us a boost in stability underwater. This diagram represents the outer layer or basic working of the project. Image Recognition: We’re going to use Opencv 3.2.0 for real time recognition. This will help We to differentiate plastic from the other marine substances. The feed received by the camera installed will be refined by Opencv 3.2.0 and plastic will be detected through the camera installed. As the plastic is detected by the bot will send an alert about the coordinates of the bot location using a GPS module. The feed of the camera installed will be shown on the laptop connected with Opencv 3.2.0. Accuracy: YOLO is an extremely fast real time multi object detection algorithm. YOLO is an extremely fast real time multi object detection algorithm.The use of YOLO( You Only Look Once) will help us to train the bot to different occurrences of plastic and increase the bot efficiency using deep learning. YOLO divides the given input into m*m grids and comes up with bounding boxes, which are boxes drawn around s and predicted probabilities for each of these regions, this will help the system to get more accurate results. Flowchart:"
"The implementation would involve the making of a proto-type model which would be dome shaped. Made by a frame work of hollow steel, on which polycarbonate sheet (12mm) will be cladded onto with 360 Degree firing loop &amp polypropylene paint applied over it. The Internal cladding of the plywood sheet along with a layer of filling in between is required."
"We start by acquiring sample raw materials i.e., vegetable or fruit peels. The primary source of We raw material are food industries and local juice shops. We shall be collecting the raw material daily since it is perishable. We will process the raw material by drying and powdering them the material that is going to be produced shall completely degrade on the material that is going to be produced own within a few months, which is ideal for packaging and making carry bags that are biodegradable. We will convert the raw material into granules. Using granules as base material We shall now test different resins to find the combination with desired qualities. After producing the compound with desired qualities, We shall do a large-scale production of it. the compound will be the raw material for the production of We biodegradable sheets. our biodegradable sheets can be used directly by the packaging industries or structured to suit our biodegradable sheets needs. The product can also be used to make carry bags and other single-use products which are then transported to retailers and eventually to the general public.The product will have to have an ideal degradation time i.e. not too short that The product cannot be used and not too long as The product generates a lot of waste that will be hard to deal with. The product however, will degrade naturally requiring little to no efforts in disposing The product off. The product will therefore save time and money spent in waste management methods apart from being environment friendly."
"Block diagram:Left Leg Electronic Slipper The pressure created in human while standing is needed to monitor for predicting the arrival of back pain the best way is to measure the weight applied using an electronic pair of slippers. Leg Electronic Slipper observes the pressure and evaluates using a load and pressure sensor and sent the data using Bluetooth Enabled aurdino@mega328.Right Leg Electronic Slipper Leg Electronic Slipper also designed to measure the pressure applied using a load and pressure sensor and using the aurdino@mega328 receives the data from left leg controller synchronize both the data and transmits to Mobile App to predict the arrival of back pain and leg pain.Ergonomic Sitting PadThis Ergonomic sitting Pad is used to calculate the time duration of user sitting and indicate Ergonomic Sitting PadThis Ergonomic sitting Pad to Mobile Application. Ergonomic Sitting PadThis Ergonomic sitting Pad has two to four Pressure sensor, two load cell and aurdino@mega328. This sitting pad can be synchronized to slippers if needed for monitoring both sitting and sending time based on need of the user.Pure Spine Process Flow Diagram:Working: Pure Spines have an Intelligent Electronic pair of Slippers and Sitting Pad for Monitoring and Predicting the Arrival of Back Pain in Human through Mobile Application using IOT Technology. By measuring the weight (pressure created by humans) using a pressure sensor and load sensor the stress level is monitored and the controller receives the data from the sensor unit then sends the details to Mobile application using Bluetooth controller [6]. The mobile application processes the data and predicts the arrival of back pain and leg pain and sends the notification message in the Mobile display.Atomic unit: Our idea is to predict the arrival of back pain, which can be determined by time period of sitting and standing. It is based on the choice of the stakeholders. For example: For drivers, the back ache is designated by the sitting pads and for pregnant women the back ache is determined by slippers Unit of Pressure: The SI unit of pressure is pascal (Pa) and is terminated as a force of one Newton per square meter.Unit of weight: The SI unit of weight is the kilogram (Kg).Unit of Time: The SI unit of time is the second. The second can be denoted as s or sec.Hence we conclude our atomic unit as, (Pascal/kg)*secProduct User Persona:"
"Implementation: Core Technical Innovation here is to bring advance technology at present like Artificial Intelligence, voice and gesture recognition. The Morse code is used for the blind and deaf to transmit and interpret the messages and SOS helps the disabled in emergency to contact the help line by a single tap on the Autobot. Uniqueness of product design is COMPACT DESIGN, flexible to move around and carry things (medium weight) on product design. These tasks are performed either by voice, gesture recognition making gesture recognition more efficient to use with great ease. The bot also consists of Morse CODE converter and SOS feature. Objective: The bot is basically designed after the problems faced by physically challenged people. The disabled instruct the bot by voice or gesture to perform the task like follow, move left, right, backward and forward. For deaf-blind people it has Morse CODE converter, where it allows such people to understand, what the other person wants to convey and reply back. SOS is an added feature, when the button on The bot is pressed, The bot calls the nearest possible emergency service.Block Diagram of the proposed design:Ø Microcontroller has inbuilt Bluetooth and wifi module which can be connected to cloud where processing and AI is done. Inputs to Ø Microcontroller are:Ø Camera: is used for processing for tracking the objects and object recognition.Ø Proximity sensor: proximity sensor is used for obstacle avoidance during the motion of the Autobot.Ø Voice recognition module: It detects the voice of the disabled and performs accordingly to the disabled instructions. For example, stop, follow, move right etc. Ø Gesture recognition module: It performs the instructions given by the physically challenged through gesture movements.Following Processing takes place:Ø Motor driver: It is used to drive the Autobot from one place to another, which contains four wheels associated with It.Ø SOS: It helps the disabled to contact the helplines in emergency situations by a single tap on the Autobot. the Autobot sends the message to the nearby helplines with the GPS location of the disabled.Ø MORSE CODE Interface: It is used for the blind and deaf people to communicate through the morse code. Which transmits the signals in the form of dots and dashes. The disabled receive the message through the vibrations.Ø Servo Motor control unit (BOOST-DRV871): Ø Servo Motor control unit (BOOST-DRV871) is used to drive the servo motor and helps in movement of the robotic arm.Ø Robotic arm controller unit: Ø Servo Motor control unit (BOOST-DRV871) picks and moves the objects from one place to another.Working Microcontroller takes the input from the mentioned input modules and transmits the information to Cloud. Cloud processes the data received and sends back the commands to MCU as to how to control the peripherals. Working Microcontroller, then controls the peripherals as per the instructions."
"As we did research about different techniques to feeding fertilizers farmers has need of a product which can work in any climate conditions.It should be hands free .We required general information i.e. distance between two crops, soil fertility rate. Feeder will work on rechargeble battery. Once we have charged Feeder we can take Feeder to the fields where fertilizers gets feed. Firstly we have to insert general information like distance between crop , amount of fertilizers should be feed. Feeder will have wheels for motion or moving forward towards next crop. For motion of feeder we can use various types of motors e.g. BLDC , DC, servo motor etc. Feeder will have sensors for detection of crop. Until sensing a crop feeder will move forward. If it sense crop then it will stop at that position. A metallic funnel will work as a fertilizer feeder. Metallic funnel is mounted on a pneumatic arm. pneumatic arm will move towards crop land. For motion of pneumatic arm we can use pneumatic system which helps to applying force for insertion of funnel into soil. In pneumatic system we can use actuators for motion of arm or mounted metallic funnel.We can use double acting cylinder. It can use for motion of arm towards soil and returning back. Metallic funnel contains proper amount of fertilizer It has a pointed tip which helps in digging or helps for inserting metallic funnel into soil. As metallic funnel has a pointed tip It helps to insertion of metallic funnel into soil easily. Metallic funnel has a flap which gets open when funnel gets inserted into soil.As funnel is hollow from inside funnel is hollow contains fertilizers in proper amount fertilizers gets inserted into soil when flap gets open. These technique is also used for sowing of seeds. These technique will sow of seed by same distance between each seed. feeder has a sprayer which will be used for the purpose of spreading pesticides on the crops. pesticides contains poisonous ingredients. We can use grass cutter for cutting grass near to crop. As We can use another pneumatic arm which has a ultrasonic sensor which cuts all grass near to crop. ultrasonic sensor is used for detection of crop which should not be cut. As the fertilizer gets feed to crop. It will move towards. It will moving towards until another crop is not gets sensed.We have an information about distance between two crops but for more accuracy position sensor is required. As following above steps more accuracy position sensor will feed fertilizers properly to every crop. For next row of crops if we give proper information about next row distance it will go to next row by using ultrasonic sensors for obstacle detection. For this actions We will use controllers like Rasberry pi 3, Arduino controllers.Rasberry pi 3, Arduino controllers are having wifi modules by accessing data connection we can send data to cloud or website . Which are accessible for customer.Camera will be mounted on feeder which can send or streamed live video of feeding. For these purpose We will use IP cameras .They has a static IP. There are various type of IP cameras e.g.HIKVISION , CPPLUS etc. We can use cam module to making We IP camera by using Ardumini cam , ESP32 cam etc. By using Arduino IDE or raspbian software we can make a program to make these IP cameras on a public server or wifi IP. Hence we can stream live video of feeding. For streaming video we have to enter IP address of cameras in address bar. These will helps to farmers to accessing from remote locations."
"· Underwater ROVs can be used for various purposes, be it as basic as fishing, to new discoveries of aquatic species or cleansing of water beds or even to monitor a particular area.· Our project however can be used for all of these.· Our project can be divided in various steps each of which would focus on a particular part of Our project.· The most important part of Our project is “Thrusters”. Thrusters and propellers help Our project to traverse in the water.· The weight of the ROV needs to be properly balanced to avoid toppling of the ROV. · For the ROV to move, Thrusters and propellers are used which are controlled by a motor.· The camera setup in Our project is for monitoring purposes. The camera is interfaced through NodeMCU. The footage from camera will be displayed on IOT enabled device.· In the front of the structure, torches will be placed to illuminate the surroundings of the ROV.· The motor in the structure will be controlled by Motor driver module which can in turn be controlled by a remote by the user."
"Implementation : For our platform our are providing two interface, first one is client interface which includes citizen and second is server interface which includes authorizes user such as BMC working department. 1) Client interface: for first time, user must have to fill basic information such as name, contact number, etc for verification purpose. Later on, to register a complain user need to upload the of pothole and fill the information such as nearby landmark, exact location or they can also take help of goggle map. 2) Server interface: the complain form citizen are gets uploaded to portal of authorizes user such as BMC working department. Where, the complain form citizen can observe the pothole issue and pervious report on that pothole problem. A authorized person for particular mahanagar palika will be allowed to view the complain of particular area and under particular area there may also have sub areas so in UI we providing different section where each section contain number of complain from same or nearby subarea. There is another feature where, due to language barrier if authorised user is not able to understand the complain information then we can translate the complain information into another user preferable language. Hence, with the help of these BMC can attend issues/problem of pothole and start implementing work on that pothole problem.Flowchart:"
"The ATMEGA 2560 microcontroller 54 digital I/O ports , 16 analog inputs(hardware serial ports), USB connection and 16 MHz crystal oscillator, power jack, and reset button. In this design I/O ports , 16 analog inputs(hardware serial ports), USB connection and 16 MHz crystal oscillator, power jack, and reset button are using motor driver which drives the shaft motor by coupling with battery bank. As motor starts rotating this vehicle starts moving. Seed storage tank is coupled at finest of module nearby wheels[5]. When vehicle starts moving confer to modification, vehicle concede precise seed to drop into the hoper is no wastage of seeds and sowing trial goes evenly. It is a module used to control the speed and direction of motors synchronously. It is two-directional driver which controls current at 5v to 64v"
"In this application, we are going to use a feasible and user-friendly solution for people stuck in flood. we will use the Jetson nano AI board for running deep learning models on the Boat itself. the Boat itself will work autonomously so that the Boat itself will take the Boat itself decisions. 8 MP camera will be used for capturing live s. By using processing 8 MP camera will detect persons affected by a flood. we will use the GPS module for location tracking of a boat if the Boat itself is stuck. we will take the help of Google Map for the direction of the road and other signs, it is helpful when there are obstacles like pillars of electricity and houses. When a person will detect through camera then the Boat itself will reach a person and will rescue a person. For changing directions we will control the Boat itself with the help of servo motors. There will be one operator to operate all the functionality. It is helpful because It will rescue people with the help of technology and people will not be scared about It and It will be guaranteed rescue system. Identifying groups of victims is necessary so as to better predict the assistance to bring. For such a complex task, several subtasks are defined: To detect people. we approach is based on Histogram of Gradients (HOG) to extract Regions of Interests (RoI). To evaluate the composition of the group (adults, children). To estimate the direction of a group, and the direction of a group velocity. the direction of a group requires to be able to focus on a given person of a group in order to follow it for a while in order to estimate it destination by tracking and prediction. To do so, we couple a HOG detector with a Rao – Blackwelissed particle filter. Basically, a Rao – Blackwelissed particle filter estimates a posterior probability density over the state space conditioned on the data previously collected. Thus, a Rao – Blackwelissed particle filter is focused on the person to follow, and the command-control of the drone is adapted so as to focus on the particle filter of the selected person. This module consists of a WI-FI and is accountable for the communication between the application and the server. If communication between the server and application is not established, live streaming will be constrained from travelling from the server. This module consists of a camera. a camera sends live video streaming of the affected area and helps locate the victim’s exact location. a camera also captures the s of the affected area and send data for further processing.Flowchart:-Function will be like flowchart of rescue drone.Block diagram-"
"Implementation We will use several data sets [3-5] taken from somewhere in Timor Leste ,South Africa.S.Nienaber , M.J.Booysen , R.S.Kroon •Total no. of s – 48,913•Camera Used – 12 MP GoPro CameraAutonomous Road Potholes Detection on video•Camera Used – GoPro Camera•Resolution – 3680 X 2760 in JPG formatSystem design after literature survey, we implement the Simulation of proposed processing algorithms and this is completed then Deployment of software and testing on Raspberry Pi on the secondary database using CNN (Convolutional Neural Network) algorithm. in this, Image segmentation and feature extractions and other several part we working on. And then finally, Prototype Testing in real environment and necessary modifications. Classification with artificial neural networks is a very popular approach to solve pattern recognition problems. One of the essential components leading to these results has been a special kind of neural network called a Convolutional Neural Network (CNN). The main advantage of CNN is it automatically detects the important features without any human supervision. a CNN model can be thought as a combination of two components: feature extraction part and the classification part. The convolution and pooling layers perform feature extraction while the fully connected layer performs the task. The first layer of convolution will try to detect edges and form template for edge detection. Then subsequent layers will try to combine subsequent layers into simpler shapes. The basic concept behind convolutional layers is filter or kernel. It refers to an operator applied to the entirety of the such that It transforms the information encoded in the pixels then convolutional with the input volume to obtain a feature.Methodology:Pre-Processing: Filtering , Image enhancementSegmentation: ThresholdFeature Extraction: Texture feature Mean, S.D., Skewness, KurtosisClassification : SVM , KNN , CNN and for pothole detection K-means Clustering classifier will be used"
"The system will be initially deployed in electric cars developed by our college students who participate in National level electric vehicle competitions. Based on the feedbacks, our will improve the performance of our if any. After this our will customize The system according to Electric vehicle manufacturers.Challenges faced in scalability of this system.1. How is The system better than existing system?Solution: Existing systems incorporate parallel flow with straight tubes. The system incorporates cross flow with corrugated tubes (which increased contact area up to 200%) with variable flow rate which will improve the heat transfer characteristics. 2. How can Our manage the additional area to be incorporated in design to fit this battery system?Solution: Area required for this kind of batteries will be greater than existing one. So, Optimization of the design to incorporate the new battery system with very little modification is needed. Retrofitting the newer battery system with older one will also be possible by creating local modification of an automotive."
"The online platform can be split into 3 phases in-order. A student can jump to the second or third phase if A student/A student is able to score well in the Initial Assessment.Initial Assessment: Once a student signs-up, an initial assessment will be conducted to understand the current knowledge level of A student. The test will be on general aptitude, topics in general aptitude field of engineering, general coding and verbal english. Based on general aptitude score in The test, the various phases in The online platform will be unlocked.The Learning Phase: The first step a student has to do is to explore the various domains. The intro lecture of each domain will introduce the students to what the domain is all about and what the students will learn throughout the series of lectures on that domain. the students will choose the domains the students like and start learning.Learning Resources: The resources provided in The online platform will not be entirely made by us. us will evaluate several online resources available under a particular domain and will give references to the best and easy to understand free resources available online. If in case there are no good beginner friendly resources available for a particular domain, us will provide us own custom made contents.Evaluation: The evaluation of a student’s progress in each domain is done by frequent interactive activities, quizzes and assignments. Motivational Elements: A digital portfolio of each student will be generated by our platform showing all the progress the student has made in The online platform. A digital portfolio of each student can download our platform showing all the progress the student has made in the platform or share our platform showing all the progress the student has made in the platform’s link to anyone if required. Level based digital badges will also be provided to the students where the level increases as the student progresses in a domain.Discussion Forum: There will be a discussion forum under each lecture where the students can ask the students doubts which can be resolved by either the peer learners or the Subject Matter Experts.Mentors for Personal Motivation: Each student will be assigned a mentor under each domain who will be a Subject Matter Expert. the student can ask any doubt to a mentor under each domain who will be a Subject Matter Expert. If in case the student does not make any progress in some period of time, a mentor under each domain who will be a Subject Matter Expert will contact the student to enquire about the issue and try to resolve the issue if possible to continue learning.Showcasing: During the learning process, if the students do small projects that can be displayed to the public, we encourage the students to do so and the evaluation will be done on the public platform. For example, software projects can be uploaded on GitHub and the videos of hardware based projects can be uploaded on YouTube. This way, we will be able to evaluate them even better - not only on them technical skills, but also them presentation skills.The Innovation Phase: On reaching a certain level in the learning phase, the entry test for The Innovation Phase will be open. the entry test for the innovation phase will be based on all the topics that the student has covered on the public platform. Once the student passes the entry test for the innovation phase, This way enter The Innovation Phase. In The Innovation Phase, students are encouraged to form teams, brainstorm on innovative ideas or solutions to existing problems. Some existing problems will be uploaded on the public platform either by us or by other organizations to which the students can team-up and submit ideas to. We encourage students to participate in The Innovation Phase as The Innovation Phase will help the students to develop the students communication and presentation skills. These skills are really required whether you are working in an organization or starting your own. It will also be a platform to bring up more entrepreneurs and create a wider start-up ecosystem.Problem Statements : There will be some problem statements either uploaded by us or by other organizations. There may also be references to problem statements uploaded elsewhere which the students can try to solve.Team Formation: Students can give request to other students to form a team if other students like other students portfolio and feel that other students will be a good add to a team. A team can have 3-6 members.Mentors: Each team will be provided with a mentor who will be good at both technical and other professional skills. The mentor will help you throughout your journey and will help you with your idea proposals, idea implementation and presentation and will provide constant feedback and make sure that all team members are participating.Idea Proposal Submission: your idea proposals, idea implementation and presentation can be submitted (even for ideas that don’t have a problem statement). The evaluators will judge the idea proposal and select the idea proposal if The evaluators feel is good. If it is for a problem statement from any other platform, selection and further process will depend on that specific case.Implementation: The Career Phase is where the teams implement the projects the teams proposed. The mentors who are Subject Matter Experts will help in completing the project successfully. Presentation: The Career Phase is where the teams present the projects they proposed. The mentors who are Subject Matter Experts will evaluate teams and guide teams to make teams presentations better. Showcasing the projects on public platforms are encouraged here also. The Career Phase: The entry test to the career stage will be more like the initial assessment. This will help in evaluating the overall professional growth the student has made. The Career Phase is the huge leap from a learner to a professional.Job and Internship Opportunities: We will tie-up with organizations and will bring Job and Internship Opportunities recruitment drives to this platform similar to how to Job and Internship Opportunities come for campus hiring. Depending on the score of the entry test to The Career Phase, or the tests of the companies, companies will invite you for interviews if companies like your overall portfolio.Starting a Start-up: If the student feels like the want to start a start-up or want to continue developing companies idea in innovation stage even further, we will connect companies with mentors from the start-up ecosystem to help companies progress with companies organization."
"The Sea bin can be deployed anywhere there is the need of plastic removal from the water bodies. The Sea bin will stay afloat in the water bodies &amp removing the plastics. The basic principle behind The Sea bin is “Suction” ,the Pump integrated in The Sea bin uses the power of suction and sucks all the plastic waste that is flowing or is still around The Sea bin.Multiple Bins can be deployed at a time if the frequency of plastic waste is more ,Thus getting the Oceans, Rivers &amp Water bodies free of all plastic waste hence reducing the threats posed by the plastics to both the the Humans &amp the marine life &amp animals.The main problem we face now a days are the increasing amounts of plastic waste in the water bodies which ultimately leads its way to the oceans by one way or the another . This may not seem that big of a problem at first glance but the effects this is having are turning to be a huge problem for the nature as well as humans &amp the marine life. Hence there comes a need for getting the oceans free from the plastics.We unknowingly intake micro-plastics weighing a credit card every week , the main sources of the plastics are the water we drink and the fish we eat. It is estimated that untill 2050 there will be more plastics in the sea than there are fishes . These plastic also create a great threat to the animals and fishes as These plastic intake These plastic without knowing that these are not eatable else These plastic get These plastic entangled in the plastics posing a threat to These plastic lives.These ""Sea Bins"" can be set wherever there is need and are really easy to be set up with no need of any modifications or tinkering with anything. These suck water in, thus trapping all the plastics in These suck water in and sending a notification once full , saving the environment of these harmfull things and saving lives of the fishes,corals,&amp humans too."
The following are the main sub-parts of the project1 - To provide cheap and affordable dustbins to people who decide to recycle domestic waste at home. Each Dustbin will come with a QR code which will help us to provide credits to the user. Here credits will be in terms of Cash or special benefits in various recreational platforms.2 -The Dustbin which we will be providing will be fully automatic and can hold waste of up to a week. Each Dustbin will automatically help in producing fertilizers which can be used by the user or else will be bought by us in terms of credits as mentioned above.3 - As waste is segregated at home level itself a major task has been accomplished. Now there will be two separate vehicles for collecting the waste. Each Dustbin will have sensors interfaced which will help us in detecting if Each Dustbin is full or not. Each Dustbin will visit only the places where Each Dustbin is full. A shortest route from the source to destination will be mapped and Each Dustbin will only visit those areas.4 - The Dry waste collected from the city will be processed and made into fertilizers. Hence the cycle of Recycling Domestic waste is complete.
"Increased solar panel efficiency: When solar panel is 90 degree to sun to achieve 100 percent efficiency and charge battery faster. We are achieving it by programing to deflect it towards the direction of the sun with respect to voltage. Here We can remove the solar panel and used in various places like street lamps, solar power plants, etc.Battery discharge time: We are including a component called power booster to increase the time of discharge.Cutting blades: We are using laser cutting blades to reduce the damage to both grass on its cute edge and other objects goes under blades.Border wires: We are using sensors to find the borders of the lawn so that the present environment is not disturbed.Bagging: The blades used will cuts the grass into small chip which is used as fertilizer for the grass itself so no bagging required.IoT: The lawnmower will be made future-ready by configuring The lawnmower to work via using a dedicated application and also can be configured to be controlled over the internet with the addition of certain modules and programming. Life of grass: After mowing, further growing of grass will be almost even because cutting of the grass will be more precised."
"The weight of a footstep on floor-tile makes a horizontal flywheel inside The weight of a footstep on floor-tile rotate as shown in fig-1. If more number of pedestrian’s hits on floor-tile then more electricity can be obtained by spinning of flywheel. Every pedestrian that passes over a floor-tile generates around seven watts in energy.Every time someone hit or a step over a Floor-tile, renewable energy is harvested from the footstep around seven watts of electricity per hour can generate with this floor-tiles. a Floor-tile, renewable energy can be stored in batteries, or used to various power applications as shown in fig-2. One footstep is enough to generate the amount of off-grid energy needed to light an LED light bulb for approximately 20 seconds The proposed process of design, fabricating and testing of the Floor-tiles Prototype and overview of the major activities to be done to complete this floor-tiles is shown in fig-3.Step1: Conceptualization of Floor-tilesThe idea of harvesting wasted kinetic energy of person was very useful for renewable energy a system is activated and converts the harvested kinetic energy to electrical energy. Step2: Design of the Floor-tiles"
"The LPC-2148 saves the incoming data from the sensors mentioned above in separate variables and provides an appropriate delay to separate variables based on the calculation delay requirement of the particular sensor. Then the physiological readings from sensors are transmitted to web-server using the ESP8266 Wi-Fi transmitter which is connected to LPC-2148 port. The web-server receives the data and check The web-server with the threshold value for the registered patient.If the parameters are within threshold the data is stored displayed on website, otherwise an e-mail along with the link of live video-feed will be sent to Doctor/caretaker’s account and a SMS will be sent as offline alert. the data is first analyzed for the threshold before getting saved to reduce the response time of notification."
"The block diagram consist of the following components. The block diagram consist of the following components are soil moisturesensor, Arduino Uno , servo motor, L293D motor driver and DC motor pump. And thediagram is as shown in below figure.In this implementation ,two sensors are used which interface with the Arduino Uno fortwo output results each having high and low comparisions. two sensors are done with thehelp of servo motor , L293D motor driver and DC motor pump. And let’s see how theyall work each other for this implementation.The Arduino Board is programmed using the Arduino IDE software. The function ofthe moisture sensor is to sense the level of moisture in the soil. The motor/water pumpsupplies water to the plants. This project uses Arduino Uno to controls the motor. Follow the schematic to connect the Arduino to the motor driver, and the driver to thewater pump. the motor can be driven by 230volt. The moisture sensor measures thelevel of moisture in the soil and sends the signal to the Arduino if watering is required.The motor/water pump supplies water to the plants until the desired moisture level isreached. In this smart irrigation technique, two sensors are used which interface with the Arduino.The function of sensor is to sense the level of moisture in the soil .Depending upon the threshold values , motor will be switched ON which provides required amount of water to theplants . This process can be monitored from any where for the above process the flow chart is shown below :"
"The video camera will live capture the video and input the video to model in the raspi. There is a raspberry pi for the individual signal which will handle the video processing and sending the real-time car values to the database. There will be 4 raspberry pi for a junction which consists of four signals. 4 raspberry pi will do the same functioning as mentioned above. There will also be one more raspi that will retrieve the latest values of the vehicles from the individual signals and input those values to the algorithm which will compute the appropriate time for respective signals. All the emergency vehicles like Ambulances, Fire Brigades. Etc. will have a special radio frequency transmitter which we detect by the receiver situated on the signal. This will be a sign that an emergency vehicle is approaching the signal. This information is uploaded to the database which in turn is fed into the algorithm for calculating the time needed for an emergency vehicle to pass the signal. As soon as an emergency vehicle is detected at a particular signal that information will be notified to the neighboring signal which will be used to calculate the required time before an emergency vehicle arrives. This reduces the time of calculation of signal timer. All the signals are connected with each other, i.e All the signals can share information between each other for smooth and smart functioning of the signals. In tolls, there will be a camera installed with the raspi connected to it. a camera installed with the raspi connected to it will be placed where a camera installed with the raspi connected to it can clearly capture the photo of the number plate of the car. Then the photo of the number plate of the car will be processed and the number of the car is extracted from the and then the car gets matched with the database which consists of the vehicle information. By retrieving the information we send an e-ticket for the toll which the owner can pay in a specified time using online payment services."
"a) Fire Sensor LM35: "a) Fire Sensor LM35 is accuracy IC temperature sensor. Yield upgraded by coordinating couple of new advances with voltage of "a) Fire Sensor LM35 is straightforwardly relative to the Centigrade/Celsius of temperature. "a) Fire Sensor LM35 does not require outside alignment or trimming to give precise temperature extend. "a) Fire Sensor LM35 is minimal effort sensor. "a) Fire Sensor LM35 has low yield impedance and straight yield. The working temperature run for "a) Fire Sensor LM35 is −55 ̊ to +150 ̊C. With ascend in temperature, the yield voltage of the sensor increments straigthtly and the estimation of voltage is given to the microcontroller which is duplicated by the transformation factor keeping in mind the end goal to give the estimation of genuine temperature. b) Moisture sensor: Soil dampness sensor measures the water content in soil. Moisture sensor: Soil dampness sensor measures the water content in soil utilizes the property of the electrical resistance of the dirt. The relationship among the deliberate property and soil dampness is adjusted and Moisture sensor: Soil dampness sensor measures the water content in soil might differ contingent upon ecological factors, for example, temperature, soil sort, or electric conductivity. Here, Moisture sensor: Soil dampness sensor measures the water content in soil is utilized to detect the dampness in field and exchange Moisture sensor: Soil dampness sensor measures the water content in soil to microcontroller keeping in mind the end goal to make controlling move of exchanging water pump ON/OFF. c) Humidity sensor: The DHT11 is a fundamental, minimal effort advanced temperature and stickiness sensor. The DHT11 gives out advanced esteem and henceforth there is no compelling reason to utilize transformation calculation at ADC of the microcontroller and thus we can give the microcontroller yield straightforwardly to information stick rather than ADC. the microcontroller has a capacitive sensor for measuring moistness. The main genuine inadequacy of a capacitive sensor for measuring moistness is that one can just get new information from a capacitive sensor for measuring moistness simply after like clockwork. d) Ultra-Sonic sensor: a capacitive sensor for measuring moistness works on the guideline of sound waves and their appearance property. a capacitive sensor for measuring moistness has two sections ultra-sonic transmitter and ultra-sonic collector. Transmitter transmits the 40 KHz sound wave and recipient gets the reflected 40 KHz wave and on a capacitive sensor for measuring moistness gathering, a capacitive sensor for measuring moistness sends the electrical flag to the microcontroller. The speed of sound in air is as of now known. Thus from time required to get back the transmitted sound wave, the separation of deterrent is ascertained. Here, the separation of deterrent is utilized for impediment recognition if there should arise an occurrence of portable robot and as a movement indicator in product house for avoiding robberies. a capacitive sensor for measuring moistness empowers the robot to identify and evade impediments and furthermore to quantify the separation from the deterrent. The scope of operation of ultra-sonic sensor is 10 cm to 30 cm. e) Raspbian Operating System: Raspbian working framework is the free and open source working framework which Debian based and enhanced for Raspberry Pi. e) Raspbian Operating System gives the essential arrangement of projects and utilities for working Raspberry Pi. e) Raspbian Operating System accompanies around 35,000 bundles which are pre- ordered programming's that are packaged in a decent configuration for hustle free establishment on Raspberry Pi. e) Raspbian Operating System has great group of engineers which runs the exchange shapes and gives answers for some applicable issues."
"Problem Weather prediction using articial intelligence in this topic we are going to design prediction software which can predict the weather. The major problems that are facing by the farmers are weather conditions. Format doesn't know how the weather changes in a year so that the farmers are cultivating crops without knowing weather rainfall is heavy or not and the former going to face a major loss while cultivating the crops to avoid this problem we are designed a new articial intelligence predicting application which can predict the rainfall and weather in that year and months. With this application former can cultivate the crops based on weather forecasting so that farmer can take predictions from this application former this application former not only give the weather report this application former also give the information what type of crop that farmer has to to cultivate in the year and also what are the things that farmer has to take for example fertilizers etc. this application former also gives the information how to sell this yield. Using Artificial intelligence, we can if Artificial intelligence know the temperature before a month then can easily work without fear. The prototype is developed by using Artificial intelligence. The prototype collects all the data from the previous years and compares The prototype with the help of classier. The sampling process takes place in the classier after the study of data collected. In sampling the training and testing processes takes place which is done for multiple samples for improving the accuracy of the prediction. The sampling process is preceded by pre-processing unit which complies in the predicted weather that is being faced by the farmer. The pre-processor gives the data to the classier and The pre-processor compares with the thresholds based on heavy, medium and normal weather conditions. The output of the classier gives the accurate and reliable prediction of the weather in the near future. Using which the farmer can be benefited to know the future weather and choose the best suitable crop to yield in the future weather.FLOW CHART:"
"We use a software application that displays the level of water flow measured through the flowmeter. the flowmeter also provides the current rate of water flow in Liters/ hour format . The water flow sensor will detect the amount of water used by the consumer and The water flow sensor the consumer will load the data to the server after every interval of time .Then this data from the server can be loaded into a software using MIT app inventor .On the bases of the usage We will provide the E_Bill The user can easily see the amount of water that has been consumed by a single outlet or consumer. There can be a daily limit on water usage which when breached, The user can be warned and asked to reduce his/ her water usage. If The user doesnt comply he/her can be subjected to action and water flow to the household can be cutshort. This feature is one of the future improvements for the project. Flowchart:- CALCULATIONS:In order to measure the quantity of water being passed in particular time through The water flow sensor The water flow sensor was first passed through the water flow sensor which was taken as input interface in the flow. Formulas are applied in order to measure the number of rotations/pulses in a minute of rotation.Flow rate can be determined inferentially by different techniques like change in velocity or kinetic energy. Here we have determined flow rate by change in velocity of water. Velocity depends on the pressure that forces the through pipelines. As the pipe’s cross-sectional area is known and remains constant, the average velocity is an indication of the flow rate. The basis relationship for determining the liquid’s flow rate in such cases is Q=VxA, where Q is flow rate/total flow of water through the pipe, V is average velocity of the flow and A is the cross-sectional area of the pipe (viscosity, density and the friction of the liquid in contact with the pipe also influence the flow rate of water).Pulse frequency (Hz) = 7.5Q, Q is flow rate in Litres/minuteFlow Rate (Litres/hour) = (Pulse frequency x 60 min) / 7.5QIn other words:Sensor Frequency (Hz) = 7.5 * Q (Liters/min)Litres = Q * time elapsed (seconds) / 60 (seconds/minute)Litres = (Frequency (Pulses/second) / 7.5) * time elapsed (seconds) / 60Litres = Pulses / (7.5 * 60)Usage = flow frequency / 450(literes) BLOCK DIAGRAM:-"
"At first the forest is under surveillance of the monitoring module. the monitoring module is to detect the fire in the forest using zigbee module. The fire sensor is placed at the input. As the fire in the deep forest is caught the zigbee module with the help of UNO module the data is stored in the monitoring module. the fire is caught the zigbee module with the help of UNO module the data is stored in the module uses low power consumption limits transmission distances to 10–100 meters line-of-sight, depending on power output and environmental characteristics. The data of catching fire in forest is detected by the monitoring module and then transmitted with the wi-fi transmission line of the suitable range. The transmission is done to 2 modules of wi-fi 2,4y with 5 GHz. the data is transmitted to the nearby station and buzzer is functioned by the transmitted signal with the monitoring moduleUNO ."
"· Obstacle detection :When the IR Transmitter emits IR rays, the IR Transmitter hits to obstacle and reflects back, When the IR Transmitter emits IR rays are received by IR Receiver1. The IR Receiver1 in the car receives the IR radiations and through the ARM the car is stopped. · Destination :Whenthe person selects the destination by switching on Destination 1 or Destination 2 the car starts moving and reaches the destination. the IR Transmitter placed in the destination emits IR radiations continuously. The IR Receiver 2 in the car receives the IR radiations and through the ARM the car is stopped.· Traffic signal : the IR Transmitter is placed in theTraffic signal. When the car moves through a signal, in case if theTraffic signal is RED then the RF Receiver in the car receives theTraffic signal and stops the car. In case of green signal the car starts moving.· Fuel indication: For fuel indication LDR sensor is used i.e,fuel indication LDR sensor senses the light and led glows to indicate fuel is less. In all the above parameters the information is sent to the user in the form of messages through the GSM module which is connected to the ARM, those messages are displayed in LCD module for local updates. At the user side, the mobile phone is installed with start-up to GMAIL app which is freely available in GOOGLE store.The messages which are received are made to sync with the email link which is created by the user.Through this the caris connected to the internet."
"User Journey MapInternet Of Things (IOT): By using IOT technology pulse rate (heart rate) of a person, which is taken as parameter, gets continuously monitored by means of smart band (build up using Arduino) for the cardiac healthiness of Arduino owner.· Arduino automation using Bluetooth: By this, the users get to control the electronic device using the users Windows PC where a centralized database will be used by both the Android and Web Application. · Machine Learning: Whenever an emergency situation arises like heart attack or cardiac arrest (including Tachycardia), the heart rate value deviates from the heart rate value normal value, which gets detected by Machine Learning predictive analysis models on the acquired sample data sets.· Cloud Computing: After the report gets generated, if emergency conditions are detected, those information are shared to an integrated Emergency Medical Service (EMS) cloud based architecture that has been developed to allow authorized users to access emergency case information in standardized document form and select the most appropriate ambulance services for each case.· GPS: The ambulance then reaches the desired location as the system uses device GPS for GEO tagging. Flow Chart"
"In system architecture, the project team has used Arduino R3 version as Motherboard, including 16X2 LCD Display, Buzzer, LED (Red, Green, Blue), Heating Mechanism, Driver Circuit, Timer, Ultrasonic Sensor, Relay Module, AC Motor, and Power Supply. Arduino board contains a timer section used for controlling the switching time of the machine. LED Lights are used to display ON/OFF the machine and Mode of RUN/ERROR. The buzzer is used to indicate to inform the insert of seeds if in empty conditions. Ultrasonic Sensor is used to detect the distance from the seeds to Ultrasonic Sensor. AC Motor is used to rotate the rod used to grind the oil. Relay Module is used for switching AC Motor and Heating Mechanism. Heating Mechanism is used to remove the moisture from the seed. The auto-cleaning process is used to remove the waste or previously inserted seeds.When the user switches ON the machine, there will be display “Welcome” and after the machine will display “Insert the I/P”. After inserting the input, the controller checks the input and starts the heating system with a time delay of 5 to 10 secs or time required by the user. If the input is not inserted then the controller will ask to insert the input through The buzzer. After heating seeds will start extracting with help of rod rotated by AC Motor. And the oil will Extract as the output. The buzzer will beep for informing the user to insert the seed as input. the controller will check if a user had inserted or not. And if the user has not inserted any input then the heating element will go in OFF state and AC Motor will rotate anti-clockwise to remove the remaining waste material from rod rotated by AC Motor easily. And If the user has not inserted any input then The auto-cleaning process will run again."
The microcontroller is the heart of the system for which the Ardiuno IDE is cascaded. The flow sensors of water and water level sensor gives the data of water level and flow of storm water and storm water level at the places of low level areas where the systems are arranged. the system for which the Ardiuno IDE is cascaded continuously sends the data of drain water level and the system for which the Ardiuno IDE is cascaded flow rate to the concerned municipality department for prompt response to clear the drain if the flow rate less than the threshold level.
"The Model being described here uses Speech recognition and visualization. The voice command from the user is captured by the microphone. This Is then converted to machine readable code readable code is then Compared with the other previously defined commands inside the commands Configuration file. If it matches with any of the other previously defined commands inside the commands Configuration file, The command Associated with it will be executed. The Model being described here processes your commands via speech. This is achieved by using the speech recognition technique Which converts the text into speech. The bot is able to show visual s with the help of Image visualization .Speech recognition​: speech recognition is a computer software program or hardware device with the ability to decode the human voice​. ​Voice recognition is commonly used to operate a device, perform commands, or write without having to use a keyboard, mouse, or press any buttons.Speech recognition technique can analyze the sounds you make by filtering what you say, digitizing Speech recognition technique to a format Speech recognition technique can “read”, and then analyzing Speech recognition technique for meaning. Image visualization : Visualization is any technique for creating s, diagrams, or animations to communicate a message. Visualization through visual ry has been an effective way to communicate both abstract and concrete ideas since the dawn of humanity. Webot​ software is used to simulate the physical model of bot . Webot​ software is used to check the accuracy, physical response of The bot . HERE'S A BLOCK DIAGRAM SHOWING YOU THE BASIC WORKING OF THE VOICE RECOGNITION FOR RASPBERRY PI :"
"This machine is based on the principle of flow of air from area of high pressure to area of low pressure i.e. a vacuum suction pump. An electric motor is attached to a fan that spins An electric motor at high velocities. The fast spinning of fan creates a low pressure region inside the suction hose of the vacuum suction pump. After collection of the waste or garbage, it will be collected in compressing chamber where a hydraulic press will press the garbage or waste into compressed solid shapes and will dispose it in the ground from automatic sliding door downward. The electric motor and hydraulic press will be powered by a battery and infrared sensors will be mounted in the compression chamber to measure the garbage level in the compressor chamber. Device will also have solar panels mounted on the front of the chamber connected to the battery.This machine consists of three major operation- suction of garbage, collection of garbage and compression of garbage.Suction of garbage: Suction of garbage is based on the principle of vacuum suction pump. In Device a dc motor will be mounted on the chamber wall which will have an exhaust fan. DC motor (12 volts) will be powered with a battery. Fan will rotate at very high speed (3500-600 rpm) and will create low pressure zone in the chamber that will suck the garbage from high pressure zone i.e. roads or dumping ground. Suction power will be controlled by controlling the speed of motor using speed regulator.Collection of garbage: the garbage will be collected in the chamber that is separated from the compressor chamber with the help of a net. the compressor chamber will have a separate box in the lower portion of the chamber in which the garbage will be collected for the further operation. the compressor chamber will also consist of IR sensor which will detect the level of garbage in the compressor chamber.Compression of garbage: Compression of garbage will be achieved by the help of a hydraulic press. a hydraulic press will be made by using a bottle jack which will be manually operated by the user. a hydraulic press will apply the load of 5-7 tonnes. the user will operate the hydraulic bottle jack with the help of a lever, after compression a spring mechanism will make a hydraulic press come to initial position. After compression the garbage will be converted into small solid shape and will be removed by an opening in the compressor chamber later it can be easily stored or transported.User Interface: This device can be easily operated by any individual. User Interface will have a display panel on the top of the chamber which will have ON/OFF switch, garbage level indicator and a speed regulator. This device will have movable wheels at bottom so that This device can be easily moved from one place to another.Flowchart"
"Motion sensor will sense the motion of the train and as soon as the train starts the water sensor will detect the water on the railway track and the flap will get opened and the suction motors will start collecting the water from the sides. the water enters the water inlet and goes through a net which separates out the solid garbage from the water and put the solid garbage from the water into the trash can attached with the device. the water flows in with huge pressure as the train is moving. the water rotates the turbine and generates the electricity to start the pump for second filter. the water is pumped and entered into second filter where the water is treated for soluble and insoluble impurities. the water is then supplied to the tanks in the trains for use in toiletries and washbasins.The whole system can be divided into three modules as shown in fig. 1:1. Control Unit2. Water Collector Unit3. Recycling UnitControl Unit: The whole system is turned on as soon as the motion sensor will sense the motion of the train and the water flow sensor detects the water then the flap is opened and the suction motors start collecting the water which is being logged on the railway track. Flap and suction motors collects the water which is being logged on the railway track and that collected water is passed to the tank where the water which is being logged on the railway track can be stored.Water Collector Unit: As collected water enters the flap and suction motors through the pipe at a particular distance there is a net placed in the pipe which only allows the water which is being logged on the railway track to pass in the tank and the garbage like plastic rappers, bottles, paper and other waste which comes along with water that garbage is separated at the initial stage and collected in a tank.Recycling Unit: When garbage is separated then the water which is passed through, is filtered and stored in another tank. the water which is passed through can be recycled and reused in the washrooms of train. Filtration process is done by using charcoal, pebbles, sand and stones which forms layers and due to layers the water which is passed through is filtered which can be reused. Filtration process goes continuously till the water which is passed through is present in a tank.Fig. 1 Block Diagram of Railway Track Logged Water Collecting and Recycling DeviceFig. 2 System Flow of Railway Track Logged Water Collecting and Recycling Device"
"Now a days the present drainages are directly connected to the rivers due to this the rivers due to this are polluted and cause of the death of underwater animals, and also there no proper solution for collecting the wastages from the cities the wastages cause cities pollution and death of the abounded animals because also the wastage of the cities houses are through on the road and the hungry abounded animals, birds, eats it. Which leads to death then due not proper digestion. To avoid this type of problem our proposed system has better solution.our project is to keep city clean and clean river water by technical method and save the life of the abounded animal, birds …etc. our have to implement Our project one cities which are more polluted and also on our present drainages system. our divided Our project in to the 7 stages. 1. Filtering the waste from drainages using nets.2. Collecting the waste from the nets. 3. Dividing the waste in to sub parts like plastic waste, wood waste, and glass waste. 4. Chopping plastic waste. 5. Chlorination, Grass and Sand Filtering6. Consumption of water for agriculture purpose.7. Web Application. In technical method we have to take drain water into big drains. Atthe end of big drains, there is net to stop the waste from drainages using nets and the waste will be collected to our factory. Now this wastage will be separated in various types like plastics waste, wood waste, glass waste.it will be send to plastics waste, wood waste, glass waste.it respective factories, then this wastage will be recycled then this wastage will be reusable. Than after the drain water pass through our checkdams, than after our using grass filtration method than the drain water will be supply to villagers before, our use chlorination method. To provided pure water to villager. Beside the canal our making a small fruit garden and in fruit garden our place abounded animals(cow, ox) and then after by using the these animals dung our are make an organic fertilizers to is used in the agriculture field and the agriculture field save the our agricultural filed to change in the barren land. And in the canal our are also fish farming. And also our collecting the wastages from the cities by using our transport and sand to our waste separating factories. Now the plastic materials are send to our chopping factories to chop the plastics and use to making the roads. And also our collecting the burning gases form the drain water.our whole project is managed by the a web application"
"With the help of the proper hardware and software we can easily manage waste as a way of proper disposal. Implementing robots in cleaning can help the sanitation workers and can reduce manual scavenging. A robot developed with all this specification can serve as a way for proper and easier way for the management and disposal of wastes. Thus, in short it can serve as a way for faster and easier management and disposal of wastes."
"The solar sprayer is mainly used for spraying liquefied pesticides. The developed system can be used for spraying the fertilizer, fungicides. The developed system can also be used as automatic Spray Painting robot. The same technique and technology can also be extended for all types of power sprayers. This model can be also used as mosquito repellent. Reduces fuel consumptions and brings down running cost due to Solar Powered Working. The solar sprayer not only minimizes the drudgery of the work but is also more effective than the conventional ones. The solar sprayer prevents the Operator exposing from noxious chemicals and pesticides. The solar sprayer is good alternative for engine sprayer. The use will be most welcomed when the fuel resources are over. The use is noiseless, eco friendly and doesn’t produce vibration. The construction is simple and not as difficult as other sprayers. The construction is simple to use and easy to manufacture."
Trash blaster is a machine that can be used for garbage management. In this we will use crushed garbage waste. Through inlet crushed garbage waste will be transferred to the blast chamber by the help of connecting pipes. Inside the blast chamber the heating element is present which will be used to burn out the input material and is converted into the liquid form which will be deposited in the residue tank .The gases released will be transferred to the blast chamber through the blower.
"MATERIALS, SPECIFICATIONS AND PROCEDURE In plastic roads (composites of plastic with other materials) construction generally following materials are used- a. Aggregates- of size 20mm, 10mm and stone dust / lime as filler. b. Bitumen- for binder different grades of bitumen 60/70 or 80/100 can be opted. c. Plastic Waste(2 to 4 mm) in size - collected from various garbage dumps in the shredded form is used (PVC is not used because of the high toxicity) A. Plastic Waste Specifications Following types of plastic wastes can be used in rural road construction-, films of a. Hard foams polystyrene (PS) and Soft foams polypropylene (PP) and polyethylene (PE) of any thickness. b. Films of polystyrene (PS), polypropylene (PP) and polyethylene (PE) up to 60micron thickness. c. Laminated plastics (metal coated also) up to 60micron thickness. B. Process of Road Construction Using Plastic Waste B. Process of Road Construction includes following steps- a. Plastic Waste Collection: In first step, various plastic wastes as characterized in above specifications are collected from various sources. b. Segregation: Other wastes are separated out from the plastic waste collected from various garbage dumps in above first step. c. Cleaning and drying: the separated waste is cleaned properly and dried. d. Shredding: After segregation and cleaning-drying step the waste collected is broken and is graded into a size of 2.36 mm to 4.75 mm IS sieve with the help of a shredding machine. e. Heating Process: Before transferring to the mixing chamber the aggregate mix is heated to 165oC to 170oC and for preventing weak bonding the bitumen is heated up to the temperature of 160oC. f. Surface Coating: At the mixing chamber, the shredded plastic waste gets coated uniformly over the surface of the aggregates and shows an oily look within approximately one minute of time. g. Construction: The aggregates after mixing with the combined mixture of the plastic waste and the bitumen are used for laying the road between the temperature of 110oC to 120oC. C. Method of Mixing Dry process is preferred for isolated works. According to the recommendations of CRRI and Dr. Vasudevan the percentage of shredded plastic waste should be 8%, and 10% respectively. However, 8% can be adopted as the optimum plastic waste content for blending the bitumen for use in plastic road construction .Flow chartØ Plastic waste collection Ø Cleaning and drying of plastic waste Ø Shredding plastic waste into required size (2 to 4 mm)Ø Stone aggregate heated to around 140-1800 C Ø Shredded polymer waste is mixed with heating stone aggregate Ø Now aggregate is mixed with hot bitumen Ø Mixture is mixed properly Ø The mixed (composite) is known as waste plastic aggregate composite is used for road construction"
"The camera will provide live video feed to the control unit. the control unit will process the input with real time video processing and take action depending on the situation. the control unit will prioritise the road with maximum traffic or a road which has a stuck emergency vehicle. the control unit will change the traffic signal accordingly.Video Processing:-Real time video processing is used for determination of traffic. By using OpenCV we can create virtual boxes on road. There are at least three virtual box is created. If the vehicle enters into at least three virtual box The camera will detect at least three virtual box is filled . If all the boxes are filled The camera will detect there is traffic on that particular lane.(Basic representation of how system is implemented on each lane)Multipurpose cameras are used for video processing. each lane)Multipurpose cameras are specially made for the implementation of AI and used for the traffic detection. The camera will continuously check the lane provided in front of The camera, The conventionally used countdown based timer sequence will signal the roads and empty the lanes according to the timer based operation. The control will use real-time processing and process the captured from The camera. The control will generate three virtual rectangular frames in the view of The camera. system will detect traffic as the boxes are filled in by vehicles The camera will continuously check the virtual rectangles. If the virtual rectangles are empty then The control will conclude there's no traffic on that particular lane or road and will give a red signal to road. If there is more traffic on one road as compared to the adjacent or perpendicular roads then the vehicles on that road with the maximum traffic will be allowed to pass first till virtual rectangles two and three are emptied.Machine learning :-Machine learning can be referred to as an application of artificial intelligence which is used to train artificial intelligence to take data as input and process it based on how the AI or artificial intelligence is trainedHere we use machine learning to detect the emergency service vehicles. we train machine to detect the emergency service vehicles like ambulance ,fire brigade tanks etc. If an emergency vehicle is detected on a road then road will the given a green signal until the emergency service vehicle passes the junction. After the emergency service vehicle passes the junction, a green signal will continue to function normally where a green signal stopped."
"In this system, we get an input of the particular speed through the RFID tags by the RFID reader placed in front of the vehicle. the speed limit is stored in RFID tags which will be embedded on signposts or certain points of the road surface. When a vehicle passes across signboards that contain RFID tag or surface point on a specific road, an RFID reader installed in a vehicle will get the corresponding speed limit information from the tags. Such information is given as the input to speed governor then Such information automatically set the maximum speed limit corresponding to the data read. As RFID provides us a non-contact data transfer between the tag and the interrogator without the need for line-of-sight data gathering, the speed limit readings of this system would be reliable in all weather conditions. this system will be suitable for all areas including tunnels and downtown areas. A new road plan and temporary speed limit can be easily introduced by changing or implementing new tags. We can separate this system as two.Input system(RFID technology):RFID technology plays a role in the input system. For demonstration, we use low-frequency RFID readerHaving a frequency of about 13.56MHz.its range up to 2-3cm.but it's not useful for real-time implementation. We can store the information about the speed limit into the tag which may be placed either on signboards or a surface on roads. The reader installed in the vehicle reads the tags data while crossing across the vehicle. The retrieved information is given as input to the speed governor.Output system(speed governing system):The speed governing system consist of a high torque servo motor that is attached to the throttle of the vehicle .this servos maximum angle is changed concerning the signal detects from the reader .this can reduce the speed of the vehicle.BLOCK DIAGRAM"
"The farmers will be given an IOT controlled robot (AQUA-Bot) which can be controlled with the smartphones like a remote-controlled car toy. an IOT controlled robot (AQUA-Bot) which can be controlled with the smartphones like a remote-controlled car toy will be equipped with a smart irrigation module, which consists of sensors like soil moisture sensor, soil Temperature sensors and a DHT22 sensor. All these sensors will be connected to a NodeMCU ESP8266 wifi microcontroller and a water pump will also be connected to a NodeMCU ESP8266 wifi microcontroller and a water pump.All these sensors will take the data from the soil and the plant’s surroundings, and the data will be analysed by the algorithm we have uploaded in a NodeMCU ESP8266 wifi microcontroller and a water pump and will be sent to the Blynk Cloud. the data will be sent to the android application (Blynk) and can be analysed by The farmers too, now for example if the condition is true (i.e. Moisture of soil is less than 50%) then a notification will be sent to the farmer that moisture is low, please turn on the water pump, now farmer can decide whether the farmer wants to water the plant or not. Let’s take an, another condition (i.e. Moisture of soil is more than 50% but the humidity of surroundings is low and temperature is high) then farmer will analyse the condition and can still water the plant even if the soil moisture is sufficient.The given below is the block diagram of the smart irrigation module.Flowchart:"
"The program code will be dumped raspberry pi board to which acoustic sensor are connected and anLED display with red and green LED lights.Sensors of the device will be placed near fruit the device checks whether fruit is fresh from inside and cameraswill verify outside parameters gives back the result through led bulbs and display.Whole system is classified into three parts:Sensing, verifying results, displaying outcome.Sensing:There are two methods● acoustic wave sensors are highly sensitive which depends upon input voltage frequency thisresonant frequency of oscillation of crystal is sensitive to added mass at crystal surface allowingfor quantitative measurements of changes at the crystal surface.● Image processing: OpenCV in python will be using for processing by this methodweprocessor of fruit shell saying whether fruit is healthy from outside by its shape and otherfactors.Verifying results: Both the functions will return boolean values if the functions both are match the functions sets theprocessed information to display.Displaying the outcome of result: the functions displays saying whether the functions is good or not through LED screen orlight.(green saying good and red saying bad).User interface: keeping the device near the fruit the device automatically detects and start processing on the device ownthen retrieves back the results and asks for further process."
"The device called Thyroscope which is portable, user friendly, cost effective works on the ELFA (Enzyme fluorescent assay) principle and immune concentration technology. Here the patient need not do much work. In The device called Thyroscope which is portable a certain amount of blood samples is been taken from the user and placed in a test tube. a test tube is connected to a motor which rotates at 3000-4000 rpm. After, the revolution of the test tube for a certain period of time the serum of the blood which is the main component for the detection of thyroid gets separated on the upper part of a test tube. the serum of the blood which is the main component for the detection of thyroid is automatically taken and placed into another test tube which is connected to a belt attached between two motors. A strip of certain chemicals is placed right under the test tube containing serum, This belt linearly moves as per the timing given to A strip of certain chemicals. the serum of the blood which is the main component for the detection of thyroid. Certain amount of chemical reaction occurs inside a test tube. Finally, after chemical reaction a laser light of certain nano-meter is passed through the final solution and is received by the IR receiver/detector. According to the ions present in it a fixed value i.e., with the help of digital meter a fixed value is calculated and shown on the display attached at the outside of the device. Hence this is the working of the device. the device does this for only one sample at one time. BLOCK-DIAGRAM:"
"This system begins with stored products, which are to be distributed. SCARA distributes these items with the help of conveyor for the sorting and marking process. The required product is selected to move using HMI. The required product is then sent to the sorting and marking assembly via conveyor. assembly uses processing to sort the products and decides whether marking is to be done or not accordingly. the products are marked and distributed by the assembly which is made for marking and the conveyor belt respectively. Whereas the products need not to be marked, are collected at other end by pushing from conveyor using the push block. Proximity sensors are installed on assembly for detection of object. It also helps sorting and marking assembly to achieve synchronization between each other. The feedback from proximity sensors will also help to enhance safety while working with system.Whole operation of SCARA is controlled by the PLC and the feedback is provided to the user using raspberry pi. the PLC is sufficient to control whole system, though raspberry pi is used to provide data on smart devices, which makes system digitally more advanced. data on smart devices, which makes system digitally more advanced is fetched from the PLC using MODBUS TCP protocol. Raspberry Pi collects data on smart devices, which makes system digitally more advanced and sends Raspberry Pi to the smart device with the help of AWS cloud, by using which we can read the data from our smart devices. This makes our system most reliable and smartly managed. Automated assembly of sorting and marking systems saves the time in result increases the efficiency of our system and the feedback system makes our system more digitally advanced.Block Diagram:Block Diagram:Flow Chart:"
"The Block diagram of IoT based Air Quality Monitoring system is given below. The Block diagram of IoT based Air Quality Monitoring system consists of various sensors that include temperature sensor, humidity sensor, air quality sensor, NODE MCU etc."
"The fingerprint of a student will be scanned through biometric. The fingerprint of a student verifies the parameters instructed in a system in accordance with the fixed amount. the fixed amount gets cooked in the processing unit. The control panel rapidly activates the induction. When the bowl container is placed on induction, the water flow sensor activates and a particular amount of water is released in bowl container and the bowl container starts boiling. After measuring suitable temperature the sensors get to activate and the sensors release the ingredients with decided proportion. One by one, the ingredients with decided proportion are released in the boiled water in a specific proportion already instructed to the sensor and motors are controlled by Arduino Uno. Onwards after few minutes of delay, the decided quantity of rice is released and the decided quantity of rice allows for minutes of cooking. After that, the cooked khichadi will be served to the candidate. This system is broadly divided into processing units and distribution units.User Interface: the sensor and motors will take the fingerprint of the student. the sensor and motors will match the finger print entered with that in the database and if a unique match is found, then the fixed amount Khichadi will be served to the candidate. the fixed amount initiates the response to the induction device to work and also stimulates the slider for shifting the bowls in a row. Biometric sensor helps in verification and also Biometric sensor will take the records on a daily basis daily for government officials and save in the database.Ingredient Selection: Various sensors including water flow sensor and temperature sensor communicate together and with specified delay to the stepper motor, Various sensors including water flow sensor and temperature sensor release the ingredients in the specified amount instructed to the system. The sequence of delays is provided in the system according to processing. Ingredients are selected as per the instructions and amount of food.Processing and Distribution Unit: A particular time period is set for cooking the food after mixing the ingredients. When the food is cooked, the food indicates the control panel. the control panel indicates and displays that the food is ready to serve. the system gets stimulated. the system consists of a slider and a couple of bowls that are placed in the row. One by one bowls shifts towards the processing unit, the quantity set by the system is served in each bowl. The block diagram of the proposed device is as follows:Fig: Block diagram of Automatic Khichadi Making and Vending Machine"
These ideas are implemented in the water bodies. collector drunker is implemented in the ships so that collector drunker can collect the waste in the surface of the water bodies. waste drunker is implemented in the dams so that waste drunker can collect the wastes in the dams from the flowing water. pump drunker is implemented in the water bodies to collect the waste in the under water
"Implementation : Implementation is somewhat tough . As our concept is to monitor the ward speed a device is made and set a device in our concept is to monitor the ward speed a device is made and set it in their vehicle vehicle . By a device our concept is to monitor the ward speed a device is made and set it in their vehicle can monitor there speed . Coming to next concept in same idea distance is meansure by the same measurement from our concept is to monitor the ward speed a device is made and set it in their vehicle vehicle to the vehicle in front ,this makes our concept is to monitor the ward speed a device is made and set it in their vehicle sake driving and precautions are taken when the device detected the accident is going to happen . The labview software is used for this implementation and coming to hardware embedded system is used ."
"A snake robot able to pass different and difficult paths because of special physical form and movement joints mechanism. A snake robot able to pass different and difficult paths because of special physical form and movement joints mechanism have no passive wheels. The robot moves by friction between the robot body and the surface on which it is. The joints have been designed and fabricated in a way that each joint has two freedom grades and The joints may move 228 degrees in every direction. Each joint has two DC servo motors and the power is transferred from the motors output to the joint shaft through bevel gear. The flexibility of the robot makes possible to move forward, back and laterally by imitating real snake’s moves. In this paper different measures have been presented in order to design and assemble The joints, motors driver, different ways to guide the robot and this paper vision."
The proposed control can be used to control the movement of the traffic. There are 4 CCTV cameras are used to detect the population by ATmega 2560 using processing and machine learning algorithm. Based on the strength and emergency situation traffic lights are controlled.
"In this paper, we use Node MCU with WIFI modem which is inbuilt to send the information regarding the waste level present in the bin through an app. There are three LEDs that indicate three different levels of height of the waste in the bin. The green one indicates that the bin is empty and the red one indicates the bin is full. In this way, we can control the over flowing bins. Then user will receive an information saying that the dustbin must be disposed. an information saying that the dustbin must be disposed is sent using the WIFI modem. The message can be sent to multiple people at the same time. In order to make some more extension we use Servo motor and Moisture sensor to make separation of wet and dry waste before dumping into the bin. When waste fall on the moisture sensor, When waste fall on the moisture sensor senses the moisture content present in the waste and then Servo motor activates, When waste fall on the moisture sensor makes rotation of waste depends on moisture sensor that means if the waste is wet then Servo motor dumped the waste in on bin or else dumped into another bin. This system is implemented by using Node MCU and he information sent through an application called as Things view. This system is connected with Things speak IOT platform. ThingSpeak is an open-source Internet of Things (IoT) application and API to store and retrieve data from things using the HTTP protocol over the Internet or via a Local Area Network. ThingSpeak enables the creation of sensor logging applications, location tracking applications, and a social network of things with status updates.After creating a channel in Things spean for a specific application, the enabled HTTP protocol and a password are placed in things view app. After dumping the code into the Node MCU, Node MCU is configured with an app with wife username and password. What This system does is This system gives a real time indicator of the garbage level in a trashcan at any given time. Using that data we can then optimize waste collection routes and ultimately reduce fuel consumption. It allows trash collectors to plan trash collectors daily/weekly pick up schedule. An Ultrasonic Sensor is used for detecting whether the trash can is filled with garbage or not. Here An Ultrasonic Sensor is installed at the top of Trash Can and will measure the distance of garbage from the top of Trash can and we can set a threshold value according to the size of trash can. If the distance of garbage from the top of Trash will be less than this threshold value, means that the Trash can is full of garbage and we will print ."
"1) Setting Up of the Systema) The crop requires different conditions at different times of the day and in different months. A dataset of all the ranges of different parameters is developed. A dataset of all the ranges of different parameters is then loaded onto the system.Different parameters that are monitored are : 1) Air temperature, Humidity, Quality2) Soil Humidity, pH3) Light Intensityb) Sensors for measuring air humidity, temperature, quality and light intensity are placed at a vertical height. The actuators for the same are also placed along the vertical height of the greenhouse. The soil sensors are placed within the soil.2) Greenhouse Monitoring and Maintenance :a) Collecting DataThe different sensors continuously sense the environment and this data is sent to RaspberryPi in the form of electrical signalsb) AnalysisThe data received from various sensors is then analysed to take further action. Different parameters are analysed differently. Air and Soil Humidity :Different values of humidity for every hour of the day is recorded. The air and soil humidity together decide how much irrigation is required for the plant.Moisture is majorly affected by the temperature and transpiration rate of the plant. The transpiration rate of the plant varies in different seasons. 1) On a normal day, the transpiration rate is normal and humidity never crosses the threshold. 2) On rainy days or in the winter or on cloudy days, the plant doesn’t transpire a lot. Thus, the transpiration rate is low. But during these seasons, the air moisture is high. Hence, the plant has sufficient water and frequent irrigations are to be avoided. 3) In the summer season, the transpiration rate is high and the overall moisture is less. Thus, the air moisture is low as well as the soil moisture. So, more frequent irrigation is required.Analysis and Maintenance of Soil and Air HumidityAir Temperature :The sensor data for air temperature is analysed as follows :-1) The time of the day and the month of the year is checked. Depending on this value, the ideal range temperature is fetched/calculated by the system.2) The received data is checked with this range. If The received data falls within the range, then no action is required.3) If the air temperature is high, then the sprinklers(that hang from the roof of the greenhouse) are started. While these sprinklers are working, the humidity within the greenhouse is also maintained. 4) If the air temperature is low, then the heaters are switched on. While the heaters are working, the temperature and moisture within the greenhouse are monitored and it is checked that none of the parameters go disarray.Analysis and Maintenance of Air TemperatureLight Intensity :Light Intensity depends on time of the day and the month / season. The received data is checked to be within a required range. a required range is decided according to the time of the day and the season.1) During a sunny day, the intensity will never fall below the required range. It will only be above a certain limit. In case of high light intensity, the artificial lights are switched off and if required the shades are pulled close.2) During monsoon and winter, the intensity may fall below the required range. In case of low intensity, lights are within the greenhouse are switched on if it is night or if it is a cloudy day. On a sunny day the shades are opened and the sunlight is used for increasing the intensity.Analysis and Maintenance of Light IntensityOther Parameters :Air quality and soil ph is analysed based on various parameters and the user is accordingly notified about the alarming levels of each parameter.Soil pH MonitoringAir Quality MonitoringFlow Diagram"
"Block diagram and respective explanation is mentioned. The basic structure of the project is shown below. The block diagram of the transmitter section is shown in Fig 2. For battery charging purpose we need DC supply so to convert AC supply into DC we are using inverter circuit in DC supply. The ATMEGA16 controller is used for the operation. Receiver section block diagram is shown in Fig 4. The motors are operated using the battery charged through secondary coil. On the receiving end, we have another LC tank circuit which is designed to resonate/Oscillate at the same frequency as transmitter LC tank circuit i.e. 50-75 KHz. Since there is a resonant inductive coupling between transmitter &amp receiver LC tank circuits, significant power gets transferred. High frequency AC output of receiver tank circuit then converted to DC by means of rectifier circuit. DC output is then given to the load (can be mobile battery/LED module etc.) From above, we have seen that power gets effectively transferred from transmitter to receiver without any connection of wires i.e. power gets transferred wirelessly. The ATMEGA16 controller is used for the operation. Secondary coils are energized through primary coils on the road and the battery charging takes place. Single phase 230V, 50Hz is given to the power supply which converts 230V AC input to DC output. DC supply is given to drive the Oscillator circuit. Oscillator gives high frequency alternating (10-100 KHz) AC output which is given to the Amplifier. the Amplifier converts low level power output of oscillator (nearly 5-10mA) to the higher level (nearly 500mA). Alternating output (5V, 500 mA AC, 50-75 KHz) is fed to the parallel LC tank circuit. LC tank circuit is basically air cored inductor with capacitor across LC tank circuit. Since high frequency AC input is given to LC tank circuit, high frequency oscillating magnetic field is produced. The energy will transfer back and forth between the magnetic field in the inductor and the electric field across the capacitor at the resonant frequency. This oscillation will die away at a rate determined by the Q factor which is high is our case. Because the Q is high, even when low power is fed into the transmitter coil, a relatively intense field builds up over multiple cycles, which increases the power that can be received at resonance far more power is in the oscillating field than is being fed into the coil, and the transmitter coil receives a percentage of that.The flow chart is as shown below."
"The users will be able to control the robot using two methods. New and unexperienced programmers will be able to program the robot using the GUI driven programming language which will be bundled with the system. Experienced programmers who need more flexibility have the option of using traditional programming languages like Python to control the robot. The core of the system will be a Raspberry Pi microcontroller board which has user programmable GPIO ports.Both the methods of controlling the robot are directly tied to the user programmable GPIO ports and thus both the methods of programming will be equally effective at enabling the users to make the users applications.Raspberry Pi runs on a Linux based operating system. A monitor, keyboard and mouse are required to operate Raspberry Pi. But we intend to make it simpler for the end user. Instead of attaching peripherals to the board, we plan to use the Secure Shell Protocol (SSH) along with VNC so that the users can seamlessly connect to the board and access all of the board features from the users own laptop/ computer. Thus, Raspberry Pi acts as another peripheral to the user’s computer.The GUI based programming can be done using blocks. Open source software like Blockly (developed by Google) and MIT Scratch(based on Blockly) can be used here to make an interactive IDE in which the user arranges the required blocks to form a flowchart. The Blockly framework will then convert this arrangement of blocks into meaningful code which can be run natively by Raspberry Pi. This is especially useful in schools where the students are not well versed with coding but are able to think in terms of flowcharts and processes to form a Blockly program which can then be used to control the robot. No programming experience is needed to make such programs. Only ideas about the applications and designing of flowcharts are expected make programs.On the other hand for experienced developers who need more flexibility in Only ideas about the applications and designing of flowcharts applications, a Python library will be available to import into Only ideas about the applications and designing of flowcharts code so that Only ideas about the applications and designing of flowcharts can over look the basic functionalities of the robot like locomotion, sensor interfacing, etc. and focus on the essential ideas of Only ideas about the applications and designing of flowcharts applications. This will enable Only ideas about the applications and designing of flowcharts to make Only ideas about the applications and designing of flowcharts applications quickly and easily."
"First we have to give the power supply to the Smart SHOPPING CART. In the Smart SHOPPING CART we used the RAspberry PI microcontroller. ESP8266 WiFi module is also used so that the complete updation will be made on the server simultaneously without any disturbance and ESP8266 WiFi module also helps to the RAspberry PI microcontroller to access the WiFi network. LCD screen is the one which will act as the user interface . With the help of this customer will be able to get the information about the item added or removed and other general information like price , total and number of items.If customer wants to buy any product, customer has to scan customer wants to buy any product to the Bar code Scanner so that customer will be able to add customer wants to buy any product in cart. If customer wants to add more products same procedure will be followed. And the list of customer wants to buy any product will show on LCD screen. If the customer wants to remove anything from the Smart SHOPPING CART then the customer can remove customer wants to buy any product easily by clicking on the cross sign available on LCD screen just in front of the item . The moment they are finished with they shopping they have to click on the total which is on the display on LCD screen . And they will get there total along with the price and name.There is weight sensor which is at the lowest point on the Smart SHOPPING CART and is used to crosscheck the weight of the product present in cart and weight of products scanned by the Bar code Scanner. And buzzer is also there so that it will make a beep sound when both the weight will not matched. And if the customer is not been able to understand the beep sound, shop lifting message will be displayed on LCD screen. It helps to reduces the robbery in store."
"Most of the processing researchers in recent years Particularly involved in the development of machine learning In-depth learning approaches to hand-written numerology Recognition MNIST dataset and classification by IMAGENET. Our proposed methodology has emerged strongly Based on these important aspects of disease severity classification From Fundus Pictures. In particular, the classification of diseases in particular Specific architecture followed by a DCNN. Basic steps for achieving maximum accuracy from s Dataset i) Data augmentation ii) Pre-processing iii) Launch of networks iv) Training v) Activation activity Choices vi) Regularizations vii) Synchronize multiple Methods. In our proposed diabetic retinopathy classification model shown in Flow chart diagram. The blocks areA. Data augmentation B. Pre-processing C. Deep convolutional neural network classificationA. DATA AUGMENTATION The fundus s are obtained from completely different the various data sets that are taken under different cameras with variable fields of reading, non-clarity, blurring, contrast, and sizes of pictures totally different. Within the data augmentation, contrast adjustment, flipping pictures, brightness adjustments are created. B. PREPROCESSING For a Deep Convolutional neural network worked on spatial data of the fundus s. A primary step involved in the pre-processing is resizing the pictures. Before feeding into the design for classification, convert the s into Grayscale. And then, convert into our proposed diabetic retinopathy classification model shown in Flow chart diagram. our proposed diabetic retinopathy classification model shown in Flow chart diagram’s a monochrome that's used to highlight the microaneurysms, and vessels within the fundus pictures. And flatten the pictures in single-dimensional for process more.C.CNN Classification In Image processing, the feed-forward artificial neural network in which Convolutional Neural Network (CNN) is a type of Convolutional Neural Network (CNN). In which the connectivity pattern between Convolutional Neural Network (CNN) neurons is inspired by the organization of the animal visual cortex, whose individual neurons are arranged in such a way that responds to overlapping regions tiling the visual field. In deep learning, [2][3] the convolutional neural network uses a complex architecture composed of stacked layers in which is particularly well-adapted to classify the s. Deep Convolutional Neural Network architecture (DCNN) having certain common layers are i) Convolutional Layer ii) Pooling Layer iii) ReLU Layer iv) Dropout layer v) Fully Connected Layervi) Classification LayerFlow Chart:"
"The maid and customer would register in our application. When The maid and customer will enter the task details such as floor cleaning, bathroom cleaning, food, etc. and time according to their convenience, this request would be notified all n maids in the near-by location. Once any of the maid accepts this request, this request would be forwarded onto the server(backend) and then allocated maid information would be directed to customer through server. Once the maid is booked, the maid live location would be shown to customer for ease.After successful completion of the tasks, the payment from customer can be made either by online transaction or by cash. Online payment would be redirected onto the maid’s bank account and its share would be directed onto our service account. If payment mode is cash, then on month basis the maid has to deposit the fixed proportionate share of the final value to our near-by hub.The app would go in the below mentioned flow:-a) User Section i) Login section 1. User Registration 2. Sign In/Sign Out 3. Manage basic profile/ Forgot Password 4. House details (including BHK of house, whether the customer’s house is a bungalow/villa/row house/a flat)ii) the maid. Schedule booking 2. Geo location based search 3. Detailed task description 4. Detailed profile view of the maid. Cancel bookingiii) Notification User will receive the notifications for booking related updates like acceptance of booking, arrival of Cleaner (Maid), completion of job, and payments.iv) Notification User will be able to view all the history of the previous workv) About Us This page contains static information about the company b) Cleaner section (Maid Section)i) Login Maid can login only via Credentials provided by Admin.ii) Push Notifications Cleaner will receive the notifications for booking related updates like acceptance of booking, arrival of Cleaner/Maid, completion of job and payments etc.iii) Work location tracking Live Cleaner work location Tracking.iv) Job history details View earnings and logs of completed jobs. v) Accept or reject booking Accept/Deny new requests. vi) Transaction details 1. Can add additional charges and hours he worked for 2. Can see complete jobs and earnings c) Admin Section i) Manage Cleaner, User and dispatcher 1. Create/Read/Update/Delete Cleaner 2. Edit/Delete/Block User or Maid 3. Create/Read/Update/Delete dispatcher ii) Dashboard Ability to view all registered users and Cleaner. Admin can see latest bookings. Admin contains following tab: 1. Bookings 2. Bookings Pending 3. Booking confirmed 4. Booking cancelled 5. Booking finished iii) Categories Management Company will provide following categories in app/Web app 1. Floor cleaning 2. Vessels cleaning 3. Bathroom/Washroom cleaning 4. Tiles cleaning 5. Food making 6. Baby sitter 7. Old age helpersiv) Admin can Add/Update/Edit/Delete Bookings v) List Stage (Details) Admin can view complete list of users and Cleaner with information like State and city, active and inactive.vi) Cities Admin can add/delete cities Master is offering services in vii) Master settings 1. Landing page Setting (Provided for promotional purpose) 2. Testimonial Setting 3. Reason to book with usFlowChartI) Maid’s:II) Customer’s:Block DiagramCurrent problem I) WORKLOAD PROBLEMII) EXTRA MONEY ISSUE Application based Solution:"
"Our proposed idea is to predict and assist the farmer in crop selection process based on the obtained environmental and meteorological data. the obtained environmental and meteorological data is analysed and predict the future environmental condition and water availability, further use this to recommend the farmer in crop selection process to select a particular crop seed to produce high yield and obtain profit in that particular region of cultivation. The process of prediction involves a series of steps to be undertaken. They are• Sensor Installation• Data acquisition• Retrieve valid data• Data Analysis• Collection of data of crops and region of cultivation• Interlinking the Crop and region of cultivation with Environmental data• Assisting farmers with the seed selection process· Sensor Installation This is the primary process where multiple level sensor nodes are installed inside the bore well to get the ground water level. data of crops and region of cultivation• Interlinking the Crop and region of cultivation with Environmental data• Assisting farmers with the seed selection process· Sensor Installation will be uploaded to the cloud and be retrieved for the data analysis.· Data Acquisition · Data Acquisition is done from two different sources. The first is from the sensor nodes which were installed to collect the ground water level and the second is the meteorological data from the meteorological centre.Sensor data Through internet of things, the ground water level data from the sensor node is uploaded to the cloud like thingspeak and further the cloud is used for the data analysis to predict the ground water level in the future. This will not be the only source for prediction.Meteorological data Meteorological data is the main data to be collected which contains the information regarding the temperature, humidity and rainfall in a particular area. This is the most important as the water availability varies region to region like area near to natural water bodies (rivers, lakes, ponds, dams etc.) and the area which primarily depends on the ground water.· Retrieval of valid data valid data will be obtained from various sources but these raw data cannot be used for data analysis. So, the required and valid data will be filtered and collected to proceed for data analysis and prediction.·Data Analysis these raw data is given to a data analytics algorithm to conclude the past and present environmental conditions and use a data analytics algorithm to predict the future.· Collection of data of crops and region of cultivation The information of each crop like each crop cultivation period, water consumption, climatic conditions, nutrient supplements etc. are the most necessary data while predicting the crop for cultivation to produce high yield. The region of cultivation is very important because, as said before, whether The region of cultivation is near any natural water bodies or The region of cultivation depends only on ground water, the nature and quality of the soil in that region etc. are needed to select the crop to be sown.· Assisting farmers with the seed selection process This is the final process where the data analytics is used to assist farmers to decide the various different crops to be selected/sown to produce the high yield and obtain profit from the data analytics."
"GAF will be used in GYM to remove the foul odor, this is the main perspective of our project. this will perform this task in following manner:our are going to place four GAF devices into the the GYM. In which one is the master GAF and other three are slaves.To start the GAF device, the trainer of the the GYM the the GYM should press the switch of GAF which is connected to the GAF device through wall mounting.When the trainer of that GYM taps the switch of GAF which is connected to the device through wall mounting then the signal is sent to the four devices placed in GYM. But, firstly they will sent to master GAF device then GAF device will sent to other three slaves.After receiving this signals, the perfume will sprayed after 10 sec., then the copper winding which will get wounded over the pipe which is going to supply the liquid of the fragrance from the can get heated.When the liquid of the fragrance from the is completely heated then the liquid of the fragrance from the will be going to convert into the steam and then sprayed out into the environment of the the GYM. For automatic working of GAF, the time should be decided to spray the perfume automatically. the time is decided by us by us survey of the GYMs in India, us have the gap for morning shift starts at 8:30 am. Because as per us survey the timing for the morning shift of the the GYM is 6:00 am to 11:00 pm in India. As the same at the evening shift, the average time or the gap is decided at 7:30 pm as the GYM timing is 5:00 pm to 10:00 pm. For manually working the number of taps are tapped by the trainer, as per this count of taps, the fragrance is sprayed. Both modes(automatic/manually) are going to work simultaneously."
"Fig.1 Block Diagram of Energy Efficient Temperature Controlled Solar Dryer As shown in above fig. 1,Solar dryer works on the principle of heat conduction and heat absorption technique. Mainly 1,Solar dryer consists of the four blocks:1. Heating Chamber2. Control System3. Ventilation System &amp External Heating4. Supply System 1. Heating Chamber: An air packed perfect black body with top portion of transparent glass is used to absorb the sun rays. As black body is used black body will absorb all the sun rays and transfers all the sun rays into heat. At normal atmosphere black body will provide 50% more than the temperature of surrounding during the sun hours i.e. approximately from 10 am to 4 pm. The sand bed or the crushed bricks are placed at the bottom of Heating Chamber so that Heating Chamber will absorb, store and slowly dissipate the heat in chambers.2. External Heating &amp Ventilation System:The major role in temperature controlling and maintaining will be done by ventilation system. ventilation system consists of fans on the two sides of heating chamber, an outlet duct at the top of dryer by which the moisture is evaporated and gets outside Heating Chamber. The DC fans are used for maintaining the temperature. Flap is used between The DC fans.There are mainly two cases:1. When temperature is more than the required temperature at this condition the exhaust fan will be started and the exhaust fan will further dissipate the heat outside Heating Chamber and hence decreases the temperature.2. When temperature is less than the required temperature, at this condition the external heating is provided by incandescent lamp. As soon as the lamps get switched on it will generate certain amount of heat in the external heating chamber and the air in Heating Chamber gets heated which is passed in to the dryer through a blower. the dryer will increase the temperature. 3. External Heating &amp Ventilation System:An Arduino based Temperature Detection System is designed which will measure the temperature inside the dryer and as an output switching of exhaust fan or external heating unit is to be carried out. 4. Supply System:For economical and reliable operation of the equipment hybrid supply system is used. Solar panels and batteries are used for controlling and switching of the ventilation system and external heating chamber is supplied by either batteries or conventional AC supply.Fig. Flow Chart of Energy Efficient Temperature Controlled Solar Dryer"
"Blood sample test tubes:First nurse/assistant take the blood sample of patient and put the blood sample of patient in the clean test tube.Pharmacy:The order in which the various tubes are filled is determined by the risk of contamination and coagulation. 1. tubes for serum, 2. citrate filled tubes, 3. gel tubes, 4. heparin filled tubes, 5. EDTA filled tubes, 6. fluoride filled tubes. Another consideration that might affect the order of tube filling is the priority of the assay for which the various tubes are needed, in case insufficient blood flow cuts the sampling short.To assure proper mixing tubes pre-filled with EDTA, gel or fluoride should be inverted about 8 times towards the stopper while the next tube is filling up (It may simplify the manual of operations to prescribe inverting the various tubes, since It does not harm plain tubes).Before the subject leaves the examination site and before the rack is moved anywhere, the various tubes should be labeled with the subject identification code. Optical Sensors and Arduino:Liquid level optical sensor is used which converts the amount of reflected light from segmentation into the voltage levels.Optical Sensors and Arduino:Liquid level optical sensor are connected to Arduino which is going to indicate the result with some reference voltage and show the result on LCD.Real time display:some reference voltage will show overview of all the data on single screen / multiple screen.P.C. (Data acquisition):All Data acquisition):All will be arranged in form of complete medical reports at excel sheet, web site and send Data acquisition):All to doctor."
A variety of sensors situated at different parts of the device create and maintains a map of the surroundings. With the help of these sensors the help of these sensors locates the toilet by the help of these sensors. There are two servo motors present at second and third joint of robotic arm. two servo motors present at second and third joint of robotic arm are used for the purpose of motion of robotic arm. robotic arm is made up of poly silicon material and aluminum material. The joints are made up of poly-silicon material and the links are made up of hollow aluminum material. The brush is attached at the end of robotic arm to clean the toilet bowl by using DC motor. The size of first link of robotic arm is 470mm and size of second link is 250mm. For reducing reverse current opt couplers are used. The 3 D design is made by using the Autodesk fusion software and poly silicon material. MAX 232 is an integrated circuit which converts the signals from the RS232 serial port to the proper signal which are used in the TTL compatible digital logic circuits. The driver increases the output voltage levels of TTL 232 from a 5 volt supply to 7.5 volts by using the external capacitor and on chip charge pumps. MAX 232 is connected to robotic arm through transmitter receiver pins. 3.3V DC power is required for the ARM LPC 2148 and 5V DC power is required to MAX 232 and LCD. These powers are given from power supply circuit which is mounted on PCB. For loading program into this PCB Flash magic software and boot loader kit is used
"There will be a search bar present at the top and tool bar at the left top end corner consisting of diagnosis, farming methods, soil test, weather, pesticides and queries.Whenever farmers want to diagonize the plant part that was infected, camera will be opened and The disease takes a clear . The will be processed. The disease will be identified by the software which includes artificial intelligence. If The disease was an already existing disease the solution for that will be given to farmers. If the identifies disease was an already existing disease the will be sent to agriculture experts and scientists. After research the solution will be given by agriculture experts and scientists to the development team. the development team will add this new disease issues and solution to the AI. Later solution will be given to farmers.the AI also provides information on which pesticides are to be used for the crop and farmers can also order pesticides online.If the problem is not rectified ,the farmer can again contact for support and will try other methods and will be asked to send the sample.samples:soil samples are very important as it determines the nutrients that were present .Soil test gives details of harmful chemicals also.Image processing:The that was processed is identified by the software which includes artificial intelligence ."
"We have come up with the idea of establishing an Invisible Ultra Sound Screen at the Red signal crossing. CCTV cameras exist on every signal zones in the city and this can be made use of.At the time of red signal, if any vehicle crosses this Ultra Sound Screen, the CCTV will automatically focus on the number plate of Vehicle and captures the number. the number is then processed using arduino and references the number in the cloud database of Vehicle registrations. The cloud is an reference index, which searches for the vehicle registrar index for the details of Owner of the vehicle. Once The cloud fetches the details of the vehicle owner, The cloud will immediately add a violation record on Owner of the vehicle's profile and a SMS will be sent to Owner of the vehicle of Vehicle notifying Owner of the vehicle/her of the penalty enforced."
"Module 1: (Transmitter end)1. Arduino Nano: The controller will be interfaced with the GSM module and MQT-3 gas sensor. 2. MQT-3 sensor:The level of emission from the vehicle will be checked by the MQT-3 gas sensor and the MQT-3 gas sensor will give the values of improper emission if any fault or value other than the given set of data is detected. Now if the MQT-3 gas sensor detects any of the faults in the level of emission, the MQT-3 gas sensor will instantly send the notification to the driver and Government.3. GSM module:If gas sensor detects any faults in the vehicle emission, the values of the MQT-3 gas sensor will be sent to the user using GSM module."Module 1: (Transmitter end)1. Mobile app: Mobile app will display the faulty values received and there will alert messages every time the value is above the default values.2. Webpage: Along with Mobile app, there will be a Web page which can also be used to check the status Desktop/PC/Laptos.Module 3: 1. Barcode Scanner: The data of every individual will be saved in every individual own databases. Now there will a Barcode scanner in every individual’s license which will give information about his/his vehicle emission data. Every scan will be registered so that there will be no chance of corruption further. Barcode scanner will make Barcode scanner easier for cops as data of individual will appear instantly."
"As shown in block diagram, the complete system can be divided into main four functional units such as Controlling UI with IOT, Robot motion, Controlling burn and Reforest.The control unit (MCU) includes a Wi-Fi for IOT. IOT is used to give input parameters to MCU to operate Robot. The input parameters are Direction, speed, digging, seeding, water. MCU plays vital role in the proposed system. MCU MCU is programmed to control all sensors and relays which operate DC motors, servo motor through servo driver.The Robot motion involves motors, shaft, wheels, motor driver, Inertial measurement unit, Ultrasonic sensor, Servo motor, Servo driver.The controlling burn involves fire detection sensor, humidity sensor, temperature sensor, and also accuracy of the robot having addition feature live camera stream. Reforest is semi-autonomous process which involves relay, digging, seeding, water for seed.Once MCU is commanded to start, the DC motor coupled is given supply and controlled with the help of motor driver to give smooth motion in forest.Once the ultrasonic sensor senses the presence of space then MCU send alert message to operator. Operator is verify using live camera stream, after the operator permission seeding is start. That process is autonomous.The other sensors like humidity, temperature, fire detect are to detect and analyze fire.With the help of sensor fire is detect then MCU send alert message to operator. Operator verify through live camera stream.Through the help of feedback system like, Inertial measurement unit, Ultrasonic sensor. Robot is Autonomously travel in forest.In some of Robot is manually operated by Operator."
"Transmittera. Detector modulenRF51822 [5]It is an ultra-low power System-on-Chip (SoC) [4] with Bluetooth and wireles applications ranging upto 2.4GHz. It is the main controller of our device. The data collection and processing is managed within the main controller of our device. nRF24L01 Module This is a wireless communication module. This job is to transmit SOS [6] signals to far away distances to a control station.MPU6050 Gyroscope and accelerometer module It is used to track the acceleration, velocity, orientation, displacement [7] and many other motion related parameters of the user.MAX30100 heart rate sensor [3]It is used to monitor the pulse rate of the user to determine the anxiety levels.Water level sensor / detectorIt will be used to detect whether the person is in water or not.b. Immediate Rescue ModuleSolenoid valve and CO2 cartridgeSolenoid valve is used to electrically control the air flow from the CO2 cartridge.Inflatable rubber bladderIt is a balloon made up thick rubber which will be inflated with CO2. Inflatable rubber bladderIt can withstand heavy loads.c. Machine Learning ModelAlong with the body parameters we will also be focusing on the swimming pattern of a swimmer which will be continuously recorded. If there seems any abrupt change in the pattern for few seconds along with the other parameters then it will predict that the person is drowning. Depending on the obtained parameters with the help of different sensors, the trained ml module will predict weather the user is drowning or not.Fig: TRANSMITTER BLOCK DIAGRAMReceivernRF24L01It is another part of the long range wireless communication. TRANSMITTER BLOCK DIAGRAMReceivernRF24L01It receives data and SOS signals and feeds TRANSMITTER BLOCK DIAGRAMReceivernRF24L01It to the controller.Arduino NanoIt is used to process the data received from the nRF24L01 module and generates output as per need.BuzzerA small buzzer is also connected to the controller that is turned on whenever BuzzerA small buzzer receives a SOS signal.Fig: RECEIVER BLOCK DIAGRAMOverall WorkingThere are 2 parts in our implementation namely:a. Transmitterb. Receivera. TRANSMITTER: The user has to wear the device across his/her waist &amp switch the device ON before entering into the water. Once the device is ON, the pulse rate and body movements of The user are monitored continuously. These signals are received by the controller. For getting the body parameters we have used MPU6050 (accelerometer and gyroscope sensor) and MAX30100 (heart rate sensor). These parameters will be fed to an ML model which will predict if the person is drowning or not. If the model predicts that The user is drowning, then Rescue Module will be activated.Rescue Module: Rescue Module includes a solenoid valve which will be electrically energized when drowning is predicted. Due to this, the CO2 from the cartridge will flow into the rubber bladder (balloon) to inflate Rescue Module. As the rubber bladder starts inflating, The user will be brought to the surface of the water. And a signal will be sent to the monitoring station using nrf24L01.b. RECEIVER: Then a signal is sent to Arduino nano. And accordingly a signal will activate the buzzer so that the lifeguards can take necessary actions if needed.FLOW CHART"
"pH sensor: The pH of a solution is the measure of the acidity or alkalinity of that solution. The pH scale is a logarithmic scale whose range is from 0-14 with a neutral point being 7. Values above 7 indicate a basic or alkaline solution and values below 7 would indicate an acidic solution. an acidic solution operates on 5V power supply and an acidic solution is easy to interface with arduino.The normal range of pH is 6 to 8.5. TURBIDITY SENSOR: Turbidity is a measure of the cloudiness of water. Turbidity has indicated the degree at which the water loses the water transparency. Turbidity is considered as a good measure of the quality of water. Turbidity blocks out the light needed by submerged aquatic vegetation. Turbidity also can raise surface water temperatures above normal because suspended particles near the surface facilitate the absorption of heat from sunlight. RESIDUAL CHLORINE SENSOR: The free chlorine sensors used by the analysers are largely pH independent meaning that the measurements are bufferless and reagentless. The free chlorine sensors used by the analysers are amperometric sensors and show remarkable sensitivity and stability. amperometric sensors work by separating the electrodes that perform the measurement from the sample, by a membrane.PHYLOCHIP: Phylochip is unique in Phylochip ability to identify multiple bacterial and archaeal organisms from complex microbial samples.TOC SENSOR: Total organic carbon (TOC) is the amount of carbon found in an organic compound and is often used as a non-specific indicator of water quality or cleanliness of pharmaceutical manufacturing equipment. BLUETOOTH LOW ENERGY: Bluetooth Low Energy (Bluetooth LE, colloquially BLE, formerly marketed as Bluetooth Smart) is a wireless personal area network technology designed and marketed by the Bluetooth Special Interest Group (Bluetooth SIG) aimed at novel applications in the healthcare, fitness, beacons, security, and home entertainment industries. Compared to Classic Bluetooth, Bluetooth Low Energy is intended to provide considerably reduced power consumption and cost while maintaining a similar communication range."
"Each day an optimized path will be made by the system with respect to which all household have waste inside all household dustbin(this info is taken via the dustbins internal system or the household user can manually override and prompt for a pick up) and an optimized path is given for each collection vehicle to pick up waste and a notification is sent to each household to ask if each household could give waste at the specific time of the collections vehicles arrival, each household could check the live location of each collection vehicle via the app and give each household response. an optimized path will be optimized again to each household’s response. If each household didn’t or couldn’t give waste even after responding each household could each household will be fined. When each collection vehicle comes near a specific household each household could slide the dustbin out of a dock which houses the sensing and Wi-Fi system and give the dustbin to the collection worker, the collection worker would give a clean dustbin which was taken from each collection vehicle and take the full dustbin to replace each collection vehicle in each collection vehicle. the dustbin can be slid back into the dock and the dock will read the RF-ID chip which is every bin is equipped with and register the serial number of the bin, current date and the household where the RF-ID chip which is every bin has been placed into the systems server via home Wi-Fi. After each collection vehicle has done collecting each collection vehicle will go to the waste treatment plant and clear each of the bins if one of the bins are found to have mixed waste the source of mixed waste is found by tracking the source of the waste serial number of the RF-ID via the server’s database and that household would be fined. After all the dustbins are cleared, household are cleaned by pressurized water and circulated back. As each dock will register each time the dustbin is changed, we could count the number of days a specific house used the collection service and bill a specific house accordingly so and each household could pay through our system and the collection workers will get the money via our system (like uber). The main way we will get the money for we services that is the two apps, the management system and all the dustbins are by taking a fraction of the monthly profit of the collection workers and the interest of the caution deposit taken for each dustbin. The dustbin and the dock together is estimated to cost around 1200Rs per household and we will take a caution deposit of 600Rs from the households and give install a caution deposit of 600Rs in the households , and a percentage of the monthly profit (excluding the fines collected from household for malpractice) of the collection workers will be taken by we. Although all the dustbins are manufactured by we and given out for free of cost like a net router provided by an ISP but will still be owned by we. As for the cleaning of all the dustbins must be done by the collection workers we will provide the collection workers the equipment for seemingly free of cost."
"The entire project is divided into two parts- Software and Hardware. The Hardware part consists of a Smart-Bin to process the biodegradable waste. a Smart-Bin to process the biodegradable waste will have inbuilt sensors to sense temperature, moisture content, humidity, pH of generated compost and weight measurement sensor. With this knowledge of various parameters we can analyze the complete composting process. Each stage in composting is characterized by specific range of values of these parameters. The ranges are given according to the method followed (Berkeley Rapid Composting Method). The entire setup can be powered by Arduino output voltage pins and thus require a minimal of 5-12V voltage which can be supplied using DC source like a battery. The complete model has two bins on a single setup. Since the composting takes 15-20 days two bins on a single setup can be used one after another. An average household of 4 members generates not more than 1kg waste every day (researched by measuring individual wet waste of the team members’ household, friends and family). Thus two 15 kg bins can we used sufficiently one after the other. User will input waste in a bin. The increase in weight will be sensed by load cells. When a bin will be filled to a bin capacity User will be notified in the App to use another bin. User will thus use another bin-bin2 for waste disposal. Meanwhile, analysis of Bin1 parameters will start. The moisture content, temperature values, humidity, pH should vary in accordance with Berkeley Composting method. This will be a parameter to ensure the genuineness in the process. The corresponding data will be sent to cloud database every day. Thus two 15 kg bins can we used sufficiently one after the other will have a rotating structure. User will have to manually just give a bin a spin everyday to ensure aeration and ventilation. This concludes the hardware aspect. In the software part the sensor data sent everyday to cloud will be analyzed. The values will be verified with Berkeley parameters. Composting will be shown successful only if Berkeley parameters vary in accordance with each subsequent days. the sensor data will be visible to user on the Smart-Bin software application. Alerts such as temperature or weight crossing certain threshold will be displayed on the Smart-Bin software application. User will be assigned points after each successful composting. A leader-board will be created of the process. The leader of each month will receive certain amount of cash which will be electronically transferred. This cash flow will be ensured by following method:A fixed amount after purchase of a bin from every user will be kept aside. Let’s say 500/- is kept aside. If 10 users are considered then 500x10=5000/- will be kept aside. However each month will have one winner so a portion of A fixed amount after purchase of the bin from every user will be transferred to the winner. Single winner each month, minimal interest received from A fixed amount after purchase of the bin from every user, further sale of bins will ensure that A fixed amount after purchase of the bin from every user isn’t depleted. Moreover the received prize in form of cash will in turn encourage more and more people for composting more and more people bio-waste. It will also cause publicity of the Smart-Bins. Thus awareness and business will go hand in hand by creation of such competitive environment."
"Agriculture is the backbone of a nation's economy. Farmers play a key role in a country's development. Technology has a far reaching effect on every sphere of our lives. As such, if Technology could be used to manage natural resources, agricultural production can be improved. The main goal is to provide feasible solution for the finding problems and to enhance the productivity of the agriculture sector."
"The overview for the methodology adopted to achieve an optimally functional solution to the described problem statement is as follows: · Evaluation of the requirements of the robot on consultation with the end users (hospital doctors, nurses and patients). Upon appropriate evaluation of the market needs, the most important requirements will be narrowed down.· Each requirement will be mapped to an engineering problem to be solved. The proposed objectives will be initially be achieved by developing a CAD model using Fusion360 and evaluating the kinematic and dynamic feasibility. This step will involve multiple iterations and continuous modifications to arrive at the most efficient mechanism to carry out the desired functions. · Since safety is of primary importance, we will opt for hydraulic actuation due to hydraulic actuation ability to retain hydraulic pressure and thus not drop the patient in the case of power failure. · The hydraulic circuit, pump and hub motor specifications needs to be calculated for the actuation and locomotion systems respectively. We will then develop the necessary software tools to be implemented in the robot such as computer vision aided pose estimation of the patient, UI design, sensor interfacing with microcontroller, and autonomous navigation using 3D cameras. · The computer vision model to detect patient pose will be deployed using customized dataset on the pretrained Google inception V3 model. The humanoid head which houses the camera used for pose-detection will be designed using Fusion 360. · The next stage will include the manufacturing of the customized hydraulic system, procurement of raw materials, bearing and fasteners for the frame, and fabrication of the 1:1 scale model according to the optimized CAD model. · Certain components which require customized design fabrication will be 3D printed (e.g., the humanoid head camera housing). · In the final stage, the developed software and hardware will be integrated to function in harmony. The entire system will then be rigorously tested to identify mechanical, software and control flaws which will be eliminated through multiple optimization iterations."
"The automated system software will accept the user information like user name, adhaar number, mobile number mail id and bank details (account number, name of the bank, branch, and IFSC code of the branch). First, the user should login to automated system software and put the reusable plastic product in the specified part of the machine. The camera will scan the reusable plastic product and identify the product details like shape, usage, how much the reusable plastic product will reusable, etc. the reusable plastic product shows the reusable product details to customer and shows how much cost will be refundable to the reusable product details to customer. The amount will be transferred to the reusable product details to customer account. The system is broadly divided into following modules1. User Registration2. User Login3. Accepting and verifying the product4. Confirmation and transferring the amount User Registration part accepts user name, address, adhaar number, mobile number, mail id, user name and password and collects bank details (account number, account holder name, name of the bank, branch, IFSC code). The system should verify the account details to with bank and shows the confirmation to User.User login module accepts the user name and password and verifies User login module authentication.Accepting and verifying the product module accepts the product from the customer and scan the product from the customer to get the of the product from the customer. In our database, our contain the details about the various products (shape, color, return amount, etc.). The automated system software compares the which is scanned with the stored in database. Identifies the product details from the database and shown to customer.Confirmation and transferring the product module will get the confirmation from the customer and transfer the specified amount to the customer customer account and show the confirmationof transformation."
"Initially with the help of teachers and study experts, the contents will be finalized. A lot of study material and videos are already available, so selection off the best ones is the first step. This will ease the process of representing the information in mixed reality format. Selection of contents, to be processed first is the only reason for teachers to be involved in the process of representing the information in mixed reality format. Once the interactive 3D content is developed, we can give a demo version of we work to school as a proposal. The schools that are interested and willing to invest would be requested to send The schools that are interested and willing to invest teachers to get skilled with the product. This will help their teachers optimize the other resources their teachers utilize for the teaching process.The need of specialized hardware is must, as The need of specialized hardware will distract the user from being engaged in other activities. The idea of using AR/VR technology is that it will help structure ideas and concepts to give feel of interacting with some object. Cutting the students interaction with the surroundings is not the motto of we product. So implementing the second mode which will help them better interact with them surroundings would be independent of the schooling mode."
"Mechanical Aspects:The robot consists of a two-wheel self-balancing robot. Due to the unique structure and material of the wheels The robot can accommodate The robot on rough terrain and climb stair by balancing The robot centre of gravity. The wheels also absorb any impact that occur due to the robot falling from a height making The wheels a robust system. The wheel design is such that The robot can traverse on diverse terrain and float on water. The wheel design consists of BLDC motors that form a combination to give a planetary gearhead reduction. The wheel design is the comparatively small make of the robot that helps The wheel design interact with the environment better. Overall Model: Intel RealSense camera is used to localize The robot using monocular visual odometry (position of The robot i.e. rotation and translation in 2D space). For accurate measurement of these values an Inertial Measurement Unit (IMU). Cameras at the rear alternate source for monocular visual odometry as well as make the system reliable and robust.Cameras are also used to detect people, objects and alert the security personal about the same. Cameras provide a 360-degree field of view and are also equipped with night vision to be able to see in the dark.Lidar rangefinder is used for mapping of the environment for more precise localisation information of The robot. Kalman filter with sensor fusion is used for accurate measurements and also used different types of filtering techniques on sensors raw measurements. Particle filter is used for localisation in known environments. GPS is used for location tracking. YOLO algorithm is used for detection of suspicious objects or individuals (e.g.: detecting guns, terrorists, etc.). 4G modem/dongle is used to transmit feed data i.e. video/audio as we as link The robot with other patrol robots in the framework.The control of The robot is done using LQR Feedback controller by using various sensors like IMU, Camera, and Lidar. DC Motors are used to drive the gyro stabiliser for changing DC Motors roll, pitch, and yaw. Gyrostabiliser works on the principle of gyroscopic effect to balance The robot on uneven terrain or on surfaces where the balance of The robot can be affected. This is also used to provide the necessary balance during step climbing. Smoke Sensor is used to detect the level of co2 and predict if there is a fire nearby. Microphone is used to get a two-way audio transfer that can transmit as well as receive, another is a one-way audio transfer from robot to the user. Microphone is also used to do footsteps detection."
"The implementation of this project can be easily understood by the following block diagram.this project is based on the principle of automation in which the machine will be operated by using a phone or a laptop with the help of microcontrollers. The components that are to be used here will have the ability to sense and perform up to the extent which will reduce human efforts and will provide High Yield Crops.Each Component used in the block diagram has Each Component own work and Each Component’s explained pointwise below.1. IR Sensor : -[3]IR sensor works by using a specific light sensor detect light wavelength in the infra-Red spectrum. When an object is close to the sensor the light from the LED bounces off an object and into the light sensor.2. MSP-EXP430FR6989 Controller : -[4]MSP-EXP430FR6989 will be helpful in controlling the complete seed sowing apparatus through -EXP430FR6989 excellent controlling capabilities. Since -EXP430FR6989 is affordable and has better capabilities than higher end AT Mega controllers used in Arduino platform. The thing which makes it better than others is The thing which makes it better than others cloak frequency.3. Battery and BOOSTXL-BATPAKMKII: -[5]Battery will be the key component for providing power to the apparatus and who’s charging will be accompanied by BOOSTXL-BATPAKMKII.4. BOOST-DRV8848: -It will be used as DC motor driver for the machine.5. DC MOTORS: -It is a device which converts the direct current into mechanical energy. 200 RPM center shaft Economy shaft series motors will be used since 200 RPM center shaft Economy shaft series motors give great performance and are quite cheaper which will be helpful to keep the budget as minimum as possible.6. Solenoid Valve: -It is an electromechanically operated valve. an electromechanically operated valve is controlled by an electric current through a solenoid. In a solenoid a valve like arrangement will be used to drop seeds in farm while seeding is to be done by machine.7. LCD: -[6]The LED decodes the control signal and performs the corresponding actions on the LCD. It will be useful for displaying any kind of fault that will arise so that problems can be solved before any further damages. It will also show the amount of fertilizer in soil and the amount of seed sowed on fields.8. Keypad: -Keys will also be installed in a solenoid because if by chance due to software code problem if a solenoid malfunctions, a solenoid can be easily be turned OF/ON with the help of those keys.9. SPRINKLERS: -Sprinklers will be set up to sprinkle fertilizers, water, pesticides along with seeds.10. CC3220SF-LAUNCHXL: -[7] For connection between device and machine.Mechanism:Firstly the person will send instructions using the person own phone or laptop. The message or instruction will be conveyed with the help of sensors present and the codes given to microcontroller after this the microcontroller will send instructions to the motor drivers to start a solenoid. a solenoid will start moving and will start sowing seeds up to the depth which is given to the microcontroller by owner. In case of any type of big obstacle present the IR sensor will detect and send message to owner for hindrance that can be caused. If in case product causes any malfunction then it can be turned OF manually by using keypad given."
"VERA is an education expert agent which can recommend resources, answer student’s FAQs and give personalized career suggestions and help in the interview preparation,a virtual assistant is developed, which is a multi lingual conversational agent capable of handling different forms of inputs from user in different languages such as Hindi,Marathi and Gujrati. The block diagram for the proposed system methodology is given in Fig. 3. Then, different machine learning techniques are used to build andtrain models capable of executing the various steps explained below :[7]The virtual assistant starts the chat, welcomes the user to "VERA, and proceeds with greeting along different recommendation questions via voice and text. And it will check whether the input given by the user is in text or voice, if it is in voice it is in voice will first be converted to text using Google API’s before further processing.The responses received from the user are analyzed to detect the language of the given input.Based on the language it will passed to the custom spell checker which is trained on the available data in the NLU and scraped data from QUORA for different fields like Data Science ,Machine learning, Full Stack and etc.Since data is in the textual form it will be embedded into vector form using word2vec vectorizations.Based on the trained model domain of the question will be classified using Machine Learning algorithms.In order to identify intent of user’s response ,given response will be classified into different intent based on trained machine learning model.After Intent classification different entities will be extracted from response using NER techniquesAs per the defined stories relevant action will be performed using LSTM model and corresponding answer will be fetched and delivered using NODEJS and cloud interfaces.Input Conversion and Language Translator :-It will check whether the input given by the user is in text or voice, if it is in voice it is in voice will first be converted to text and language translation using Google API’s before further processing.Custom Spell Checker:-Based on the language Custom Spell will passed to the custom spell checker which is trained on the available data in the NLU and scraped data from QUORA for different fields like Data Science ,Machine learning, Full Stack and etc.Intent classification and Entity Recognition :-Intent classifier uses the spaCy library to load pretrained language models which then are used to represent each word in the user message as word embedding. Word embeddings are vector representations of words, meaning each word is converted to a dense numeric vector. Word embeddings capture semantic and syntactic aspects of words. This means that similar words should be represented by similar vectors. Fig. 1 : Intent Classification ModuleIntent: This tells us what the user would like to do.The intent classification model is as shown in Fig. 1.Ex : Raise a complaint, request for refund etcEntities: These are the attributes which gives details about the user’s task The Entity classification module is shown in Fig. 2. Example: Complaint regarding service disruptions, refund cost etc. Fig. 2 : Entity Identification ModuleConfidence Score : This is a distance metric which indicates how closely the NLU could classify the result into the list of intents.Node based chat flows :NodeJS is used as backend framework and ReactJS is used as a front-end framework for the management of dialogue flowAdmin Panel :-Grafana Admin will be used to make admin panelGrafana is an open source metric analytics &amp visualization suite. an open source metric analytics &amp visualization suite is most commonly used for visualizing time series data for infrastructure and application analytics but many use an open source metric analytics &amp visualization suite in other domains including industrial sensors, home automation, weather, and process control.Google Kubernetes Engine :Google Kubernetes Engine is a management and orchestration system for Docker container and container clusters that run within Google's public cloud services. Google Kubernetes Engine is based on Kubernetes, Google's open source container management system.Google Kubernetes Engine helps in deployment of applications.[6]Flow chart: Fig. 3 : Proposed Block Diagram of the System"
"First we will collect the waste, collected by municipality • Using evaporation treatment we divide the waste, collected by municipality into wet waste and dry waste.• we will now send wet waste to the agriculture compost centre for make compost.• Dry waste will now be split into heavy and light waste using gravity separation technology.• Heavy waste will now have glass, metal object and heavy plastic pieces. Using belt magnetic separation we separate metallic objects and remaining glass and heavy plastic and this can be separate by metallic objects and remaining glass and heavy plastic density. • The residual lighter waste such as paper and plastic, will be separate using air separation system.• Thus everything divided will be delivered to the corresponding recycling center."
"Automatic sensing of air quality system is check and indicate the quality of air time to time. • The automatic sensing of air quality system will be of robotics arm configuration.which used as when vehicle is on check the quality at that place from when gas coming out and after some time it will take their place automatically. .• this system work into 3 parts. 1.initial measurement 2.indication 3.alert • when vehicle on , this system go that gas outcoming place and after some time these robotic arm measure initial air quality. • this initial measure display air quality on digital screen. • then, after sometime these robotic arm check air quality system and indicate it.like wise during some time period these robotic arm will continuously check the air quality and display on digital screen.• automatic air quality sensing system compare the initial measurement and final measurement.and if air quality is bad then these robotic arm alerts and advice to make changes in vehicles.• in this system alert is mainly due to 3 ways. 1.on screen 2.by alaram 3.by sms/email•On screen: due to measurement if air quality is decreases then by the use of system it indicate on screen. Like, red light•By alaram: if sometime screen display not take into consideration due to some reason then sound alaram is used.• By sms/email: in this sensing system sms and emails are used for indication and alert purpose. When air quality decrease then alert is done on screen and by alarm. But by sms and email it indicate to vehicle owner also. Due to vehicle owner know the condition of vehicle at any time and he/ he/ get the information about maintenance of vehicle.And at the end people aware with air pollution. Alert. Ondigital screenBy alarm sms/email"
"Main challenge faced for robots is traversing, which we are solving by using a mechanism called Rocker Bogie Mechanism shown in figure 1. The rocker-bogie suspension is a mechanism that, along with a differential, enables a six-wheeled vehicle to passively keep all six wheels in contact with a surface even when driving on severely uneven terrain. There are two key advantages to this feature. The first advantage is that the wheels pressure on the ground will be equilibrated. This is extremely important in soft terrain where excessive ground pressure can result in the vehicle sinking into the driving surface. The second advantage is that while climbing over hard, uneven terrain, all six wheels will nominally remain in contact with the surface and under load, helping to propel the vehicle over the terrain [2]. Precision in traversing is obtained by using encoders used to calculate distance. Figure 1:Rocker Bogie [1]Traversing for a robot in an agricultural field becomes difficult because Figure 1:Rocker Bogie [1]Traversing for a robot in an agricultural field looses track, due to numerous obstacles and doesn’t have any guiding line to get Figure 1:Rocker Bogie [1]Traversing for a robot in an agricultural field back on track. The field being uneven makes The field very hard for moving in a precise motion. Figure 2 Block DiagramFigure 2 shows the block diagram of our system. Different sensors mounted on robot like Soil Moisture Sensor, Temperature and Humidity sensor will collect data about different greenhouse parameters and store different greenhouse parameters in the database. If any parameter drops below threshold the farmer will be informed so that they can take corrective action. The robot will traverse in the greenhouse and perform seeding with the help of arm mechanism.The robot is going to perform seeding in the following manner:A mechanism having suction pump with pointed nozzle having length appropriate enough to plant the seeds at required depth. A mechanism having suction pump with pointed nozzle having length appropriate enough to plant the seeds at required depth will be mounted on servo which will pick the required mechanism as given by the controller. Servo motors help control the movement of arm precisely. Nozzle attached to the suction pump will pick a seed from seed tray placed on rover and release at certain depth in soil.Various parameters like Soil Moisture, Humidity and Temperature of greenhouse is monitored with the capacitive soil moisture sensor and amt1001 sensor, data gathered by the sensors will be delivered to the user via internet, data gathered by the sensors will help in continuous monitoring, control signals will be taken from the users via internet [3]. Most of the times it is difficult to a good internet connection in agriculture fields so system will also have a GSM module which will send a direct message to user if one of three parameters fall below the predefined condition."
"The implementation of the proposed system is depicted in Architecture shown in Figure 1. , In Architecture modules are designed: (i) Vaccine Scanner – This module will scan vaccines to be used for patient. A QR Code scanner software in Raspberry PI based IoT device will scan the QR code attached in vaccines. The data extracted is used by Python program and will fetch all relevant details of vaccine from a cloud based storage. Expiry of vaccine, operating temperature and dosage required are displayed. (ii) Dosage Monitoring- Once vaccine is declared to be usable, the amount of vaccine used is recorded using values of a HC-SR04 based Ultrasonic distance sensor. The dosage used is recorded into cloud storage and alerts are sent if abnormality is observed. (iii) Stock Monitoring – each time vaccine exhausts (or about to be exhausted on a particular threshold) alerts and notifications are sent to prospective vendors. (iv) Analytics – The overall use of vaccines in different hospitals is graphically represented with filter and drill down options. Visualization softwares like Kibana is planned to be used. Since vaccine overall data becomes big-data, an elastic search is used for analytics. (v) User Interface: Android based Apps are developed to enable details of vaccines used for nurse, managers and others. Role based access is provided for different users of the App and details of vaccine stock and dosage can be observed in the App. The following performance parameters are planned to be evaluated in proposed system: · Stock Monitoring – measuring stock of vaccine available accurately (measured as number of false positives/negatives alarms) · Accuracy of Temperature data collected – measured as percentage of error in measurement · Expiry time monitoring – measured as percentage of false positives and negatives alarms · Dosage measurement – accuracy parameter measured as percentage of error in dosage value · Number of possible health hazards avoided by implementing Smart Vaccines"
"The smart prescriber system has 4 components as shown in Figure 4 and listed as follows:1. A trained system for drug prescription.2. Set of sensors for regular health updates of patient.3. A server to store the patient data.4. A system/mobile application as an interface to the doctors, pharmacists and patients.When the patient arrives to the doctor suffering from some disease, the doctor first gets the diagnostic reports of the patient and further proceeds with the smart drug prescriber app to get assistance over the prescription of drugs.SensorsBasically we are using 3 sensors to get regular updates regarding the patient health, along with a daily surveillance over the vicissitude health status. Primarily the vigilance is done about the blood pressure and pulse rate using blood pressure sensor, amount of calories burnt on the daily workouts with the help of data obtained by combining inputs from accelerometer and heart rate monitoring sensors.Trained systemA system is trained with the help of supervised learning algorithms and data obtained from the physician community regarding range of dosage values of drugs for a disease with particular attribute values as seen over the lab reports. Trained systemA system will be trained with supervised learning which uses algorithms like linear regression, gradient descent, stochastic descent etc. And is being tested verified with validation techniques like K-cross validation technique. Trained systemA system will get the input from the doctor and do the required computation as predefined in the algorithm and gives assistance to the physician on what drug need to be given as remedy and what need to be the drug potency.ServerFor storing confidential data of the patients we are maintaining a server. For this storage purpose we are making use of Google's mobile application development platform Firebase which is a cloud-hosted NoSQL database that enables data to be stored and synced between users in real time. This makes the data available anytime and anywhere. Also the data is well secured. We are storing the data entered by the doctor during the treatment of the patient like current status of the disease, currently prescribed drug and currently prescribed drug’s dosage, suggestions given to the patient for the betterment of health based on the regular diet and daily workout followed and also the regular updates from the health monitoring sensors are being stored in the server.System/Mobile Application To access all these services we are going build an application which acts as an interface to doctors, patients and also to the pharmacists. This makes the system more transparent, easily accessible. Application will be developed using languages like kotlin , swift etc. System/Mobile Application consists of interfaces for login/sign in option and also to display the test result of the particular patient calculated in trained machine. Figure 4:-System Architecture"
"The bot will traverse through the environment, and These s. These s will contain a wide variety of objects. Through classification, SegriBot will determine whether the contains plastic objects or not. If the response is positive, SegriBot will move over to the object, and using SegriBot grill mechanism, pick up the object, and begin the object cycle again. If the container is full, SegriBot will go to a secluded place to deposit the plastic waste for a much easier collection by the authorities. Using a trained CNN, our ML model will identify the plastic objects found within the said , and our ML model will act as waypoints for The bot, as The bot traverses the environment looking for waste."
"As this prototype is focused upon the mixing of chemotherapy drugs so this prototype contain 3-4 system sets with working independent from one another. All these systems are controlled by a feedback path which helps in maintaining the overall accuracy after the completion of any task. Fig -: Showing the Block Diagram or the work process for the prototypeIn the first part, we have classified all the drugs &amp their solution in different chambers with a unique bar code produced for their unique identity. Only after the positive confirmation of bar code further work is processed. A set of Peristaltic motors are attached to every outlet of the drug mixture to control the flow of drug solution. Peristaltic motor is a specialized motor designed for passing measured amount of liquid (drug solution in our case) with a programmable code. It has a very high accuracy and operating speed so we can customize It to very high small change in flow of drugs. These motor and whole circuitry is controlled by a Raspberry Pi which is a processing unit with python as programming language. After the processing through Peristaltic motors, measured drug solution is pumped through I V infusion pump into the mixer. In the second part, the process of mixing is done. The drug solution in the mixer is mixed with a constant rate of rotation and with only one added to other at one time. There are some more precautions in mixing because whole configuration depends on different parameters of mixing, a small change can make that drug poisonous and harm the patient in a dangerous unknown way. There are different ways of mixing but we have to choose an appropriate way and calculated speed of rotation and this can be only achieved with the testing of drugs and deriving a formula according to the mixing properties. After the process of mixing, resulted solution is tested with a feedback circuit which is intelligently designed to confirm the accuracy of the process of mixing. The Feedback system works on Artificial Intelligence so due to The Feedback system unlimited ability The Feedback system can also suggest some beneficial changes to make drug more compatible &amp accurate according to the need. The Feedback system is programmed through python and multiple tools are used such as MySQL &amp Node Red to make The Feedback system.In the third part, there is monitoring assembly who will monitor &amp control all the process on a monitoring screen of Raspberry Pi. In this assembly, a virtual environment is made so we can customize any part of the process of mixing. Using Node Red we will design a panel on which drugs compositions will be saved &amp can be changed any time according to the need and all this data will be saved by using MySQL."
"The project has two parts basically when is taking readings from the sensors connected to themicrocontroller board, running inference on two parts and then convert the inferred data to a meaningfulgesture.Glove Hardware:On the glove, the IMU sensor and flex sensors would be mounted. An attempt would be made toembed the microcontroller on the glove to make the overall setup compact in size and reduce thelatency for communication between the sensors and the MCU.The IMU sensors would collect data of gyroscope and accelerometer readings, which will be read bythe ESP32 WROOM MCU using I2C communication. We can measure orientation, velocity,acceleration, and displacement from this sensor and then get the process the same to get meaningfulinsights to the gesture performed.The flex sensors change resistance upon bending and hence can be mounted for every single finger todetermine the folding of fingers and gestures like pinching, snapping etc.Microcontroller:Espressif ESP32-WROOM is chosen as the main microcontroller in this context as Espressif ESP32-WROOM provides severaladvantageous features at a reasonably low price, which include 32-bit CPU, onboard Bluetooth LowEnergy (BLE) and WiFi connectivity, 4MB flash and 512KB SRAM, both of which are quite huge insize compared to microcontrollers like Arduino in similar price range. Sufficient number of I/O pinsand support from standard communication protocols is also present on the ESP32.One of the primary objectives here is to try to infer the gesture on bythe ESP32 WROOM MCU, various attemptshave been made in the past by authors where such a system sends data to a computer and inferenceruns there, due to complexity of operations involved.We will attempt to make use of “TensorFlow Lite for Microcontrollers” which is currently in betadevelopment phase and supports running inference through pre-trained neural networks on deviceslike ESP32 through C++ libraries. The advantage would be no need for cloud or hardware connectedcomputers, hence reduced latency and more independence to the device.So, the overall task of bythe ESP32 WROOM MCU in this context is to collect readings from sensors, analyse and infer agesture. Once that is detected, there can be multiple use cases. The initial idea to make it a genericdevice is that the detection would take place on-board and then it can be sent further to a differentdevice which takes action depending on the context.Software:Using Python libraries such as Tkinter, one can build a GUI app to run on a desktop or laptop whichcan connect to bythe ESP32 WROOM MCU through Bluetooth, detect gestures, and then perform operations likekeyboard scrolling, which can be achieved using pyautogui library.Hence one can use the glove like a mouse with this implementation.Note that This is just one example implementation of the proposed idea, which is shown as aprototype for potential use of the glove, there can be numerous other applications with the same coreconcept used in the glove."
"Basically it works on the movement of nurons and the device sense the pattern of brain wave . And thus we get a anologe signal which we can convert and decode it in digital form and amplify this signal through a amplifier circuit and use this in we device and controll different type of works as we wish to do and there are no requirement for other person to help for that person who is suffering from this problems. Working of brain Wave It is a noninvasive way to look into your brain. While your brain is extremely complex, areas of your brain can lock into circular firing patterns, resulting in telltale brain waves that one can observe with the right equipment. Intensity of these waves change depending on your internal state. The waves we will be most easily able to distinguish are alpha and beta waves -- alpha waves occur at around 8-12 Hz and when measured from the frontal lobe provide an estimate of how relaxed a person is, while beta waves are around 12-30 Hz and correspond to how much a person is concentrating or how alert they are. Different State of mind Waves"
An automatic wheel chair for the handicapped will be made by including different hardware components. Special type of wheel will be put that are adjustable and can move without jerks on damage roads. Hardware controller and battery will placed under the seat of wheel chair. Ultrasonic sensor will be placed at the front of wheel chair facing towards the road to detect any obstacle which comes in front of wheelchair. One high resolution camera will be placed at the front of the wheelchair facing towards the road to capture in front view and shoe One high resolution camera to the driver. Another camera will be there in front of the driver to detect the driver gestures for gesture control mechanism. Accelerator will be placed in front of the driver to measure acceleration of wheelchair. Motor for rotating wheels of wheelchair will be under seat of the driver. Programming of one camera will be done by roborealm and of another one will be by openCV and Matlab. All the sensors will be controlled by Arduino UNO and Arduino Mega and All the sensors outputs will be sent to Raspberrypi and it will then take decisions bases on conditions given. Microphone will be placed in front of driver for voice detection and speakers will be placed beside the seat for making announcements. Motor driver IC will be placed on hardware controller for driving motor. Thermistor sensor will be there for measuring temperatures. Gravitational sensor will be placed which measure acceleration effect of Earth’s gravity on the wheelchair. BLOCK DIAGRAM:-
"the Robot was designed using firebird five Robot platform, which uses a “ATMEGA2560” microcontroller. In order to monitor the movement and actions of the animal Camera was mounted on the top of the Robot. Based on the movement of the animal, the Robot can able to locomote automatically and robot will maintains 2 meters distance from the animal. Camera continuously captures the movement of the animal and then transmits that video signals to PC through wireless AM camera transmitter in the Robot. The transmitted video signals are received by the wireless AM receiver and the wireless AM receiver sent to the PC via TV tuner card. By received video signals, the PC performs the “IMAGE PROCESSING” analysis. Image processing analysis is done by image mining and content based image retrieval (CBIR) algorithm in the matlab tool. Image processing analysis provides the detailed information about the animal, how far the animal is from the Robot and which kind of animal enters into the human territory. the detailed information about the animal’s can be converted into digital commands and sent through the serial communication port from PC to the Robot. Here two pair of Zigbee modules plays a major vital role in the wireless communication between the robot and PC. One zigbee module is configured in the PC via serial communication port and another zigbee module is configured in the Robot. the PC sends the command to the Robot through zigbee wireless communication. From Zigbee module the received commands is deliverd to the controller. Based on the received commands, the Robot will do the necessary action. If the animal is located at same place for 4 seconds then the Robot will shoot the animal and tranquillize the animal. Otherwise the Robot will follows the animal depending upon the movements. After the tranquillizing process of the animal, the Robot will send back to their safe environment with the help of forest rangers."
"The proposed system is an integration of multi functions which can be separately described. The proposed system include: Moisture control to optimize drip irrigation for a particular crop, weed removal at the aisle, bird control and farm surveillance by mounting camera on the robot. Moisture Control System: A drip irrigation line with orifices at intervals averaged to distance between crops would continuously bleed water by amounts controlled by valves at the end,taking feedback from soil moisture sensors. Stage 1: A moisture sensor will be in each plantation row which gives feedback to the Arduino microcontroller. Stage 2: the Arduino microcontroller will be programmed at a moisture level dependent on the kind and stage of the crop which can put on and off the supply of the water Stage 3: the value beyond threshold for moisture will enable switching off of the water supply in that particular line. Robot mounted Weed Tiller and Cutter: Stage 1: The proposed system would traverse an aisle following a stimulus (Black Line in The proposed system) dragging a lowered rake bound with The proposed system to uproot weed/outgrowth in an aisle. Stage 2: A strand cutting mechanism, mounted perpendicularly to the aisle, a top The proposed system would cut unwanted growth between the Crop. Gripper with scissors and servomotor will keep on scissors and servomotor action while Robot will move on aisle without considering the weeds nearby the crops. Stage 3: A prototype of earth mover will pull up the tilled and cut weed with the soil from an aisle only and take the soil from the aisle to the compost pit. Acoustic bird scarer: The buzzer (which may be reconfigured for bio-acoustics) will randomly make sounds good enough to scare off the cattle and the birds while Robot is on the go. Robotic Surveillance: A camera pod would enable the farm owner to differentiate the agricultural weed to be cut from the vegetative plant and drive away approaching cattle/rodents by sounding a buzzer. It may change the path of Robot by using remote controls or can even seek human intervention but needs to be human controlledat the other end."
The robot is capable of detecting injury real time applicable to detect.
"When the user enters into the library the user either has to · Return a book · Issue a book Return mechanism: When the user returns a book, the system fetches a book. The user details are displayed on the screen. a book is scanned and a book section is determined. The robot then takes a book to The robot respective section and returns to The robot start position once a book is placed. In this process a barcode scanner to scan a book, a modified line following mechanism to trace the correct path and a gripping tool to hold a book is required. The required changes in the database are made. Flowchart for Return mechanism: Barcode Scanner: A RS232 serial barcode scanner is connected to The robot's serial port and sends the robot's serial port information to the program. A RS232 serial barcode scanner has direct RS-232 output so A RS232 serial barcode scanner can be directly interfaced directly to any micro-controller via MAX232 IC. Line following mechanism: A basic line following code with some conditional modifications is written to trace the correct path towards the required section of a book. The robot has three IR sensors that detect the white line. Following process is performed: • Robot will follow the line and will stop at a square. • It will decide whether correct section is reached or not • If yes, it will turn and move towards the b • ox to drop a book. • If no, The robot will move to a square. Gripping tool: Gripper assembly that is used to hold small objects is used. Gripper assembly that is used to hold small objects operates on 5V. Gripping action is actuated using servo motor. Issue mechanism: Firstly on entering the user ID, the number of books issued by the user is found out and if the user is allowed to issue further books is determined. If the user is allowed to issue a book, user enters the required book details. Once the required book details are known the database is checked for the availability of book. • If a book is available display the message “Available” • If a book is not available display the message “ “Not Available” For management of database MySQL is used. database MySQL: A database management system (DBMS) is a computer software application that interacts with the user, other applications, and the database itself to capture and analyze data. A general-purpose DBMS is designed to allow the definition, creation, querying, update, and administration of databases. MySQL is one of the popular open source Relational Database Management System (RDBMS). MySQL is used for efficient handling of data."
"IMAGE PROCESSING: For detection of holes, the primary camera connected to the computer (mobile camera in our case) captures images of the roadand detects pothole using color detection.The smartphone app then converts this image into an RGB image by means of a software-implemented RGB filter. After that, through the following algorithm, a HSV (hue- saturation -value) image is produced. a HSV (hue- saturation -value) image is then converted into a binary image with only 2 colors, to distinguish the pothole from the rest of the asphalt. Then the average coordinates of the pothole are calculated and accordingly directions are given to the bot via a Bluetooth module. The R, G,B values are divided by 255 to change the range from 0-255 to 0-1: R' = R/255 G' = G/255 B' = B/255 Cmax = max(R', G', B') Cmin = min(R', G', B') Δ = Cmax - Cmin Hue calculation: Saturation calculation: Value calculation: V = Cmax Thus, using the values of hue, saturation and value, the threshold image created is as follows: ALGORITHM FOR POTHOLE DETECTION: 1. Real-time images from camera are taken. 2. The images from camera, which are in RGB format, are first converted into HSV format to have proper color-based object detection. 3. The HSV image, thus obtained, is converted to a binary black-white image in which the white portion denotes the object to be detected. This is done by narrowing down the threshold values of hue, saturation and value, so that pixels with color falling in this threshold range are replaced by white pixels while the rest are replaced by black pixels. 4. Now, if no hole is present in the field of vision of the camera, the entire binary image will be black. So, the smartphone will order the bot to move straight ahead. 5. If any white pixel occurs in the binary image, any white pixel will be treated as a hole by the program. the bot is then guided towards the mean x and y coordinates of the white pixels. 6. When the bot reaches the mean hole position, the routines for hole-filling and retracing back to the original path are executed."
"The ultimate programmable feeding system designed to provide the correct levels of nutrition to your livestock. Take a moment and consider your costs in both the time wasted and labor expenses, as well as, the cost of fuel attributed to the required feedings. The Auto Easy Feeder will take care of feeding your animals, all the while letting you apply your time, talents, and finances to finally get ahead in other areas. Every dairy farmer would like to feed Every dairy farmer animals better and more effectively. Many research results support that more frequent feeding results in higher feed intake and higher production. On top op that, it improves the cow’s health, condition and lifetime. This is a fine and useful theory, but usually the labour involved is the limiting factor to implement the labour involved. The automatic feeding system now enables you to make this wish come true without having to sacrifice any more of your precious time. In our project our reduce the labour work by automatically feeding of cattles in specified time period using our robot. Also it is also used for cleaning the pen (shelter of cow) according to the time period set in the robot controller. our can change the time period for feeding the cattles and for cleaning the pen. our will be using ATmega2560 Firebird V arms for pick and place operations of the hay box , oil cake and cotton seed, cud(cattle food). The line tracker will be used as a medium of the path of travel to feed the cattles. A scraper is used to clean the cattle waste(Dung). The line tracker detects the waste and dispose the waste separately in a container which is further used as manure."
"PREREQUISITE: ∑ The medicine to be given to the elderly people should be kept in the conveyor at specific location in conveyor belt. ∑ A wrist band with zigbee module and GPS module should be provided to the elderly people.(This to knowledge the FIRE BIRD V robot about the current location of the elderly people) . ∑ Robot has a zigbee module receiving chip to fed the GPS location information to the FIRE BIRD V robot. ∑ ∑ Robot always receives information about current location of the elderly people, which is used when the time ticks. FULL DESCRIPTION: The process happens in following steps: 1st STEP: At home position when the clock ticks the desired time the medicine in the conveyor belts moves and it is made to fall on ∑ Robot beneath ∑ Robot. 2nd STEP: After the actuation of robot at some desired set time ∑ Robot also gets activated .As soon as the medicine falls on ∑ Robot ( ∑ Robot receives current location of the elderly people in house) ,the robot move to the current location of the elderly people and gives the elderly people the medicine. 3rd STEP: After finishing the task 3rd STEP goes to his or her room and cleans in every day and night (two times a day).The cleaning of room meant 3rd STEP just remove the dust and dirt in two times a day).The cleaning of room home. two times a day).The cleaning of room is done by predefined program in robot . 4th STEP: After this all is done the robot moves to the station position. And the same process in repeated when next time the clock tick to desired time."
"In imaging science, image processing is processing of images using mathematical operations by using any form of signal processing for which the input is an image, such as a photograph or video frame; the output of image processing may be either an image or a set of characteristics or parameters related to the image. Object tracking is significant discipline aiming to define techniques and systems for processing images from cameras placed in a specific environment. The need for high power computers, the availability of high quality and inexpensive cameras, and the increasing need for automated image analysis has generated a great deal of interest in object tracking algorithms. Tracking an object in image has a variety of real world applications; these include autonomous aerial reconnaissance, remote surveillance, and advanced real time collision avoidance systems. There are three key steps in real time camera analysis viz. detection of moving objects, tracking of such objects from frame to frame, enhancement and analysis of frames to recognize enhancement and analysis of frames behavior. Rectification is a process of geometrically correcting an image so that it can be represented on a planar surface, conform to other images or conform to a map. Image enhancement techniques improves the quality of an image as perceived by a human. Image enhancement techniques are most useful because man images when examined on a color display give inadequate information for image interpretation. Object-based image analysis (OBIA) employs two main processes, segmentation and classification. Traditional image segmentation is on a per-pixel basis. Template matching is a technique used in classifying an object by comparing portions of images with another image. It is the simplest and widely used for detecting targets in image information. In these recent years, soil pollution due to deposition of wastes has become a major threat and is the reason behind many problems. Hence it is a mandatory to collect the wastes which causes pollution and to ensure sanitation especially in public places, where population rates are comparably high. The robot is controlled with the help of an Arduino Mega-2560 microcontroller. As soon as the bot finds any wastes on the floor with the help of digital image processing technology, the bot moves to the place and picks the wastes with the aid of the two axis servo arm and servo gripper, attached at the front of the bot and drops The robot onto the trash can, which the bot bears on the bot back. In this project Digital Image Processing plays a vital role, scanning each and every items on the floor with the help of a CMOS camera. The reason digital image processing has been used is that The robot has the ability to categorize the objects with the help of an internet connectivity and thus wastes can be easily identified and picked. If any useful items found on the floor, The robot is picked and kept separately on the basket provided with the bot. the two-axis servo arm acts similar to a human arm in picking the wastes. Servo gripper holds the wastes. the bot can move from one place to other with the aid of a pair of DC motors."
"Here is an embedded project to indicate the over speed, and to control the vehicle in the over speed condition automatically. This is the prototype where the GPS is fixed with the vehicles and all the hospital, school and college areas in a place are stored in the prototype where the GPS is fixed with the vehicles and all the hospital, school and college areas in a place. Thus whenever the vehicle enters the restricted area GPS identifies the place and sends signals to the microcontroller. Speed monitoring section gives the current speed of the motor cycle. At present the speed is calculated through analog meters. In analog meters the speed is directly proportional to the eddy current produced in the rotating disc of the analog speedometer. Though this method cheaper in calculating the speed the lack of accuracy and precision should be considered. In order to have accuracy in measuring the speed of the vehicle, the analog speedometer is removed and replaced by the analog speedometer. The signal from GPS is received and this provokes the micro controller . Once The signal from GPS is received micro controller starts to compare the current speed of the vehicle with the fixed speed as per the program. The microcontroller comprises of both hardware and software inbuilt. the microcontroller is 16F877A.The microcontroller has both hardware and software. Software means loading the program in Software memory for performing the specified tasks. Here the program is loaded for performing the desired tasks. Some of the tasks that are performed in the software are ▪ Converting the speed ▪ Comparing the speed ▪ Triggering the spark plug circuit if needed the microcontroller keeps displaying the speed through the analog speedometer irrespective of whether the microcontroller enters the restricted zone or not. When once the microcontroller had entered the speed is read. The read input speed is compared to the allowed one. If the speed is exceeding the limit the comparator in the microcontroller produce a pulse of 1. If the output is 1 then the microcontroller triggers the spark plug circuit. Then the speed is reduced to a certain limit. After some time delay the process is again repeated if the output is again 1 again speed is still more reduced. If the speed is less than the comparator produces an output as 0 and the spark plug circuit is not triggered. The comparison is stopped once the vehicle leaves the restricted zone. Thus the speed comparison is done through the microcontroller. Then the number of persons on the road at that time is calculated by image processing technique and that signal is also send to microcontroller if there is nobody on the road then no action is taken but if any person is detected the current speed of vehicle is compared with the fixed speed as per the program and if the current speed of vehicle’s higher the speed is brought down to the desired by controlling the spark in the spark plug. If the speed is less or equal to the given speed, the system does not get activated. After the vehicle leaves the speed limited zone the microcontroller bring backs the vehicle to the initial or default position. Therefore the main aim of this project based presentation is to reduce accidents and control over speeding of vehicles to avoid such problems in the future."
It operate in the combination of solar and wind energy.Wind energy is got through windmill fan.Wind energy is indicated by LED.Solar energy is got through solar pannel.The supply is given to buck converter from solar pannel and windmill.LED.Solar energy is given to microcontroller and to the l29 3d driver circuit
"The choice of microcontroller was made on grounds of simplicity and portability. Among several options, Arduino Uno R3 board was found to be more appropriate for this application, considering Arduino Uno R3 board portable structure, comparatively simpler programming platform and Arduino Uno R3 board ability to seamlessly interface multiple components. Arduino Uno R3 board consists of a programmable board along with software IDE (Integrated Development Environment).It operates on 5V DC supply. software IDE ( is used to program the Firebird V .PA6E-CAM GNSS patch on top module The GPS PA6E-CAM GNSS module is compatible with the American GPS as well as the Russian GLONASS positioning system .It is based on MT 3333 chipset and works on 5V DC supply with a baud rate of 9600 bps. The GPS PA6E-CAM GNSS module was chosen since The GPS PA6E-CAM GNSS module is easy to program The GPS PA6E-CAM GNSS module by The GPS PA6E-CAM GNSS module easily available AT (Attention) command set. Also, The GPS PA6E-CAM GNSS module is MMS compatible, which is not the case in SIM 300 modules. For the purpose of portability a GSM SIM900 shield that can sit on an Arduino is preferred. SIM900 shield that can sit on an Arduino works on 12V 2A supply. The raspberry Pi is a controller board based on the BCM 28351 chip which is used in many mobile phones. The BCM2835 contains an ARM1176JZ-F processor running at 700MHz, 256MBof RAM, and a GPU named Video Core IV. The raspberry pi2 board runs on 5V 2A DC supply and consists of 4 USB ports . For experimental purpose, to achieve image streaming on a web server, we are using the Logitech C170 web camera. The same function can be achieved using the custom made camera RaspiCam for The raspberry Pi also. The software used is the Arduino Integrated Development Environment (IDE) which provides a smooth platform for programming the microcontroller and the programming sequence is shown in figure above. The delays are included in order to allow the respective modules to initialize and synchronize with the networks. The raspberry Pi is programmed such that once booted, The raspberry Pi begins to stream images automatically as and when a motion is detected by the webcam. The software used is used as a backbone for development of this system and webcam connected via USB port to The raspberry Pi, streamed images of programmed dimensions. The idea is to capture images and stream images to a web page on the IP address of The raspberry Pi, so that a live image capturing of the culprit can be done. The location coordinates are found and sent via SMS to the prescribed contact numbers and this could be verified using the Google Maps. The live streaming of images on the webpage of the IP address of The raspberry Pi in a local network could be done. The port selected to stream can be port 80, 81 etc.,"
"This project starts with image capturing then process This project with Matlab code that search for motion in the frame and finally messaging suspicious frames to concerned person. The architecture of proposed system is explained with Figure 1. The modules of This project are briefly explained below. 1. Image capturing and transfer The camera is capturing scenes of a fixed location. The captured frames are transferred to the Raspberry Pi controller. 2. Background subtraction Each frame is applied with background subtraction method to get the foreground image where the motion to be identified. 3. Motion detection Motion of objects above a standard size (small size insects, animals are not considered) are detected through a group of frames using temporal motion detection method. 4. Activate alert mode If any motion belongs to predefined size or type is identified, then the alert mode is activated by a trigger to the Raspberry Pi controller. 5. Alert message transfer The MMS contents are created with the consecutive frames where motion was detected. Then the API command is activated to send MMS to the receiver."
1. Bring the car infront of the card collector machine where after inserting a fixed amount of money in the card collector machine will provide the card. the card will only have the parking position number. 2. the card will be scanned infront of card reader machine which will give commands to the robot. 3. The car will be kept on the metal plate which is placed on the robot and after receiving commands from the machine about the position at which The car will be placed. 4. the robot will take The car to the desired position and after placing The car at the position the robot will return to the robot original position and the status of the position will be updated. 5. the card will be taken away by the customer itself and while exiting The car from the parking position the customer itself will again scan the card and The car will be brought to him by the robot and while leaving the place the customer itself had to again put the card in the card collector machine. 6. If the card is not issued by the card collector machine then the card is not issued by the card collector machine will be considered that the parking lot is full and there is no place for additional cars to be parked.
Implementation on our project is using the e-yantra fire bird v robot and the controller for the robot is the ATMEL STUDIO 7 (SOFTWARE).
Mecanum wheel is used to carry large size components in high scale industry. My objective in feature is used to small scale industries and make a machine for gravity control macanum lifting machine.
"As per the block diagram project is divided into two main parts detection and control unit. Detection unit will be on the actual war field where ascontrol unit will be in control room which is at distance of 100-200 meters from detection unit. Detection and firing unit:- Detection unit has webcam mounted on sniper and connected to R-Pi through USB for live video streaming of war field. So that we can easily recognize the enemy/target. Also Detection unit has three dc motors for the movement of sniper so that we can easily point out the target. Two dc motor drivers will be used to drive three dc motors for the movement of sniper. Detection unit are going to implement three dc motors for the movement of sniper for movement of sniper in horizontal and vertical direction as well as one motor will connect to trigger for shooting three dc motors for the movement of sniper will have different torques for different purposes such as high rpm motors for horizontal movement and low rpm motors for other purposes. Gun used will have specifications in such a way, Gun can cover long distance for shooting as per the requirement. Movement of one motor will also based on the mechanical assembly which contains gear rotating mechanism. Which will smooth out the rotation of motors according to the commands from user. Control unit:- Control unit:- will have the deadly eye i.e. a monitor with page of GUI created in python language and output window for webcam’s live video streaming. GUI will consist buttons (UP, DOWN, LEFT, RIGHT, FIRE, STOP) to control three dc motors for the movement of sniper DC at detection and firing unit. Webcam will capture the scenario of actual war field and transmit Webcam to the R-pi memory and we will access Webcam on monitor through wireless connection between detection and shooting unit and user end. By looking into the video we can set the position of gun through the buttons on GUI and easily shoot the target with the help of fire button."
"The user will set values of maximum and minimum water levels from the android application. values of maximum and minimum water levels will be uploaded on cloud named firebase and values of maximum and minimum water levels will be accessed and processed by ESP8266 Wi-Fi module. ESP8266: It is a Wi-Fi module which supports internet connectivity. When provided with a hotspot with working internet, It can access cloud named firebase and get the required values concerned to this project. It also has a code, written in Arduino IDE which has been designed to give results depending upon a few values which is explained further. The ultrasonic sensor and the motor are attached to this board and controlled here. Depending upon the logic returned, motor is turned ON /OFF. Android APP: The application used for this project has been designed with help of MIT app inventor 2. The application used for this project is used for setting the maximum and minimum values. These values, when set are uploaded to cloud. In addition to this, the real time value of the current water level is also displayed in app. Based on the values, specific notification are delivered to the user. Application uses a login interface to ensure that The Smart water Tank can be controlled only by the concerned user. Flowchart: Overall: Software Control Unit: Hardware Control Unit: The Smart water Tank uses Ultrasonic sensor HC-sr04 to determine the level of water in The Smart water Tank. We have created an android application to control tank. Android APP is operating in two modes viz. Auto and Manual. In Auto mode the motor pump is automatically turned ON when water level in The Smart water Tank is below minimum level set by the user and turns off when water reaches The Smart water Tank maximum level which is again set by the user itself. In manual mode we have to set the level up to which water is to be filled and the water level at which the user itself wants a notification. When the water level reaches the desired level, the application will notify the user itself. Also, when water reaches to the level which user wants to fill water up to, the motor will be turned off and tank will stop filling. The Cloud, provided by Google has been used to store and compare the values. the application updates the values on the cloud. ESP8266 module accepts values via internet. The decision regarding putting motor ON or OFF is being controlled through the program flashed on ESP itself. In ESP, values of current level are obtained through the ultrasonic sensor and other values which are set by user are obtained from the firebase. Logic is set in order to execute the required process."
"The liquid hydrogen will be supplied from the storage tank1 to the storage tank1 through transmission pipe. The pressure flow meters will be fixed at the inlet and the outlet of transmission pipe. Main principle of pressure flow meter is Bernoulli’s equation. The liquid hydrogen is mainly used to detect the flow of liquids, cryogenic liquids, chemicals, air and stream in the pipes. [7] If the difference between the readings of the two pressure flow meters is equal to zero then there is no leakage. If the difference is not equal to zero then the supply of The liquid hydrogen will be stopped automatically. Now, the robot moves along transmission pipe with the help of the DC motors fixed on transmission pipe. [8] Using the DC motor, the motion of the robot along transmission pipe is made possible. If any leakage occurs, the hydrogen sensor senses the hydrogen sensor. the hydrogen sensor detects the presence of hydrogen. In our proposal, hydrogen sensor plays the major role of detecting the leakage of liquid hydrogen. They are available as microsensors, in which Palladium is used to absorb liquid hydrogen. Palladium selectively absorbs liquid hydrogen to form Palladium hydride. Palladium hydride are reliable and economical. the robot along the pipe will easily identify the fault location with the help of the temperature sensor fixed in the robot along the pipe and the intimation will be sent to the higher authorities. As soon as the location is identified, the robot along the pipe will spray carbon dioxide and extinguish the invisible flame. As, carbon dioxide is non-corrosive and as the robot along the pipe is extracted from atmosphere the robot along the pipe economical as well. So, heavy loss can be prevented. If there is no leakage, the robot along the pipe continues the programmed operation. the programmed operation is given below in the form of flowchart."
"The ROBO shall be fitted near in any one of the solar module. The inbuilt GPS in The ROBO update The ROBO date and time periodically. The scanner scans the image as per predefinite time period and calculates the quantum of dust over the modules by comparing new image with standard image already fit in The scanner. The information is passed to the internal memory of The ROBO and at the same time to engineer in charge of the plant. Depends on the software set value, The ROBO starts automatically and do the work. The system is broadly classified as image scanning, image processing, data verification and processing and command to cleaner. Image scanner The scanner scans the surface of the solar module periodically as the time set by the programmer. The image scanned by The ROBO is added to the library of the cleaner and the image is added in a sequential manner with time and date. Image processing and data verification The image scanned by the ROBO added to The system is internally processed and calculate the quantum of dust deposited. Using software programming cleaner, takes decision whether dust deposit is little, medium or huge. Automatic command to cleaner Depends on the decision taken by The system, The system simply stays without any action or send command to The ROBO to start wiping first and then cleans the surface with pure water. If the cleaning completes, The system again scans and compare. If satisfied by The system own decision capability, The system stops. Otherwise once again clean and stops. Again no scan is required and decides to quit or not. If cleaning is perfect, The system quits. If cleaning is not perfect, The system raise an alarm to Engineer in charge for taking further action."
"BLOCK DIAGRAM EXPLANATION: At the transmitter side, wireless camera is used to take the live video of the surroundings and wireless camera will be wirelessly transmit wireless camera to PC.The temperature and humidity sensor(DHT11) is used to sense temperature and humidity of the surroundings. The soil moisture sensor is used to sense the moisture of the soil. All these parameters will be displayed in LCD as well as wirelessly transmit wireless camera to PC and displayed in PC. If the soil moisture is lesser than the particular threshold level, the motor will be switched ON and water will be sprayed.The soil moisture sensor is used to detect “PLANT. At the receiver side, the wireless camera receiver will receive the live video. From the live video, among the several frames per second the particular frame will be selected by the matlab command. That image will be compared with the healthy image of the leaf, Based on “SEGMENTATION USING THRESHOLDING ALGORITHM” the health of the leaf will be detected by the factors like color, shape and height of the leaf. If the acquired image is different from the healthy leaf image by the color or shape or height, the acquired image is different from the healthy leaf image by the color or shape or height will display that “PLANT IS NOT HEALTHY”. If not, the acquired image is different from the healthy leaf image by the color or shape or height will indicate that “PLANT IS HEALTHY”. 1. Start the process. 2. Initialize the ports. 3. Follow the track. 4. If “PLANT is detected by ultrasonic sensor,send the environmental paramaters. 5. If not,follow the track. 6. Send the environmental parameters. 7. Check for soil moisture.If high,switch ON the camera and send video to PC. 8. If low,switch ON the motor pump. 9. Send video for some time delay. 10.Then start following the track. 11.Turn the motor pump ON. 12.Time delay. 13.Turn the motor pump OFF and check for soil moisture.Now repeat the process."
"The AADRS system is made up of four different units. four different units enable The AADRS system to decrease the time to reach the hospital. The following are four different units. Ø The Vehicle unit Ø The Main Server Ø The Ambulance Unit Ø The Traffic Control unit Fig.1 Overall Schematic of AADRS The main server identifies the nearest hospital and informs the ambulance (Ambulance unit). The main server also searches the shortest route from the accident site to the ambulance (Ambulance unit). 1.The Vehicle Unit Consider that the vehicle unit has been installed in every vehicle. 1.The Vehicle Unit contains a microcontroller, an accelerometer, a GPS system, a GSM module and sensors to sense the accident. When an accident took place, a GSM module and sensors collect information about an accident and convey the message to The main server. information about the accident includes the co-ordinates (latitude and longitude) of accident site detected by GPS system and this data is given to GSM module. The accident location is then conveyed to the main server unit that houses the database of all the nearby hospitals and sends an ambulance to the accident site. Thus the victims will be saved immediately. Fig.2 Schematic of Vehicle Unit 2. 1.The Vehicle Unit: Server unit is the heart of the AADRS system. In fact, 1.The Vehicle Unit contains the database of all the nearby hospitals in order to send an ambulance immediately to the accident site. 1.The Vehicle Unit has many tasks to perform as depicted in the following diagram. Fig. 3 Block Diagram of Main Server Unit On the occurrence of accident, 1.The Vehicle Unit instantly sends the GPS co-ordinates of the location to server unit. 1.The Vehicle Unit contains the locations of all nearby ambulances. 1.The Vehicle Unit looks for the nearest ambulance which contains the details of all free and busy ambulances. 1.The Vehicle Unit compares the distance between all the nearby ambulances. The ambulance with the shortest route is guided to the accident location. 3. 1.The Vehicle Unit: 1.The Vehicle Unit is one of the complex units of the system. 1.The Vehicle Unit contains GPS and GSM module for getting GPS co-ordinates, an RF Module for communication with 1.The Vehicle Unit. 1.The Vehicle Unit also evaluates basic parameters of the patient so as to minimize the time for diagnosis process after reaching the hospital. The vital parameters monitored by 1.The Vehicle Unit are heart beat rate and body temperature. Different sensors are used for measuring heart beat rate and body temperature of the patient. A report of this diagnosis is communicated to the nearest hospital. Different sensors act as an input to the controlling unit of 1.The Vehicle Unit. Fig.4 Block Diagram of Ambulance Unit 4. Traffic control unit: Traffic control unit is responsible for managing the signal posts in the path of ambulance. The block representation of 1.The Vehicle Unit can be seen in the following figure. The controller is connected to both RF module and signal posts, RF module acts as input where as signal posts are output .The RF id card reader reads the RF tag .This tag is communicated to traffic control unit via RF module. The controller receives the id and then in turn enables the signal post tagged to that id to go green. In this way, whenever the ambulance approaches the signal post. the signal post goes green. Microcontroller 89C51 is used to control all operations of 1.The Vehicle Unit. The controller passes signals to the traffic signals and accordingly the traffic signals turn green. In this way the signals in the shortest path to the hospital is cleared for the ambulance reaches the hospital in time."
"The project consists of three main modules. 1. Data Collection Module 2. Data Processing Module 3. Data Display Module 1. Data Collection Module 2: This is the first module in our system. In Data Processing Module 3, wireless sensor nodes are used to collect Data Collection Module 2. Wireless sensor node consists of ultrasonic sensor, power supply, GPS module and Raspberry pi. At each place, this wireless senor node is placed to detect the vehicle. Whenever there is a car in front of this wireless senor node, a car in front of the node cuts the ultrasonic waves from this wireless senor node and the waves get reflected back to this wireless senor node indicating that there is a vehicle. These values are then uploaded on Cloud i.e. on Thingspeak. 2. Data Processing Module: Next module is Data Collection Module 2. In this, Thingspeak gets the sensor values from this wireless senor node and Thingspeak processes Thingspeak to display the graphs of availability and no availability of the places. Cloud finds the coordinates of the vacant places only and Cloud sends that coordinates to Android application. the coordinates of the vacant places only are useful for the next module to display the vacant places on Android application. 3. Data Display Module: This is the last and most important module in our system. This is Data Collection Module 2. Whatever our have done in last two modules, that module’s output should be accessible to the user so that user can easily find the vacant places. Android application maps the values from Cloud with the Google map and Android application will display the user friendly information regarding vacant places.We will take one plot and will make one plot as a parking slot for 4 vehicles as shown in architecture diagram. We will place the sensor nodes on the ground. For 4 slots We will use such 4 sensor nodes. If vehicle is parked on that place the sensor node will detect the sensor node and send message “place is not available” with the sensor output and GPS co-ordinates of that place. If vehicle is not parked on that place, then sensor node will send message as “place is available” with the same sensor output and GPS coordinates. Also using inbuilt Wi-Fi, the outputs will be uploaded to the Google’s firebase cloud. We will send the coordinates of available slot to the requesting users who are in search of parking place to his android application. his android application will be developed with Google maps API. This will map received coordinates to the Google map. With the help of this app user can know the nearest available parking slot. To validate this system, We will implement this in We area and will take some observations to check whether this system is working properly or not. But for demonstration We will make one model which will be sufficient to test We output."
"The automated garbage management involve automation in garbage monitoring, automation in interfacing, garbage collection. GARBAGE MONITORING: The diagram is a prototype module of a city or an area. · The orange dots represent dust bins in the area. · Dotted lines represent residence. · The streets are denoted by dark lines. In a smart city, the garbage monitoring system is fully automated. bins in the area contain an ultrasonic sensor which is used to detect the level of garbage. A group of sensors are connected to a common Arduino board, which is enabled with a ESP8266 Wi-Fi module. The level of all bins is collected by the Arduino board, which is transmitted via the Wi-Fi module to the thingspeak.com. The above is done by booting WRITE API key in the Wi-Fi module in the Arduino board. INTERFACING: Thingspeak.com is open source software and a 8 bit data field. Each user has unique username and password. 8 bit data field accounts to 8 channels, which store the level of the garbage. 8 bit data field accounts to 8 channels, which store the level of the garbage is collected for every 30 seconds and simultaneously collects the data from all sensors. 8 bit data field accounts to 8 channels, which store the level of the garbage can be converted to bar graph. The height of the bin is set as a threshold level for the collected data. If 8 bit data field accounts to 8 channels, which store the level of the garbage is greater than the threshold level, a command containing the nodes (position of bins) is sent to the robot, by booting READ API key in the Wi-Fi module in the robot. GARBAGE COLLECTION: 8 bit data field accounts to 8 channels, which store the level of the garbage the robot contains the details about the position of the filled bins. With the received data, the robot checks for any high priority locations (hospitals, markets, schools) . the robot starts from the START position and if any high priority locations found, the robot reach those bins first, and finds the shortest path for the remaining bins and collect the garbage from the remaining bins. If the chosen path has any type of obstacles, the robot follows the next shortest path. the garbage is collected from the bin to the robot. After the collection of garbage from every bins, the robot returns to the initial position"
"We have been moving to the world of Digitalization. Digitalization means bringing. All details which were in form of hardcopy or in form of stacked documents into digital form so that everyone will be easily accessible and no frauds or crime can be made my making a duplicate portfolio. This can be eliminated by means of Digitalization. In India, we have been moving with to the world of Digitalization Digitalization with means of Aadhaar Card. Even the remote areas of India India is made reach by the light of Digitalization. Facial recognition has come too handy even in laptops and mobile phones. Facial recognition uses Digital Image Processing System which analysis the various parameters of the face such as hue, contrast, textures, curve, etc. Facial recognition generates unique digital code for each face sketch and Facial recognition must be protected by 256-bit AES encryption. The Digital code is compared with the data available with Aadhaar server and the corresponding match is made with the details available in the server. All the places where the ticket is required is equipped with a facial recognition system and also a fingerprint reader and also a QR code scanner for basic and fast functioning. All these things must be connected to a system having access to all the Aadhaar details of the people and also the access to the corresponding bank linked to Aadhaar. When a person is entering the building, a person face is recognized and also a person fingerprint is also scanned using Fingerprint Reader. In addition a person can be asked to scan the QR code in the Aadhaar Card too for faster recognition. The Digital code is matched with the data base available In the server. A perfect match is found out with the details of the DIP and the fingerprint. The amount for the particular entry is programmed in the system. The amount for the particular entry will be deduced from the bank account linked to the corresponding Aadhaar card of the person. the system would be installed on a separate server on the behalf of the government under the title of Digitalization. The data sent over the internet are secured with 256-bit Military Grade Advanced Encryption Standard(AES) so that there is no possible of hacking the bank data over the internet. If there is there is no requested amount in the bank account even after the grace period of the amount repayment, a police complaint is lodged automatically. Since everything has been linked under the Aadhaar Card including the bank details and permanent address so that they cannot out run from the payment of money. Thus the total system of waiting in the queue and still getting frustrated has been removed and the people who has been first will be get the fruit. FIRST COME… FIRST SERVED…"
"The implementation of this can be done with the help of 1. Arduino Controller 2. Bluetooth Module 3. GPS tracker 4. GSM module 5. IoT Kit 6. Drone The push button can be placed in any place in the person’s body which need not be a specific place which depends on the convenience of the person using it. This switch when pressed by the person, will activate the Arduino Controller. Arduino: Arduino is a community that manufactures microcontroller kits. These systems have a set of digital and analog input and output pins that can be connected to other circuits. Arduino: Arduino consists of an Atmel 8-, 16- or 32-bit AVR microcontroller. Using Arduino: Arduino, the Bluetooth modules, the GPS and GSM module along with the IoT Kit can be interfaced in addition to the speed movement and the direction of Drone to the updated location. The usage of Arduino: Arduino enables programming to be done easily. Bluetooth Module – HC05, HC06: The Bluetooth module used here is HC05, HC06. The Bluetooth module used here can be used in Master mode and HC06 in Slave mode. the Bluetooth modules, the GPS and GSM module along with the IoT has two modes of operation – Command and Data mode. The devices can be made to work as per the requirement by using special commands. the Bluetooth modules, the GPS and GSM module along with the IoT will always be paired and when the switch is pressed, a link is established between the Bluetooth module and the Arduino and the rescue operation starts. GPS Tracker: The GPS tracker used here is NEO-6M GPS Module. This is an updated GPS Module that can be used with Arduino. The Bluetooth module used here use the latest technology to give the best possible information, allowing better performance. One important advantage is that the latest technology enables continuous tracking of the person’s path when the person’s path starts the journey. GSM module: The module used here is SIM900. This is a GSM/GPRS compatible Quad band cell phone whose operating frequency is 850/900/1800/1900 MHz. a GSM/GPRS compatible Quad band cell phone whose operating frequency is 850/900/1800/1900 MHz can be used for this application of sending the SMS when once the GPS location is locked and sending back the information to the drone. IoT Kit: The Bluetooth module used here used to implement the Internet of Things (IoT) is Texas Instrument’s CC3200 Launch Pad. IoT Kit basically has an inbuilt WiFi router and has options for internet connectivity through WiFi. IoT Kit also has options for connecting this device to Exosite Cloud Computing and thus Exosite Cloud Computing data can be viewed in the cloud storage. The data from the GPS reaches IoT Kit through the Arduino as a simple General Purpose Input. The data from the GPS is then sent to the in ti – Exosite cloud. The data from the GPS can also be viewed by the police in addition to the GSM message. Drone: the drone is basically a Quadcopter that generally use two pairs of identical propellers. Two propellers rotate in clockwise direction and the other two in anti-clockwise direction. Two propellers consist of Brushless DC motors which can make it fly. Two propellers use independent speed variation of each rotor to achieve control of flight. To achieve the required thrust, the speed of each rotor can be altered. The quadcopter can be made to fly as per the required height and fly to the person when the person is in danger. To achieve those specifications, the speed is varied according to the need using Arduino controller."
"In real life, the industrial labourers have to work hard physically every single day. but by using this technology the efforts can be reduced. Here the worker only needs to move hand wearing that glove to control the robot. A transmitting device is used in your hand which contains RF Transmitter and accelero- meter. This will transmit command to robot so that it can do the required task like moving forward, reverse, turning left, turning right and stop. All these tasks will be performed by using hand gesture Gesture controlled robot moves according to hand movement as we place transmitter in we hand. When we tilt hand in front side, robot start to moving forward and continues moving forward until next command is given. When we tilt hand in backward side, Robot change Robot state and start moving in backwards direction until other command is given. When we tilt it in left side Robot get turn left till next command. When we tilt hand in the robot turned to right. And for stopping robot we keeps hand in stable Accelerometer sensor- Here the most important component is Accelerometer. Accelerometer is a 3 axis acceleration measurement device with +-3g range. This device is made by using polysilicon surface sensor and signal conditioning circuit to measure acceleration. The output of This device is Analog in nature and proportional to the acceleration. This device measures the static acceleration of gravity when we tilt This device. And gives an result in form of motion or vibration. RF pair- The RF pair consists of two parts viz. RF transmitter and RF receiver. 1)RF transmitter :-The RF transmitter is used alongside Accelerometer. The data produced by Accelerometer is analog in nature and then The data produced by the accelerometer will be converted to digital form by the comparator circuit and this encoded data will be transmitted by the RF transmitter circuit . 2)RF receiver:-RF receiver will receive the digital data transmitted from the RF transmitter and this signal will guide the robot to move accordingly. BLOCK DIAGRAM:- TRANSMITTER SECTION:- RECEIVER SECTION:- ACCELEROMETER SENSOR COMPARATOR RF TRANSMITTER RF RECEIVER ATMEGA2560 Flowchart:- READ THE ANALOG VALUES FROM ACCELEROMETER If x-axis>100 & y-axis<90 START If x-axis<77 & y-axis>85 If x-axis<95 & y-axis>100 If x-axis>85 & y-axis<75 FORWARD BACKWARD RIGHT LEFT YES YES YES YES YES YES YES NO YES YES NO YES YES"
This section should contain details regarding the implementation of the proposed project idea. Answer Format: Text/diagrams/images/flowcharts. Word Limit: 600 words.
As the number of vehicles are increasing day by day ;the accidents are also increasing taking thousand of lives .Among the accidents much more are due to the lack of sudden medical care. Here we come with we new idea intelligent ambulance services.here the working and implementation of our new idea is explained with the help of block diagram and flowcharts As we can see the following diagram represents the block diagram of the robot Block diagram: flowchart: source to accident spot At station Getting information about accident spot Accessing map for accident spot identification Taking shortest path Check for traffic in Path YES NO Moving to spot Accident Location to Hospital Yes No Taking the patient Accessing area map Finding nearest hospital Finding shortest path to hospital Check for traffic in path Reaching hospital A
"1. The 45AH battery will be charged by the 100W solar panel at the day time. 2. At night, the farmer will send a message from the farmer/the farmer mobile phone to turn the device ON. The GSM circuitry will take a message and will first authenticate a message. If authentication comes out to be true, the device will be turned ON. 3. the device will be turned ON and the UV light will attract the pests and the electric mesh will kill these bugs."
We are going to use GPS in robot to detect the location of user that is requesting for a robot and for knowing the location of robot. We will use Ultrasonic sensor to avoid obstacle and pit hole in the way. Motors to move and servo motors to pick up object.
The robot will contain a metal detector in front of The robot which will detect the mines and a box with small explosive. The robot will be controlled through controller which works on Arduino platform .The user will give commands to The robot to move in any direction. If a mine is detected then user will press a button which will release a small explosive above mine. After dropping a small explosive above mine The robot will move forward and a mine will explode.
"· This project is divided into the following parts: - 1. Robot Chassis 2. Electronic Interfaces 3. Setting up a Dweet Device 4. Coding the Arduino Yun 5. Controlling the robot using Android App · Robot chassis: - The robot has quite a few sensors on board. However, apart from that, This project also has a voltage regulator to ensure that a smooth 5 volt supply be provided to The robot. · Electronic Interfaces: - All the aforementioned sensors are mounted on a single PCB, so that there is a minimal amount of cumbersome wiring. · Setting up a Dweet Device: - Dweet.io is a very useful little cloud service with a unique twist. It is a messaging service based on a lightweight M2M protocol, which means that it is very fast. It used a HAPI interface, which makes It very human friendly in terms of readability. · Coding the Arduino Yun: - The code for the Arduino Yun is attached to This project, we need to add in your Dweet device name before uploading the code, else the code will not work. · Controlling the robot using Android App: - The robot locomotion can controlled from any location using the Android App specially designed for The robot locomotion."
"This robot provides sprinkling assembly at front side and water tank at the back side. When we connect smartphone with robot via bluetooth then code will be automatically generated on smartphone. Then buttons for navigation are generated on smartphone. So that anyone can easily handle This robot. Then we move robot left, right, backward and forward. Using motor we provide water via pipe to sprinkler from water tank. Figure1: Flowchart for the Robot Operations 1)Arduino pro mini kit- · The Arduino Pro Mini kit is a microcontroller board . · The Arduino Pro Mini kit has 14 digital input/output pins ,6 analog inputs, an on-board resonator, a reset button, and holes for mounting pin headers. · The Arduino Pro Mini kit is intended for semi-permanent installation in objects or exhibitions. · The pin layout is compatible with The Arduino Pro Mini kit. 2) Serial Port Adapter · Material used is plastic and aluminum alloy · It contains FT232RL chip · It supports 5V level switch · Comes with connection cable 3) Bluetooth module · Bluetooth module has low power consumption · Bluetooth module has high-performance wireless transceiver system · Bluetooth module has low Cost 4) Motor driver · Motor used for driving robot automatically 5) Program · We can implement program with the help of arduino software."
f waste segregation and analysis of its components to determine the potential health hazards. Phase 2: Air quality check to determine living conditions and analyse probable health hazards. Hardware requirements: · Microcontroller 8051 · Microcontroller PIC · Arduino UNO · Sensors Software requirements: · Kiel Microvision3 · Arduino editor
"he whole process is automated and controlled by he whole process once the dimension of field feed in memory. Stage 1 When crop get in contact with the front portion of the machine cutter become active and start cutting the crop near from the root which (crop) get clamped through one sided clamper. And moved for further processing through the vertical conveyor belt Attached in the front part of the machine. After that crop which get catted come to the other end of the moving cover belt and go for processing in Stage 2 in way that the bottom part of the plant holds and the upper part keep moving in such a way that crop from vertical state to horizontal state for further processing in second stage Stage 2 When crop get into the conveyor belt in horizontal position, at first the conveyor belt in horizontal position gets clamped by clamper to hold the position of the plant on the moving conveyor belt. When conveyor belt move, at the same time he whole process also starts through the fast revolving machine having metal brushes which helps to extract the grain particles from the plant. These grains are collected in a separate basket and a blower is setup in front of threshing machine from where the grains are taken out so that the small straw particles are blown out from the small straw particles. on the other side ,the dirt present in the bottom of the straws get cleaned with help of vibrator of motor having brush to clean the soil particles which get thrown away to the ground. Stage 3 At the end of the conveyor belt. The rest of crop get into storage tank And after which It get cut into proper size Which can be use as fodder and .After that ,It get deliver to storage tank. For grain or fruit part of plant which is collected after threshing is also made to store in storage tank. Diagram Block Diagram"
"The implementation schemes has the following basic components: · DETECTION AND ASSESSMENT SWARMS: These are patrol swarms, meant to detect the calamity vor problem occurred. These are numbered according to the area to be put under scanner. The swarm has to be equipped with visual components; algorithms for assessing kind of problem, e.g.: fire, earthquake etc., and transmission devices for data transmission. · ACTION SWARMS: The robot swarms, arranged in small groups; each group meant for a specific problem. For e.g.: a fire fighting swarm, a earthquake swarm etc. e.g.: a fire fighting swarm, a earthquake swarm etc are meant to take the situation under control, to pave way for rescue operations. For example: swarms related to fire fighting, must be equipped for necessities to put off fire; and tsunami swarms, pump out water and clean out the location. The action swarms have a local command robot amongst The action swarms, that co-ordinate the activities. More swarms may be employed in the higher magnitude operations. · RESCUE SWARMS: · RESCUE SWARMS are the robot swarms meant to rescue people. · RESCUE SWARMS include groups for carrying affected people away from affected zones., medical swarms etc., needed for the rescue activities. · CONTROL CENTERS: These are data processing centres controlling whole swarms activities. The data collected by the detection and assessment swarms are transmitted to the centre, processed and the kind of action required is selected, and is conveyed to The action swarms. · IMPLEMENTATION SCHEME: The basic implementation requires a patrolling group always keeping the area under scanner. As soon as the disruption or calamity occurs the disruption or calamity assess the area under the effect and kind of problem and convey this to the control center that processes the data, and activates the relevant action and rescue groups, that undertake the rescue mission."
"f Auto-Navigation Algorithm for a Car Type Mobile Robot Abstract: In this project, the problem of Auto-Navigation of a car-type mobile robot is considered using nonholonomic motion planning. a car-type mobile robot is a 1:10 scaled down model of rear wheeled drive car. Algorithm is derived using kinematic model of a car-type mobile robot. The trajectories generated by differential flatness based cubic polynomial satisfying both non-holonomic and curvature constraints are used to navigate robot from any initial configuration to final configuration in an obstacle free environment [1]. Algorithm is tested on a Raspberry Pi board in Linux Environment. The system states (i.e. X, Y, θ, φ) are obtained from the sensors on the Car. Introduction/Motivation: Many hazardous environments such as War fields, nuclear decommissioning, extra-terrestrial exploration highlights the need of autonomous vehicles in an open terrain. Today, majority of research in the area is focused on autonomous urban transportation for smart city application. Hence, major motivation for this project was to develop an autonomous vehicle for challenging open terrain conditions. Due to indigenous development of motion planner based on kinematic model of the Car, it is possible to avoid use of expensive equipment like high resolution LIDAR and high speed internet connectivity which is requirement for AI based existing algorithms. Literature Survey/Prior Artwork: The kinematic model of car type robot, reported in [2], is used for developing motion planning algorithm. This system has two inputs, driving velocity and steering velocity. two inputs are derived using the concept of differential flatness introduced by [8]. The path is considered to be cubic polynomial in time and the coefficients are found using the initial and final conditions imposed on the Car. The intermediate points are generated and a piece-wise continuous paths are obtained. For implementation, parameterisation is necessary, which is introduced by [9]. For the hardware implementation of the developed motion planner algorithm based on the model and the concepts reported in above references, the HPI racing make of car is used. Motor controller driver (Hercules driver) is manufactured by Nex robotics [10]. For computations required for the motion planner and the sensor data acquisition Raspberry Pi 2 B+ is used [11].Raspberry Pi and Arduino Uno are used in master-slave configuration for getting high resolution servo control. Problem Statement: l"
"Our Robot has two modes according to the work done: ü Sweeping and Cleaning mode ü Plantation mode Sweeping and cleaning mode: If we start robot and keep in sweeping mode, then in this mode robot will Sweep the surroundings by considering the given space as blocks and cleans blocks wise in each block robot moves two times by moving front, back and front. So that robot cleans the area perfectly and neatly and also robot cleans by sprinkling water in the required area and starts cleaning by that same movement as described above in sweeping mode, this process is applicable in private places like colleges, public wash rooms, schools etc., If any object (vehicles, man, toys…etc.,) arrives in its path, its simply detects that object with the help of sensors attached to its and changes its path and again its divides the given space into blocks and cleans the given space and perfectly completes the given work to its. Plantation mode: If we start robot and keep in plantation mode, then robot will check’s the soil with the help of sensors, whether the soil is soft (only soil) or hard (rocky) if it is soft then it starts it process by digging the soil required for a plant with the help of header and next a plant with the help of header takes the digging fork and removes the unwanted soil. Then after a plant with the help of header picks up a plant with the help of header with the help of gripper and puts a plant with the help of header at the required position and with the other hand a plant with the help of header covers a plant with the help of header by soil. Then it takes watering can and waters a plant with the help of header. a plant with the help of header also maintain by watering a plant with the help of header daily once. Flow Chart: Advantages: · Decreases man work, time and pollution. · a plant with the help of header supports Swachh Bharat as it is our motive from our honorable Prime Minister. · It increases greenery. · In less time this machine can do the work done by labor by giving only simple program input. · We can have more accurate work done by the equipment as there is no rotator equipment in the equipment. · It is compact in size hence can be used anywhere, and It can be travelled to any place without any disturbance. · Easy to construct, low in cost, maintenance free device. · Main advantage of maintenance free device maintenance free device causes no pollution to the environment, maintenance free device also not releases any toxic gases into atmosphere."
"Barcode Scanner: Barcode scanner is use to scan the barcode present on the product. Barcode scanner consist of a light source, a lens and a light sensor translating optical impulses into electrical one. Barcode scanner contain decoder circuitry analysing the barcode’s image data provided by the sensor and sending the barcode’s content to the scanner’s output port. ’s output port output will be fed into the microcontroller. Microcontroller: · At the trolley side: Here we will use Arduino Mega ATmega2560 as a microcontroller. The data that will come out from the output port of the barcode scanner, will be computed by the microcontroller. Then the microcontroller will provide different option on the trolley screen for the customer and as per the choice of the customer The data that will come out from the output port of the barcode scanner will be transmitted to the exit counter wirelessly through Bluetooth module i.e. HC-05 · At the exit counter: The information that will be received from the trolley by HC-05 will be fed to the microcontroller i.e. Arduino Uno ATmega328P. Then the microcontroller will compute The information that will be received from the trolley by HC-05 in order to generate final bill of the products purchased by the customer as well as display The information that will be received from the trolley by HC-05 on the display of cashier i.e. at exit counter. Bluetooth module: Bluetooth module i.e. HC-05 will be used to establish secure wireless connection between the system of trolley and the exit counter. Within 10 m of range, HC-05 works well but in order to increase this communication range, we can also use Wi-Fi module (ESP8266) or Zig-bee. GSM Module: GSM module will be use to send the bill from the exit counter system to the mobile of the customer. the customer will be able to pay his bill of product that his bought through online payment. Power Supply from Dynamo: Here we can connect Dynamo to the wheels of the trolley so that dynamo can charge the batteries installed in trolley to run the whole system. In order to reduce the running cost, we can introduce this concept to save we cost of electricity used to run the whole system of trolley. Flowchart:"
"The proposed project finds application and implementation in various fields. For example 1. In health sciences : It is a great invention for being implemented in health sciences. New features and new technologies are helpful for fighting disability to its best. 2. In military/ defence : we have found that military or defence fields can use The proposed project as an important tool/equipment in military or defence fields space. 3. Commercial level: For patients at home such as old age people or paralyzed people or disable people, this wheelchair can be used at homes by patients at home such as old age people or paralyzed people or disable people. 4. Old age homes : old age people are many times not able to move on old age people own so this wheelchair can be used by old age people. 5. Homage for specially challenged : specially challenged people are gift of gods n specially created. Some of whom are not able to move on Some of whom own or do not understand of how to move. In such cases this wheelchair can be used."
"The dustbin recognizes waste as The dustbin enters by movement, smell (with addition of smell sensor) and other distinguishing features with respective sensors. A keypad for user friendly way of entering is attached which asks for mobile number of the user. mobile number of the user receives a text message so there is paperless transmitting of coupon code. Coupon code can be used for online transactions (at the portal of website that has invested) as a reward for the good work done. Coupon code gives the facility of free mobile recharge. Block Diagram : LCD Display POWER SUPPLY MAX 232 Micro Controller Switch This system includes a switch module which retrieves the access of a dustbin in terms of waste entering. This data is fed to Microcontroller. Microcontroller retrieves the details from the sensor and sends a coupon code in form of an SMS over GSM modem. An LCD display is interfaced to Microcontroller for crossing the data received before being sent over GSM. Following includes the block diagram for proper understanding of the how the system works, the circuit diagram for the system: DB9 CONNECTOR PROGRAM RESET SWITCH GSM MODEM"
"This section lists all the subsystems and provides a more in depth coverage of the vehicle. Each subsystem section starts with a design Section which tells the original intent of the subsystem and a list of design goals. the original intent of the subsystem and a list of design goals also contain the actual developement which describes how it will be finally constructed. The other main components are DC Motor and Fork mechanism. This assembly is used to transfer vertical motion into horizontal motion or vice versa. In the vehicle we used This assembly to rotate the wheel at 900 in a steady state condition. There is a switch integrated in the vehicle which is used to lock & unlock the wheels for turning in 900. Like other vehicles during turning in normal running condition, the drive is in front wheels. The program is set for turning vehicle in sharp turn. For turning the vehicle towards right, we have to stop the motion of right wheel. So that only left wheel is in motion. The same process is done for turning vehicle to left, backward rightand backward left also. This assembly consists of DC motor, two wheels, battery pack, and microcontrollers for programing vehicle. Car Wheel: A wheel is a circular component that is inevitable to rotate on an axial bearing. The two wheels of robotic car are connected to two different DC motors. We can operate the speed of two wheels separately by using microcontroller. DC Motor: A stepper motor is a brushless DC motor that divides a full rotation into a number of equal steps. A stepper motor's position can be commanded to move and hold at one of these steps without any response of sensor, as long as DC Motor is cautiously sized to the application."
"This robot provides the cleaner assembly at the front side and the wiper system at back side for the faster drying of the floor surface. Cleaner assemblyconsists of a brush which has rotary motion, by using a dc motor. Cleaner assemblyconsists of a brush which has rotary motion, by using a dc motor is placed in such way that Cleaner assemblyconsists of a brush which has rotary motion, by using a dc motor touches the floor surface. Due to rotational motion of Cleaner assemblyconsists of a brush which has rotary motion, by using a dc motor Cleaner assemblyconsists of a brush which has rotary motion, by using a dc motor starts the cleaning of the floor surface. For cleaning purpose water is required. That required water supply is provided from water tank. water tank is placed at top of the cleaner assembly. water tank is supplied to the floor by the pipe from water tank. During cleaning some water is remained on the floor surface. It is necessary to drain some water. For this draining purpose we provided the wiper system, which is placed behind the cleaner assembly. fig. Flow chart for the robot operations Ø DC Motor:DC motor is used for rotary motion of the brush. Rotary motion is important for the cleaning of the floor surface. The power for DC motor can be taken from the battery used for driving the robot. Ø Program: As per requirement of the floor surface we can implement program with the help ofWIN AVR 2009-03-13 software. After Begin cleaning from any point Implement a program as per required path Running of program in the robot Starting of the cleaning operation implementation of program program is run in the robot using the AVR Bootloader by connecting to the computer. Ø Wiper:Ø Wiper is provided for the removing the remaining water on the floor after cleaning of floor. And another use of Ø Wiper is faster drying of the floor."
This section lists the working of system in depth. Detect obstacle within 1M area with the help of ultrasonic sensor. This information is then sent to microcontroller. This information accepts the information data and processes the information data according to instructions given in program. As per program conditioning signal is obtained at output of microcontroller which is used for next processing. As obstacle is detected in 1m area then This information gives signal to blind person in the form of vibration created by ultrasonic sensor. Due to occurrence of a vibration the person gets aware of obstacle and can walk safely. In this way proposed system will work for blind people while walking in unfamiliar places. In this way blind peoples get prevented from collisions with obstacle or getting injured by obstacle.
"The robot vehicle consist of the 3 wheeled chassis as the base. The Arduino board is interfaced with the Motor shield to connect with the sensors, DC and servo motors and to give external power supply. The advantage of using the Motor shield is to avoid direct damage to the motors. Sensors are used to measure the temperature and humidity. Ultrasonic sensors are deployed in the bot to encounter the obstacles in the bot path. DC gear motor is connected with the wheels for the movement of the bot. Servo motor is used to for the angular rotation of the camera. The Arduino board controls all the sensors and motors connected to The Arduino board and a mobile application is developed to control the motion of the robot. the robot can detect the obstacles in front of the robot and can take the path which is free. The continuous imaging of the remote area can be done with the help of the camera at various angles thus ensuring complete monitoring."
"Black line follower to monitor: The firebird V moves along the black line to check for the excess of grown branches. The firebird V halts after moving certain distance for pruning. The advantage of having The firebird V as black line follower is that The firebird V avoids traffic along the roadside with perfect pruning of the plants on the left, right and at the centre of the road/ area. Arm positioning: The arm is mounted on the Firebird V. There is a double axis arm mounted on The arm. The double axis arms are placed such that they are diagonal to each other so that The double axis arms operation does not disturb each other. One of they is mounted at 15cm along first axis and the other at 7.5 cm along the second axis. Pruning: Once the arms connected with the high speed propellers are aligned , The arm starts to prune the plant. The pruning is done perfectly so that the bushes look uniform. The blades of the propellers cut the excess part. Trash collection: A trash collector box with 3 sided covered is placed beneath a double axis arm so that the wastes while pruning are collected without making the place untidy. Once A trash collector box with 3 sided covered is full A trash collector box with 3 sided covered can be disposed off at the nearby waste disposal area."
"The following concept diagrams depict the procedure involved during QC implementation for air sample collection. 1. Step 1: Establish communication with QC and feed the desired altitude. 2. Step 2: QC ascents to the specified altitude. 3. Step 3: The microbial sample collector and data collection mechanism is activated. The Petri dish is exposed to air. 4. Step 4: Once the sample is collected QC descends to the starting point. Communication: Set up communication with QC using RF module. Once the location is fed, a command is issued for ascent of QC. During retrieval of sample, another command is issued for descent of QC with the sample. The GPS module attached to the quad-copter will also register the coordinates for each reading taken. Sample Collection: Microbes are microscopic living organisms like bacteria and fungi that though invisible, are present everywhere in the environment. These require mediums which can provide nourishment for proper growth. Agar gel is one such nutrient rich medium for the microbes. Our idea is to build a mechanism that uses a Petri dish to store Agar gel in a sterile environment. a mechanism that uses a Petri dish to store the agar gel in a sterile environment will be mounted on the Quadcopter. a mechanism that uses a Petri dish to store the agar gel in a sterile environment will use a servo motor to open the lid of the Petri dish and expose Agar gel to the surroundings after the quad-copter has reached the desired altitude. Once the lid is opened the quad-copter will hover at the set altitude for a couple of minutes waiting for the microbes and other particulate matter such as pollutants to deposit on Agar gel. the lid will then be closed at this same altitude so that the samples collected are not of different altitude then the one set earlier. Weather Data Collection: Parameters such as temperature, humidity and pressure used for weather forecast are mostly measured at ground level or by satellites [6] which are hundreds of miles away in orbit. This leaves room for error in forecasting since a major chunk of data related to the lower atmosphere remains unaccounted for. Our solution for this issue is to fit the quad-copter with various sensors that measure the temperature, humidity and pressure. The recording of these parameters will be done at varying altitudes to generate an entire profile of the weather in the region. Display Section: Parameters viz. latitude-longitude and meteorological parameters such as temperature, pressure and humidity, and battery level status are displayed on the LCD mounted on the remote control module. Submission of Sample to Research Organization: The samples collected need to be handed over immediately to the lab for sampling. Proposed Specifications: The requirement of motor thrust and the amperage drawn by each BLDC motor which is 8A leads us to believe that a 12V, 5,200mAh battery should be sufficient to power the quad-copter for 12 minutes for reaching a maximum altitude of 1,500 metres above sea-level."
"Tensegrities, which Buckminster Fuller helped discover, are counter-intuitive tension structures with no rigid connections and are uniquely robust, light-weight, and deployable[6](b) . counter-intuitive tension structures with no rigid connections are composed of an intelligently designed network of interconnected struts and tensed cables which are able to resist compression and allows mobility in any direction. Block diagram: The ERROR bots can be deployed from helicopters in order to carry out the relief operations. The main advantage of using tensegrity structures is that The ERROR bots can sustain the impact of falling from a certain altitude without damaging the payload. When force from an unexpected direction is applied to the tensegrity structure,force from an unexpected direction distributes the forces globally across force from an unexpected direction tension network thus reducing the impact on any individual rod. So there is less risk of a single rod failing. The core of the tensegrity structure is used to deliver payloads that would contain, basic relief and survival resources. Locomotion of robots Once the ERROR bot is deployed, the ERROR bot locomotion can be controlled through the GUI provided. The orientation of the ERROR bot is determined using an IMU sensor, the data from which is given to the control unit (Raspberry Pi 3).There are six struts out of which three are linearly actuated using geared motors. Due to the actuation, the structure of the ERROR bot gets deformed which results in shifting of the position of the center of mass that makes the bot topple. This is done until the ERROR bot reaches the survivor. Communication The communication between the bot and control pc is carried out by SSH over wifi ,due to which Raspberry Pi can be easily controlled using the GUI provided. Flowchart for Locomotion"
"A display as well as a voice announcing system, passengers will know where passengers are and when to get off the bus. This passenger data collected from the Automatic Passenger Counter (APC) will be translated into statuses for people to know the seat availability on a bus. [2] The transit dispatch centre can use this information to determine the need to dispatch extra buses during peak-passenger hours. Also through the on-board GPS device and the RF link, the transit centre will be able to gather transit data collected from buses in real-time. Fig.1 Transit Web Service [3] Real-time passenger information will be displayed at bus stops. Bus stops will be equipped with an RF link to receive data from the transit centre, LCD to display real-time transit data, and a Bluetooth beacon to communicate with Bluetooth-enabled cell phones at the bus stop. As well, to increase safety, camera surveillance will be added and remote bus stops will have LED lights. Finally, all the real-time information will be available via website and a Smartphone app. a Smartphone app will feature real-time schedule, bus stop locator and bus arriving time. In more details, a bus stop will detect a Bluetooth-enabled Smartphone within a range and allow a Smartphone app to transfer information displayed at the bus stop to the Smartphone. Fig.2 Intelligent bus system [4] To Receive real-time passenger information from the transit control centre, Real-time schedule Bus capacity, Priority seats availability a RF link implementing GPRS protocol with Display for passenger information of next buses on LCD display. For Short range communication Bluetooth beacon will Transfer passenger information to user mobiles to Notify an event of bus arrival. A Camera on top of bus stop taking photos every certain interval to ensure complete surveillance and ensuring women safety. Also Lighting in remote area will be provided by LED light with infrared sensor. [5] Transit data gathered by the transit centre will be made available on the internet and to the phone service provider. Users can check schedules and other information via the transit website, hotline / text messages, and the Smartphone apps. Users can also download real-time transit data from a bus stop through Bluetooth. This provides an alternative way of perceiving information displayed at the bus stop. By translating the text to voice on their Smartphone, visually impaired people will be able to ""see"" the display at a bus stop and get notified when and which bus is arriving. Block diagram of Passenger Safety Control system Signals from all these devices are fed to the microcontroller. Then [5] Transit data gathered by the transit centre is compared and processed for appropriate result. An alcohol sensor is suitable for detecting alcohol concentration of person breath. Also E button system is provided for emergency situation in buses like terrorist attack, bus hi jack. Whenever any emergency situation arrives driver will press that button and the require message is send to nearby police station or bus depot. [6] Fig.3 ITS and applications for city bus operations [7] SAFETY: The Infrared Anti-Collision Device is expected to be made of relatively inexpensive components for easy purchase and incorporation. E button system is designed using around three basic modules: (1) High Frequency 30KHz square-wave oscillator, (2) Monostable multivibrators and (3) A D.C. Battery power supply. [8] ENERGY EFFICIENCY: Use of hybrid electric buses or battery-only propulsion includes opportunity charging of the batteries while the bus is out on route, usually at layover points in the route design automatically via a robotic arm placed at layover points. This on-route, fast-charge capability, turbo chargers addresses many of the concerns over lower range and long charge times. . A common communication network serves both units with sensors to detect which charge head a bus is approaching to enable proper bus-to- charger communication for docking."
"In this Project we are implementing a Service Robot using Fire Bird V platform.a Service Robot using Fire Bird V platform will be initialise a Service Robot using Fire Bird V platform with the help of keypad and the numbers on the keypad will be the instruction for the described room of the patient.The Robot as soon as receives the instruction will carry the medication prescribed by the doctor for the particular patient will start from the initial position to find the destination room of the patient.To implement the destination room of the patient we have designed a m*n (where m=2,n=2) grid track path for a Service Robot using Fire Bird V platform .It will identify the nodes using the white line sensors on the board.The grid consists of 2 rows and 2 columns i.e maximum 4 rooms .This can be applied for any m*n grid array track,the main emphasis is on the intelligence provided to robot to take instantaneous decision.a Service Robot using Fire Bird V platform will start from initial node and move forward till a Service Robot using Fire Bird V platform detects the first node i.e first coordinate (0,0) x,y on the track.After detecting the initial node the initial node will calculate the distance of the final node from the initial node for which we are using the minimum step calculation to reach the destination node. Then a Service Robot using Fire Bird V platform will go to next node based on the calculation ,if the destination node is next node in that case the destination node is next node in that case will stop and buzzer on for 5s to provide information that medication is at doorstep.If next node is not the destination node ,then further path planning is done to follow the minimal shortest path to traverse the destination node,till a Service Robot using Fire Bird V platform reaches the required destination path.The flow chart of the process is shown in fig.2 Direction Turn Set Direction Coordinates North Forward North Y++ North Right East X++ North Left West X- East Forward East X++ East Right South Y- East Left North Y++ West Forward West West North Y++ West Left South Y- South Forward South Y- South Right West North Left East X++ Table 1 Fig 1. Track for Service Robot Start 1 2 3 4 Y E S Fig.2. Flow chart for Medical Service System"
"In this project we use Firebird V Robot which works on AVR platform using ATmega2560 Microcontroller, used for moving the robot in farms. Before starting the robot we implement height adjustable stand which gives freedom to the user to identify the disease at a particular height. Also the distance will be set by the user which is set by entering the value by keypad. Then we start the robot that start moving in the farm field in forward direction, at the same time camera also started that program for transmitting the signal through Zig-bee module to desktop, then the received image from robot via Zig-bee is analysed using MATLAB program to detect the brown spots and brown colour on leaves. Then after detecting and counting the number of brown spots by MATLAB software the robot will continuously moving in forward direction and capture the images then send the robot to MATLAB toolbox via Zig-bee the count is updated by the result of every images that sent by microcontroller to the desktop. When the distance reaches to the limit set by the user the sending of images is stopped and then MATLAB Toolbox gives overall final count result that shows the infected spots in plants that will be sent by desktop to Robot via Zig-bee module to be displayed on LCD of microcontroller. The flowchart of the process followed in this project is shown in fig.2. The samples of infection in different parts of late Blight and early Blight is shown in fig.1. and fig.3. Fig.1. Late blight symptoms on tomato Fig.2. Flow chart for Smart Pest Detector by Firebird V. Fig. 3. Shows the impact of early blight on tomato. Start Turn On the Camera and Motors Capture Image Firebird V Analyze colour Zig-bee Module LCD for display count Image processing toolbox Using MATLAB Zig-bee Desktop Check Distance Yes No Set Distance After the detection of density of infestation we will further use this robot for spraying the pesticides to the field. So for this we can use a container filled with pesticide then the user can switch on the motor for spraying and switch this robot for spraying in fields after setting the distance for spraying by this robot. So this project will help the farmers for detection of infection, also for spraying the fields. So he control of pesticide application will reduce the probability of destruction of farms through the late and early blight disease thereby improving production and also reduces the probability of excess usage of pesticides in farms which effects the fertility of farm lands also the society get benefit from the exact usage of pesticides so as not to be effected diversely by consuming pesticide through crops."
"In this project firstly we initialize the robot which will start the timers, that will be synchronized according to traffic light signals. Then as timers indicate the motion conditions that the robot will move forward direction with activation of three sensors called left sensor, right sensor and front sensor. three sensors called left sensor, right sensor and front sensor helps to avoid accident of robot with other vehicles that crosses the road by breaking traffic rules. three sensors called left sensor, right sensor and front sensor sense the direction form left side and right side, if an object or obstacle detected the speed of motor is doubled and move towards the other side so as to avoid accident. If front sensor detect an object then the robot will stop then as object moved away from path then robot move forward to reach at other side of the road that helps to cross the persons at other side. The buzzer will be on that indicates that the robot reach at the destination point. Then after that the logic will be reverse to move from this present position to previous position, i.e. back sensor will be front sensor for this logic and right and left sensor will work as discussed above. So in this manner persons can cross the road from pedestal crossing safely. The flow chart for pedestal crossing through robot is shown in fig.1. Fig.1. Flow chart for pedestal crossing by Firebird V. Start Turn On the timer Start motor, sensor array and buzzer when Timer Flag Set. Sensor Decision Move forward No Obstacle Left and right sensor detect obstacle Front Sensor Obstacle Detect Increase speed Stop Motor Stop Robot"
The received information of the correct location of the pothole or hump is send to the server through the GSM in the system which is interfaced with the microcontroller.
"As shown in above block diagram it takes the input from a three phase input supply coming from distribution points. These 3 phases are nothing but the R, Y, B phases. These 3 phases are then given to the switching logic followed by a controller. As per the status of the incoming signals from These 3 phases the controller will switch the input lines to deliver the signal to the load. Moreover if any of the phases get damaged then that information will be given to MSEB via GSM system and that respective phase will be automatically connected temporarily with another phase to avoid shortage in electricity requirements. The output of the controller is given to the load which will continuously deliver the input to the load irrespective of the status of the phases. Three phase input supply: - The whole circuitry will be connected across a three phase supply to detect faults and maintain continuity. Switching block: - The switching block will switch the phase load to other phases when any one of the three phases are out of power. This will help in maintaining the power and there will not be any power outage. Controller PIC: - The controller is used to interface GSM module to the three phases and switching logic to detect faults and discontinuity in the supply. GSM module: - Dual-Band GSM/GPRS 900/ 1800 MHz RS232 interface for direct communication with computer or MCU kit to the MSEB office. Distribution line multiple faults detection and indication to Electricity Board (EB) deals with the problem of detecting the fault in the distribution lines and the automatic intimation to EB. The project deals with the design and the fabrication of Power supply, Rectifier, Boost converter, three phase inverter, Micro controller and GSM modem."
"Methodology: 1. Camera will capture an image of the room. 2. an image of the room will be sent to the system. the system will use various image processing algorithms on an image of the room, e.g. colour detection, edge detection, etc. 3. Using multi-sensor fusion, system will get the positions of obstacles, unreachable areas, reachable areas, etc. System will make a map with this available information. 4. With this available information, the system will use a path finding algorithm to find shortest possible path for the robot to follow and clean. 5. Some of the information in the form of directions and positions of nearest obstacles will be provided to the robot using wireless communication. 6. Robot will follow the directions and will constantly check if the provided location of obstacle is correct or not. In case of incorrect information about obstacle, Robot will send a NACK (Not Acknowledged) type of signal to the system and leave that area for later. the system will flash that area on map asking if the system is an obstacle or not. 7. The positions of each object will be recorded in the system for further processing. 8. Steps 1 to 8 are repeated with suitable period. This way, in case of changes done in object positions, the system may find another suitable path for Robot. Flowchart: Future Scope: System will display this obstacle map graphically for User. User can make changes to the information like declare some part of area as cleaned. User may also set the guard band for some/all objects, if any of some/all objects are delicate."
Digital menu card will be placed on each table. Customer will see the items in Customer and will select the items in it. Then the order will be sent to the server placed on counter. Digital menu card & server are connected via Bluetooth. The person on the counter will receive the order with the respective table no. When the order is received then server will save the order & sends the acknowledgement and time required for serving order. The concept of automated train will be used to serve the items to the table from which the order has been received. Arduino kit with Bluetooth is placed on the toy train & is connected to server. As per the tables no. IR sensors are placed on each table with the unique ID. When order is received then server will send the IR sensor ID of the table from which order is received to the train. Train will start to deliver order & stops when it sense the IR sensor. it will wait there for 1 Minute and will return back to server. 4 Fig: System Design
"Block diagram Software Architecture · The SBTS system is a three tier architecture. 1. First layer consists of three parts : A.USER: User should enter the source address and destination address and request the query. Android application will provide the arrival time of various buses running on the same track with the number of passengers inside the bus. B.ADMIN: . Admin will update the database with the parameters like Bus Id, Route Id, Scheduled Timing of Bus, etc. through the webpage. C.MICROCONTROLLER: Microcontroller will fetch the data of GPS and will update the data of GPS on database using IOT protocol like MQTT. 2. Second layer consists : Application server will control the requests from user and admin. Application server will also be used to calculate estimated arrival time and represent the number of passengers inside the busthe bus. Number of passengers can be calculated using smart ticketing system. We are proposing The System. The System is fully automated to attend to client’s application service request. 3. Third layer consists: The application server of The System will connect to a database containing the information regarding prediction results. The System will process the client’s request and reply the client with the requested information. The real-time information and the prediction results will be stored in a database containing the information regarding prediction results. Control/ Main algorithm Algorithm for data update from Admin 1. Login request from Admin. 2. If admin is not authorized goto step 5. Client Admin Request from microcontroller to server. Client Admin enters or change the data and request server to update. 4. Server returns status. 5. Exit. Control/ Main algorithm Algorithm for data update from Admin 1 for data update from Bus 1. Request from microcontroller to server. 2. Bus Id/ Route Id is checked/identified. 3. Data is updated and returns the status. 4. Exit. Algorithm for data update from Bus 1 for Android App User 1. Open application. 2. Enter starting point and destination location. 3. Check the real time bus information. 4. Choose to board the bus or not depending on crowd and time. 5. Book the ticket. 6. End."
There will be wheel robo and quadcopter and interfacing between them.
The project will build a voice command system in the robot by which person with disability call the robot anywhere but within a distance. Recognising the signal the signal the robot will directs the person in which way the person can move.
"STEP ONE: The Robot revolving around the agricultural field detects the pest present inside the field limits using a PIR sensor. STEP TWO: After detecting the presence of the pest, The Robot revolving around the agricultural field produces ultrasonic sound waves within the field limits, which causes a disturbance to the pests and the pest moves away from the field. PIR SENSOR (PEST SENSOR) FIREBIRD ROBOT ULTRASONIC WAVE GENERATOR http://news.bbc.co.uk/2/hi/health/914556.stm http://www.environmentalhealthnews.org/ehs/news/pesticides-block-male-hormones http://www.environmentalhealthnews.org/ehs/news/pesticides-block-male-hormones http://health.utah.gov/asthma/pdf_files/Respiratory_Packets/pesticidesandrespiratory_ag.pdf http://www.deccanchronicle.com/channels/cities/hyderabad/pesticides-vegetables-killer-recipe-723 http://extoxnet.orst.edu/tibs/cutaneou.htm Flow chart:"
"Phase one: to detect the rain fall and flood flow when the limit exceed threshold value, a message will be transmitted to all people in nearby villages and cities using, Sahana a free open source disaster management software.[fig 2] Sensor interfacing: We have incorporated IR sensor to detect the rock slides over the mountains and the flood flow will be monitored by rainfall detector and the flood flow detector circuit placed near dam and river bank. The signal will then be processed and if the reading exceeded the minimum threshold set by us then warning system will be initiated. Processing: The warning system make use of online resources such as Crisis and Management systems. First it will search the place for any previous instance of hazards and it will immediately alert that area. A warning message will be then transmitted to authority over that area.[2] Initiating: Then the evacuating robots will be initiated. The disaster prone areas will be then be listed and the location will then be transmitted to the evacuating robots wirelessly. Then the appropriate number of robot will initiate rescuing. Phase two: phase mainly compromises of evacuating, cleaning and to rescue the people who got stuck in the disaster by automated robots and the clearing of road will be done by remote assisted robots controlled by operators.[fig 3] Deduction: Continuously monitor The signal. If there is any semblance of disaster is deducted, then determine where the disaster happened. Determine how many bots were required based on the location. Set one bot as leading (to remove the blockages). Minimum distance path: one bot will move along the predetermined shortest way to the location. The minimum path will already be set by us. Then one bot will make sure all the way to victims will be cleared of all obstacles.[3] Evacuating methods: The robot will be controlled from a operator who will the start to clear the blockages and the evacuating robots will then place the peoples in the trailing vehicles which will then bring the people to safe zone.[4] Block diagram: Fig 1:Pictorial representation of disaster data gathering and managing using disaster warning systems.(pic courtesy: HDSS org..,) Flow chart : IMPLEMENTATION OF PHASE ONE Fig 2:Flow chart depicting the sequence of action that will be taken when phase one will be initiated no Initiate all the sensor module stop Compare data with previously recorded history Gather the signals and analyse the signals Alert the immediate disaster prone areas. Initiate executing robots If Received signal> threshold value Start yes IMPLEMENTATION OF PHASE TWO: Fig 3:Flow chart depicting the sequence of action that will be taken when phase two will be initiated yes yes no start Monitor the signals Initiate rescue operation Locate the minimum path to travel If path clear? Clear the obstacles Bring the people to safe zone stop If warning occurred? no no yes"
"Robot Model: The characteristic of robot of travelling on any terrain is possible due to the use of legs instead of wheels. The static and dynamic stability of robot depends on the legs and are better provided than wheeled locomotion. the legs would be ‘C’ shaped and pivoted to the motor shaft. There would be six legs out of which three rotate in phase with each other and synchronously while the other three will rotate in phase with each other. However in order to balance the robot body while navigating, they would be in activated with 180 deg. phase shifts. The legs will be driven by individual motors which would rotate based on feedback through encoders allowing to synchronize the leg motion and move forward. Encoders do the job of ensuring correct phase difference between motors with help of microcontroller. The robot starts navigating and avoids the obstacles by using Sharp sensor for obstacle detection. The conceptual design of The robot is shown in figure (1): Figure (1) Human Detection: Figure (2) The webcam will continuously map the surroundings and if The webcam finds any human like pattern, the data of sensors will be checked. the data of sensors will be used by microcontroller to decide whether human presence is detected. To confirm human presence, CO2 levels of the surroundings will be checked.Indoor CO2 levels usually vary between 400 and 1200 ppm (parts per million). Outdoor CO2 levels are usually 350–450 ppm. Therefore CO2 sensor is calibrated to trigger the buzzer through ADC (analog to digital converter) whenCO2 level in its vicinity gets above 1000 ppm or 10% which is the amount in a crowded or industrial area and resembles this situation of an improperly ventilated enclosed space. Both the results will help in determining more appropriate conclusion. Figure (3) On detection, microcontroller will obtain that location of point through The GPS. The GPS gives data in terms of latitude and longitude to microcontroller. data would be transmitted through Zigbee communication module connected on the robot. The receiver station (rescue team) would receive the data (location) on computer by Zigbee receiver connected to The receiver station (rescue team)."
"The Smart Waste Management System has a set of garbage bins that are arranged in a defined path. The garbage collecting robot uses a defined path to travel to the garbage bins using a line following mechanism. bins have IR sensors inbuilt which are used to determine whether the bin is full or not. When the bin senses that it is full, the RF module communicates with The garbage collecting robot and signals The garbage collecting robot to come and empty the contents. When The garbage collecting robot reaches the bin, The garbage collecting robot uses a robotic arm with claws to grab the bin and empty the bin contents into the containers (separate for wet waste and dry waste) carried by The garbage collecting robot. In a case where two or more garbage bins call for the service of The garbage collecting robot, The garbage collecting robot will respond to the bin and if a garbage bin calls The garbage collecting robot, but The garbage collecting robot is full then, The garbage collecting robot will first go to the garbage treatment centre to empty The garbage collecting robot containers and then service bins. The working block diagram below tries to explain the working diagrammatically. Working Block Diagram Functional Block Diagram Work Flow Diagram: The garbage collecting robot follows a specified path to collect garbage from bins. This will be done using line following mechanism. 2.Robot stops at the location of bins. 3.There are two separate bins for wet and dry waste. We have differentiated the bins based on The garbage collecting robot colour i.e. red for dry waste and green for wet waste. 4.RGB sensor will help The garbage collecting robot to know whether a garbage bin is a dry or wet bin. Using the data from RGB sensor the robotic arm will pick up a particular bin and dump the garbage into a garbage bin. 5.If a bin on the path is full the IR sensors placed in a garbage bin will interrupt The garbage collecting robot will serve the bin which is completely full. 6.Now as the system consists of multiple bins there might be a case in which two or more bins are full at the same time. So, based on the shortest path algorithm The garbage collecting robot will decide which garbage bin to serve first."
"Our project consists of sensors like voice sensing module, ultrasonic sensors and IOT sensors. sound sensor are used to receive instructions from people, Ultrasonic sensors are used to explore environment and create virtual image of home, in this theme Our will develop 3BHK home model, voice sensing module will be mounted In each room, Hall and kitchen to receive instructions, Robot consist of ultrasonic sensors on the periphery so that it can explore home, obstacle and create virtual image of home. Robot will find path using algorithm to go to the destination and complete the task. Figure 1: Block Diagram of Proposed System . Figure 2: Demo Model of Working Environment"
"A moving platform is made using 2 DC motors and a static wheel on which a hand is mounted with 2 servo motors one for grip purpose and other for moving freedom in vertical direaction and will be controlled by a microcontroller , a wifi shiels will also be connected with the microcontroller that would recieve our signals via our internet and send back a visual feedback by internet only. BLOCK DIAGRAM"
"First step is to develop an App through which public near the patients can send the request for the drone service and information about the incident of the cause. One medical centre is developed at drone station for providing the medicines into drones. Through the App the request is arrived at the drone station, the worker at drone station feeds the drone with the required medicines. With GPS tracker the location is tracked by the workstation and the drone is controlled by the worker who is in the workstation and makes the drone reach the patients. the worker at drone station will control the drone with the help of the eye of the drone that is camera. Block Diagram:"
"f Robotic Security Guard. Abstract: Most of time there is a robbery and other theft case taking place in the houses where there are old people in the home. Though we have CCTV cameras for the security purpose still we cannot stop the theft from doing robbery and hurting people. So in order to decrease the rate of such case we are proposing this project to increase the security of the home and firms too. Introduction/Motivation: Literature Survey/Prior Artwork: Currently in market we are having systems which are capable to detecting any intrusion and Currently in market are able to inform the nearby police station, but Currently in market are not capable of stopping the theft. In we we would be making a robotic system which will first of all inform the neighbours and then inform nearby police station, it will be also capable to transmit live video wireless to nearby police station. Problem Statement: To implement a robotic security system which is capable of saving lives and thefts in cities. Hardware requirements: 1. Firebird V (master robot). 2. Wireless camera for shooting the live video. 3. Spark V robot (slave robot). 4. GSM module (optional). 5. PIR sensor, window sensor, zigbee module. 6. LCD module. Software requirements: 1. AVR Studio 4. 2. AVR BootLoader."
"We are presenting a robot that will be moving along with We. A smart watch will be connected to robot through bluetooth and a blind person can hear the messages passed by robot through earphone of smart watch. A smart watch will be able to give instructions like ""I need to go to coffee shop"" so that with the help of GPS, "" will locate the destination and "" calculates distance ,time,traffic and such details and provides a clear Description .Then We can give instructions like ""OK"" or ""Not OK"" so that it will process the request.Then it starts moving along with them. As soon as it starts moving, it will collect the information about the path and his surroundings.Then it will convert the images taken by camera in to text by processing it and the processed text will be spoken out by robot.Thus the person can hear the details through earphone/speaker. It can be like ""take 4 steps forward"" or ""stairs are ahead ,Please raise your foot to climb up"" .In this way we can create a guide or companinon to a blind or an old person in this busy world."
To implement the project the following things are to be done- 1. A Mechanical workshop is to be set up where all the Mechanical Designing and manufacturing will be done. A Mechanical workshop should be able to provide the enough resources for the fabrication of frames and other metal works as proposed in the project the following things are to be done- 1. Welding shop must be there in A Mechanical workshop. 2. An electronics lab has be setup in which all the electronic materials related to the project the following things are to be done- 1 are available. An electronics lab should be a fully equipped Mechatronics lab. 3. A space has to be assigned where An electronics lab is going to be parked. 4. Then the system is to be installed and with the help of nut and bolts the system has to be made firm and stable. 5. Then the system is to be installed and the connections are to be done. 6. Now with the help of a battery the system is to be powered and then the actuation is to be tested.
"The rescue operation will be undertaken according to our project in two major steps: 1. Collect information from the affected area. 2. From the data collected, take necessary actions. The first step is achieved by The Analyser. The Analyser contains a LiDAR sensor which is instrumental in constructing a view of the affected area. The LiDAR is fixed on a gimbal which is moved in 4 Degrees of Freedom with the help of 2 stepper motors. The trapped victim is recognized by a heat sensor. The data obtained by a heat sensor is given as an input to a MATLAB program which calculates 'r' (Obtained from LiDAR), ' Ɵ '(Obtained from horizontal stepper motor),' α '(Obtained from vertical stepper motor) and then plots it to generate a 3D view of the affected area. MATLAB takes an array of computed data containing [ x, y, z ] distances calculated using Python. Using loop statement and inputs from the Numpy array the software creates a plot of the points individually in 3D using ‘plot3’ and a for loop. The plot3 function displays a three-dimensional plot of a set of data points. plot3(X1, Y1, Z1), where X1, Y1, Z1 are vectors or matrices, plots one or more lines in three- dimensional space through the points whose coordinates are the elements of X1, Y1, and Z1. The values in X1, Y1, and Z1 can be ‘numeric’ or ‘datetime’ or ‘duration values’. Eg:- Drawing a 3D Helix t = 0:pi/50:10*pi; st = sin(t); ct = cos(t); figure plot3(st,ct,t) In robotic mapping, simultaneous localization and mapping (SLAM) is the computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it. This 3D map will then be analysed along with the infrared heat data to localise the scene virtually and the information of the victim’s locations will be calculated and fed to the rescue (secondary robot). The Rescue robot contains a mechanical arm and positional encoders. Through the obtained results, the Rescue robot to remove the rubble upon or around the victim and take the victim/the victim away from the affected area into a safe area. r Ɵ https://en.wikipedia.org/wiki/Robotic_mapping"
"Flow of working: 1) Robot compares the time with real day time and triggers to ON the Bot module and initialize the node n=0. 2) For the direction the direction follows the black line path 3) At first significance of node, sense the dustbin with magnetic sensor and increment the count of node, n=0+1 n=1. 4) Pull out the arm to pick up the dustbin and put in the garbage slot of Bot. 5) Sense the level by IR in garbage slot of boot, if the level is HIGH then move to the destination point. 6) Send the message via GSM at each service of dustbin. 7) Clean the side area of dustbin by vacuum cleaner. 8) If level is not HIGH then take the service of next node of dustbin and increment the count of nodes. 9) At destination wait for the input from the push button switch by driver, this to know the service of next node of dustbin is done with robot. 10) After the input from driver send the message “Work is completed” to control room. 11) Now control room will send the message “MOVE to SOURCE POINT” to robot. BLOCK DIAGRAM FLOW CHART:"
"App: App: will automatically detect our current location and will show all the available vacant parking spots nearby. Once the parking spot is clicked App: would check The Database and would show the vacant slot details and the users can select the parking spot and book the parking spot for a particular time period until we arrive at the parking spot. Parking slots may either be a free parking spot or a paid parking spot. Users can book a paid parking spot for a particular time by paying certain amount and if Users do not reach there by the mentioned time frame the slot will be cancelled and Users money will be refunded to Users respective accounts after deduction of some amount depending on the parking lot terms. The Database holds data of the different parking slots available, rates for slots and vacancy. Smart Parking P a g e 3 | 6 Start Detect Current Location using GPS Display Available slots location in map in Green and locations with few slots in Blue Display Unavailable slots location in map in Red and Is Vacant Slots Available? Select the desired slot Book the slot Drive to the parking lot Stop Search for Vacant slots nearby Is Vacant Slots Free? Payment for the slot to be booked Yes Yes No No Smart Parking P a g e 4 | 6 Image Processing: The system uses Raspberry Pi to feed data into the Android App. The Raspberry Pi camera is used to detect the vacancy of the parking spot using Image Processing and then sends the data to The Database. From The Database the data is fetched by the Android App and displayed to the user. If the image processing is successful with The Raspberry Pi camera we can try the prototype with a high definition camera for better results. Start Scan Parking Lot Update “Slot Free” to DB Update “Slot Occupied” to DB Is Slots Free? Send data to DB and App Stop No Yes Smart Parking P a g e 5 | 6"
"The implementation of the project will be carried out in two steps. The first step will be to design a UAV which can manoeuvre smoothly in a stable condition. The first step, will be to mount the equipment required for inspection and communication with the servers. The equipment needed for this purpose are Passive Infra-Red Sensors (PIRs), Thermal and visual camera. Initially for communication we can deploy WLAN (Wireless Local Area Network) which will be used by a UAV which can manoeuvre smoothly in a stable condition to communicate with the inspection team nearby, who can then send the received signals accordingly to main servers using satellite communication. In final stages we can use satellite communication directly in a UAV which can manoeuvre smoothly in a stable condition so as to decrease the requirement of inspection team (as shown in Fig.1). The satellite communication will also help in mapping and reaching any particular power grid automatically using the data received from the satellite. a UAV which can manoeuvre smoothly in a stable condition a UAV which can manoeuvre smoothly in a stable condition will sent the collected data i.e. IR, thermal and visual pictures/videos in real time to the main servers where this data will be analysed by experts. The final step will be to design a process such that a UAV which can manoeuvre smoothly in a stable condition analyses the data and suggests possible solutions with the appropriate images and GPS coordinates of the faults. Fig.1: Diagram showing the procedure for automated inspection Design of a UAV which can manoeuvre smoothly in a stable condition: There are various factors which decide the type of multi-rotor. For the feasibility and low cost the project demands that the a UAV which can manoeuvre smoothly in a stable condition’s flight time should be reasonably higher and energy consumption is low. To achieve this, a UAV which can manoeuvre smoothly in a stable condition a UAV which can manoeuvre smoothly in a stable condition should be lighter in weight and designed such that a UAV which can manoeuvre smoothly in a stable condition has low frictional losses (due to air). The components will be selected such that The components are of light weight and effective in inspection. a UAV which can manoeuvre smoothly in a stable condition a UAV which can manoeuvre smoothly in a stable condition will be designed such that a UAV which can manoeuvre smoothly in a stable condition can be operated easily at different altitudes, and bad weather conditions."
"We will divide the project into three parts. The first part is the base which is a movable one that is designed for the Robo-Bin to move from one place to another without human help, basically designed and programmed to perform such task. We have attached two Infra-red sensors to the microcontroller which is then connected to the servo motor which is attached to the wheel. The servo motor rotates according the controller and hence helping the Robo-Bin to move freely. IR or VISIBLE light is emitted from the emitter. This emitted light strikes the surface and gets reflected back. If the surface is white, more intensity of light gets reflected and for black surface very less intensity of light is reflected. Photo detector is used to detect the intensity of light reflected. The corresponding analog voltage is induced based on the intensity of reflected light. The corresponding analog voltage is compared with the fixed reference voltage in comparator circuit and hence The corresponding analog voltage is converted into logic 0 or logic 1 which can be used by the controller. The comparator circuit may be designed in two ways. Case-1 Black area=1 White area=0 Case-2 Black area=0 White area=1 Block diagram: Schematic diagram: Flow Chart: Basically they are the code for the line following robot used for the movement of the Robo-Bin. As they senses the white line of the road and move toward the direction of they destination. Now we discuss the second part which is the auto lid which helps to open the cover automatically with the help of ultra-sonic sensor which detects the presence of the person. ultra-sonic sensor which detects the presence of the person is connected with the audrino uno which gives instruction to the servo motor to open the lid. The third part and the important part the plastic detector we use ultra-sonic sensor which detects the presence of the person as shown in the figure. It’s very simple where we connect the capacitive proximity sensors to a buzzer circuit if It detects any trace of plastic It will automatically signal the buzzer and hence the buzzer buzz and will raise alarm therefore awaking us about us mistake and making us to throw correct waste in the Robo-Bin. START IR==1 && IR==0 ON left motor OFF right motor END IR==0 && IR==1 YES NO YES motor OFF left motor ON right motor OFF left motor OFF right motor NO Capacitive proximity sensors measure the proximity of conductive as well as non-conductive objects with high resolution. Analogous to the function of an inductive proximity sensor, where a magnetic field is generated, a capacitive proximity sensor generates an electrostatic field at the face of a capacitive proximity sensor. The sensor face is surrounded by a guard with equal potential so that the electric field will be focused towards the target. The capacitance varies inversely with gap distance and directly with the dielectric medium as well as the surface area of the target. Target size and dielectric medium are important design criteria to take into consideration."
"Here we are considering we robot (FIREBIRDV) as the transmitting section and all the embedded garbage bins as the received section. So, immediately when the garbage bins are filled up to the garbage bins threshold level it can be detected by using level sensor then a message or signal will be sent to our robot (FIREBIRDV) by using RF module, then with the help of unique ID, robot will detect the particular bin which has filled. So, it is easy for our robot (FIREBIRDV) to collect the garbage from the respected bin."
In this project we use a RF tag which is tagged to the ambulance. When the ambulance consisting of RF tag passes through the first signal the ambulance consisting of RF tag is detected by the RF reader which is situated on the traffic signal. Each ambulance of different hospitals will be given a different RF tag. The information of each hospital will be stored in the controller. The received signal from the RF reader will be transmitted to the controller. Now the controller processes the data and the traffic signals on the nearest way to each hospital are controlled and made green(allowed to pass) with a preset delay which is in correspondence to the time taken by the ambulance. As soon as the ambulance reaches the next traffic signal and is detected by the RF receiver of that area the previous traffic signal is set back to normal. Hence the ambulance will be free to pass without causing any problem of vehicular congestion.
"In our project the main part like GSM module, RFID reader, LCD panel & Weight sensors, swaps Cards are included. IF we load the garbage in empty container (dustbin) below that is attached weight sensor. This senses we load the garbage in empty container (dustbin) below that and we load the garbage in empty container (dustbin) below that get converted into electrical signal with the help of transducer. At the same time LCD panel indicate the message ‘ CLEAR DUSTBIN ’ .so we clear this dustbin then again LCD panel display the message ‘ CLEAR DUSTBIN ’ ‘ EMPTY DUSTBIN N SHOW CARD ’ i.e.( your dustbin is empty you swap the card ) then garbage truck pass through the next section RFID reader takes place. Here worker have to swap the card so this attendance will be also noted. Then again LCD panel indicates us ‘EMPTY DUSTBIN MESSAGE SENT’ i.e. (Your dustbin is empty and attendance also noted of worker to the municipal corporation office and message is sent through GSM). In our project camera and gas sensor is also play very vital role in the system. by using camera also our are detect the capture when our want and also can save the record as a video and also capture. By using detecting camera we can observe of man ability (Worker) which comes daily to clean that garbage. If any one worker is not come to clean this dustbin on the time means when garbage is overloaded then this situation also seen by corporation officer and then any one worker give quickly action on that movement. And tell to another worker to clean that specific area quickly. Also man power is reduce and time consuming by this project. In short thing all the record near about (dustbin) garbage is recorded by corporation office. this project is also protected by camera so anyone can not play with this system [11]. GAS sensor detects the gas which is produce by the wet, water, and some other reason. Which is produce harmful gas which affect on surround air and also harmful for surrounded people. Air pollution is also occur that reason and so in rainy season some of mostly people is injure due to this air pollution which is occur due to wet wastage and this is very real fact. So avoid this issue we need gas sensor in that system which detect harmful gas(like ammonia ,carbon ,etc...) as specified level and then message is sent to corporation(clean the garbage immediate which is fill by wet wastage) [8]. Block diagram: Fig no. 1 Block Diagram of Proposed Concept Before implementation: (a) (b) Fig no.2 (a) (b): Dirty Environment Due to garbage [12] After implementation: Fig no.3 (a) Fig no. 3 (b) Fig no.3 (a) (b): Clean Environment after"
"In public places we will deploy the robot instead of man as security personnel. This robot on the outer hand will perform the task of cleaning i.e. This robot on the outer hand will work as a garbage collector. On the other side, robot will perform the task of a secret agent that will detect the presence of explosive and this system cannot be bypassed. 1) The cleaning mechanism will work as follows: - The robot will detect the size and the color of the object lying on the floor and match the specification with the database and if the object will be sensed as garbage then the object will be collected. - The collected material will be segregated as metallic and non-metallic substances. - The smaller dust particles will be collected through the vacuum. 2) The Security sensing will be working as follows: The Security sensing will work as a detector for any explosive. If any signal is detected by robot, The Security sensing will send the location immediately to the control room and also will share the type of object / explosive detected. As per the command from the control room robot will send the live pictures of the location. Process: The Following Steps Will Be Followed To Execute The Entire Process: SECURITY SENSING MECHANISM: 1) robot will be activated and will start robot motion on the specified path. 2) robot will be activated and if robot senses the explosive robot intensity will be reported to the control room. 3) In case the intensity of the waves is normal robot will not take any actions. 4) If the intensity is abnormal robot will share the location and the live images to the server immediately. 5) Then further action will be taken based on the command from the control room. Neutron activation detector is the sensor that will be used for the sensing of the explosives. The sensor mechanism and the explosives working will be based on the Artificial Intelligence that will be programmed using C++ language. The image will be captured and processed to an HTML file and then will be send to the server through JAVA. CLEANING MECHANISM: 1) robot will be on robot routine path. 2) Using robot robot will sense the size and the shape of the objects present in the path. 3) robot will pick the object and then transfer the object to the collection bag. 4) Depending on the material of robot will categorize as metallic and non-metallic and thus segregate metallic and non-metallic accordingly. 5) The extremely small dust particles will be sucked through the vacuum. Arduino language will be used to interface the Camera, Vacuum Sucker and robot with the software."
"In our project ,our will interface two microphones at two sides of the robot with the microcontroller. Sound signal is captured by microphone and time delay is measured or if time delay, then turn one of two motor available on board to turn robot such that time difference of sound to reach microphone should reduce and become zero. Or changing the speed of robot motor depending on the time difference of sound to reach 2 micro phones placed at least 6 inches apart. In this way it will try to search for the exact location of the person, so that the help may be reached as early as possible."
"In this, current plant and crop condition will be monitored through various sensors like temperature sensor, humidity sensor, vision inspection cameras and Google map. Then data will be collected, analysed and given to our automated software systems. data will process the respective data and will geotag the image with Google map. This also monitors the area or plant condition and assign different task as per the requirement like spray and watering in order to maintain the desired adequate parameters. This information will be also provided to the other support systems and concerned government bodies. The user interface for farmer will include details of farmers which will link to the other support systems and concerned government bodies accounts. This is broadly divided into four parts- Geotagging, image processing, verification of data acquired by certified agencies and regulating mechanism. Geotagging:The map of selected farmer’s area will be marked and The map of selected farmer’s area boundary will be defined using Google Earth, open source software. On the basis of geographical details from database, plant location will be geotagged onto the field map along with plant location description depicted with help of image in the geotagged part. The tagged information is stored for further accessibility. Image Processing: Images of the area under consideration is taken in accordance with the geo- positioning system. The photos are captured under varying conditions and camera resolutions and the clicks are processed. Control action of sprinkling is taken on comparing the current status of the crops with the predefined data. From The photos the current crop position can be determined and accordingly the amount of pesticide needed is sprayed. In parallel the predefined data is provided to government agencies and laboratories. A continuous loop is formed where feedback is taken. Verification of data: This part of system includes verification of acquired data with standard crop specification in order to monitor the plant condition. the predefined data is compared as well as stored for future references .governmental bodies and other concerned agencies are kept updated with the conditions through the farmer and requirement of facilities and control is so maintained. Regulating mechanism: This helps in controlling the dosing and sprinkling of pesticides directly to the roots making it more comfortable and easier for the farmer. Simultaneously the predefined data is stored for further verification. User Interface: There will be online analysis of the sample data given by the farmers, so that proper controlling of quantity and related things can be appropriately done. Same data can be transferred to authorized government bodies by using the farmer’s identity. Flow Chart:"
"Ø Robot worked in the following steps: Ø The first step is giving information about the object to Ø Robot. This can be done through computer by using Zigbee. We can just simply give the product/object name and the category of object by using the computer. Ø Robot will move by following the white line. This can be best done by using white line sensor which is present on the kit. These sensors allow robot to move only along the white line thus restricting robot to move in any direction. Ø We can use either of the barcode scanner or the colour detection technique to identify the specified object/product. Ø At Ø Robot will stop and start scanning the object’s barcode (or detect colour). The barcode scanner (or colour detector) will scan the barcode attached to the objects one by one and compared the barcode attached to the objects one by one with the input given. Ø As the barcode reader matches the correct barcode with the given input, Ø Robot will pick the object. Ø The most important step after that is to collect the object by using robotics arm. robotics arm will gently pickup the object. Ø After picking up the object, Ø Robot will move 1800 and starts moving towards Ø Robot initial position to collect the object there. Ø After reaching to the initial position, Ø Robot will put the object there. Ø To allow user to know that task is completed, Ø Robot will start beep for few seconds."
"1)OBJECTDETECTION InObjectdetection,thesensorsthatissharpsensorsandIRproximity sensorscomeintoplay.ThesesensorsareconnectedtotheADCofATMEGA2560 AccordingtothevaluesfromADCwecouldfindoutatwhatdistanceacertainobject is,inthecontainersforfoodandwater.Hencewecoulddoobjectdetection. 2)COLOURDETECTION Nowafterobjectdetectiontherewouldbesomeconfusionfortherobot whethertheobjectisthecontainerorsomethingelselikechicken,sothecolour detectorwilldetectthecolouroftheobject.Theobjectdetectionblockhasdetected andwillconfirmifitisthecontainerorchicken. 3)POURINGOFFOODANDWATERUSINGROBOTICARM Afterthecontainerhasbeendetectedthereisaneedtoputthefoodorwater intothecontainer,theroboticarmwillbecontrolledbytheATMEGA2560. 4)TEMPERATURESENSING TheTemperaturesensorLM35willdetectthetemperatureofthesurrounding ifit’ssuitableforthechickensthentherobotwon’tdoanything.Ifit’sbelowthe requiredtemperaturethenitwillturnONthelightswhicharehighpoweredlights whichdirectlyincreasesthetemperature. 5)SWITCHCONTROL Theswitchforthehighpoweredlightsiscontrolledwirelesslyusingthe ZigbeeTransreceiver.Thereceiverattheswitchboardwillreceivethecommand whethertoturnonorTurnOFFtheLights. 6)MOVEMENTOFTHEBOT TherobotwillmoveusingwheelswhichareconnectedtotwoDCgeared motor.TheATMEGA2560controlthespeedasthewellasthedirectionofthe motorssoastomovetherobothereandthere. SHARP SENSORS MOTOR IRPROXIMITY SENSORS ROBOTIC ARM TEMPERATURE SENSORS COLOUR SENSORS ATMEGA 2560 SWITCH Therearetwotasks:- 1)FOODANDWATERMANAGEMENT START OBJECT DETECTE D OBJECTDETECTION CHECKFORCOLOROFOBJECT OBJECT DETECTE D DRIVETHEARMTOPOUR ENTERTHEDIRECTION 2)TEMPERATUREMANAGEMENT"
"Sensorswillbeduginsoilswhichwillmeasurethequantityofessentialspresentinsoiland compareitwiththerequiredappropriatelevel.Iftheirisdeficiencyinsoil,systemwillturnon theirrigationsystemuntilltherequiredlevelisattained."
When we enter in library first we have to enter the name of book which we want to issue. The input is give through the switch. This information provides to the microcontroller AT mega 16.According to the information motor is moved and because of motor movement whole robotic structure is moved. RFID tag attached to the book and RFID reader is placed in robot grip. RFID reader read the information of book saved in RFID tag. This information is sent to the microcontroller AT mega 16 .Microcontroller again send This information to the information motor through motor driver IC L293D.Robotic arm picks the book and put the book on the conveyor system then conveyor carries the book to the issue counter. For returning the book the process will be reversed.
"Software will receive request form hospital authorities to conduct green corridor between hospital and destination airport. From data provided by request form hospital authorities it will find the shortest, fastest and secure path by using shortest path finding algorithm. The shortest route generated by software will be send to emergency vehicle"
Fig: Block diagram It is a mobile robotic arm which is used to distinguish two contrast colors of the cubes. A particular color is sensed by the color sensor which is chosen by the programmer. That particular color cube is separated from the two color cubes. The robot picks that particular color cube and follows the line to place That particular color cube in The robot designated place. Flowchart: Set counter to zero Go to source place Search for particular color cube If color =red Pick up the selected cube Rotate the motor Reach to destination and place That particular color cube Go to source place Increment counter by 1 Display number of cubes Go to start position Start End
"The flyer can ask the query to the Machine using the microphone in his preferred language, while the Machine reverts back with a precise answer to the Machine in the very same language as spoken by The USER, in the form of text. Our idea is a combination of Artificial Intelligence, Natural Language Processing and Machine Learning. The objective is to make a model that would listen, comprehend, process and deliver an appropriate result in the form of text. The USER get to choose his language of preference from the list of Languages present on the display. After that He/She can proceed with the Question by asking through the Microphone. It works as follows: 1. Recognition of Speech: This machine learning software will be implemented via Raspberry Pi. Raspberry Pi will be interfaced with a Touch Screen LCD panel which would be used as a display and to select the preferred language. Additionally a microphone will also be interfaced with the Raspberry Pi which would be used by the flyer to speak through. When something is spoken through microphone, the continuous audio signals are converted into texts. Training of the model is done by using feedback mechanism. Speech recognition programs get better as we use Speech recognition programs because Speech recognition programs learn as Speech recognition programs go along using feedback we give Speech recognition programs, by correcting mistakes. If we don't correct mistakes, Raspberry Pi assumes that Raspberry Pi has recognized everything correctly. If you force the system to go back and tell which words the system should have chosen, the system performs much better next time. 2. Processing: Once the audio is converted into text, the entire sentence is broken down to a few “most significant words"" by removing the prepositions, punctuations etc. NLP is an important technology that would bridge the gap between human communication and digital data. NLP is used to find the most significant words spoken by the user from the entire sentence. the most significant words spoken by the user from the sentence are then compared with the list of Questions present in the Database, based on the selection of the language by the user. Different Database’s would be created for each of the Languages which would contain the list of all possible Questions with Different Database’s relevant answers. 3. Producing the output: On comparison with the list of questions, relevant answer is given back to the ""user"" in relevant answer preferred language as output in the form of ""text"". Fig.1 Overview of Process FLOWCHART: Fig.2 Sequence of Execution After the selection of language, all the information displayed henceforth will be of the same language. Now, the flyer gets to ask his question. As shown in Fig.2 according to the nature of the question the machine would categorize the question in two categories- a) Basic b) Advanced In the basic section, the machine will answer general FAQ related questions pertaining to: 1] Safety guidelines 2] Baggage allowances 3] Prohibited Items etc. In the basic section, the machine would answer all his other questions like, 1] Flight details 2] ETA of flight 3] Gate terminal of his flight etc. the basic section would also deal with providing directions to various locations like, 1] Specific Gate Terminal 2] Cafeteria 3] Shopping Centre 4] Lounge etc. Once the kiosk has answered his query, the whole process would be repeated again if his wishes for more queries else would return back to the kiosk home screen as shown in Fig.3. Fig.3 Screen Display"
"This project can be best for implement to the tourism industry like hotels, home and various commercial purpose. Working Diagram"
"The basic project structure depends on two main principles on which the system focuses: · FAULT DETECTION:- The image to be inspected is captured using a camera assembly and is to be compared with a template image of the layout stored in the system. The image comparison is done using image subtraction. The image to be inspected is also segmented in different segments for a better fault detections and also focusing on different types of fault occurrences using Image segmentation. These comparisons help analyse different types of faults that may occur in the PCB etching processes. Depending on the faults, the system notifies the type of occurred fault individually on the GUI for the user to summarize. · FAULT RECTIFICATION:- After the fault detection process, depending on the fault a rectification solution is provided. Different faults that are detected, generate relative solution for the same. BLOCK DIAGRAM- [1] First Conveyor Belt will carry the PCB to Barcode Scanner and Colour Sorter. [2] Barcode Scanner scans the barcode of the PCB the PCB and load the the PCB monochrome board image to the GUI. [3] Colour Sorter will sort the PCB of different colours depending upon the user’s requirement. [4] Second Conveyor Belt will carry the PCB from Colour Sorter for detection and image capturing procedure. [5] Object Detector will detect the presence of PCB and if the PCB is detected both First Conveyor Belt Colour Sorter is turned off and camera for image capturing purpose is turned on. [6] Camera is used for capturing the PCB Image and the captured image is loaded into the GUI. [7] MATLAB is used for further image processing which include following processes: Convert RGB Image to Grey Image, Thresholding of image, converting to Binary Image, Image Subtraction of two images for finding location of faults, Image Segmentation of a Binary Image and then Image Comparison of each segment of Binary Image with the preloaded images for detecting the Type and Number of faults. [8] Emailing and Printing of reports of PCB fault detection and rectification to user and manufacturing department which included image of information such as Location of faults, Number & Type of faults, Solution to correct the faults. [9] Line Follower Robot is used to carry the PCB along with the PCB reports and the print of rectified image on butter paper and drop the PCB to the Manufacturing Department. FLOW CHART- · Hardware:- · Software:- · Faults to be Detected:- Sr. No. Defects 1 Small traces 2 Breakout 3 Missing Conductor 4 Missing Hole 5 Noise 6 Conductor Too Close 7 Excessive Short 8 Incorrect pad sizes 9 Wrong Size Hole 10 Under etch 11 Over-etch 12 Footprints 13 Open Circuit 14 Short Circuit 15 Excessive Short 16 Spur 17 Spurious Copper 18 Mouse-bite 19 Pinhole 20 Adjacent tracks too close"
"MV=Measured Value SV=Standard Value Fig: [Flowchart of Air Quality Monitoring System] Our air quality monitoring System is an automated version of monitoring the quality of air and sending the information to a distant database wirelessly. Our system has got almost all things automated so that Our get an advantage of this concept ie the real time direct measurement of the parameters (here air quality) through GSM/PC. Maintaining backup of sent data is easy and can be done within a few seconds. This model uses gas sensor, GSM module (SIM900A), LCD, a microcontroller and a Fire Bird-V Robot for movement of the air quality monitoring system. The GSM module is connected to PC through RS232 cable. The GSM module is attached to AT mega 16 to simultaneously display the measured temperature, through which we can experimentally check whether the data that is being sent is correct. The air quality sensor will record the pollutant levels of gases like CO, SO and NO and relay the information through Internet/GSM network to the base station. The data received at the base stations will be arranged in a data base. The data received at the base stations will then be processed and The data received at the base stations involves validation, verification, standardization, normalization, aggregations and transformations. After The data received at the base stations is suitably processed the data prediction and analysis will be carried out. Finally conclusion, regulations and recommendations will be proposed. The communication protocol will serve as a mediator between the end user and the data base server. 1. ATmega16 microcontroller: microcontroller is the main component of a pollution detection unit. The operating system that runs inside the chip coordinates the substances measurement process, the acquisition of the GPS coordinates and the data transmission to the central server. microcontroller is mounted on a development board that provides an RS232 serial communication to the GSM modem and GPS receiver and a parallel connection to the Air quality sensors. 2. MQ-135 Air Quality Sensor: In this Project we are using MQ-135 sensor for detection of pollutants like NH3, NOx, alcohol, Benzene, smoke, CO2, etc. Air Quality Sensor is directly employed to atmega-16 microcontroller by using AVR C(embedded C) using C for coding purpose. The surface resistance of Air Quality Sensor Rs is obtained through effected voltage signal output of the load resistance RL which series-wound. When Air Quality Sensor is shifted from clean air to polluted area, output signal measurement is made within one or two complete heating period. Resistance value of MQ-135 is difference to various kinds and various concentration gases. So, when using this component, sensitivity adjustment is very necessary. We are using to calibrate the detector for 100ppm NH3 or 50ppm Alcohol concentration in air and use value of Load resistance that( RL) about 20 KΩ(10KΩ to 47 KΩ). When accurately measuring, the proper alarm point for the gas detector should be determined after considering the temperature and humidity influence. 3. GSM Module: GSM (Global System for Mobile communication) module is used to establish communication between a computer and a GSM-GPRS system. Global Packet Radio Service (GPRS) is an extension of GSM that enables higher data transmission rate. GSM/GPRS module consists of a GSM/GPRS modem assembled together with power supply circuit and communication interfaces (like RS-232, USB, etc.) for computer. At the location of sensor, the Gas sensors will measure the concentration of Gas at that point. MCU over there will process the voltage output and return a string containing the information about the concentration of different gases. In the initial phase of our project, our will send this data to the living people as well as the base station by using the most useful feature of GSM protocol i.e. Short Message services (SMS) at regular interval."
"1. Firebird V robot will be used for the detection of alive human bodies. PIR sensors present on firebird Firebird V will be used to sense the radiations emitted by human bodies. 2. Firebird V provides us with an excellent environment for experimentation, algorithm development and testing. Firebird V modular architecture allows us to control Its modular architecture using multiple processors such as 8051, ATmega 2560, ATmega 8, etc. Modular sensor pods can be mounted on platform as dictated by intended applications. 3. PIR sensors for detection of human presence will be mounted on Firebird V robot. PIR (Passive infrared sensor) Sensor: 4. Every object with a temperature above absolute zero emit heat energy in the form of radiations. Usually radiations are not visible to the naked human eye because radiations radiates at infrared wavelengths, but radiations can be detected by electronic devices designed for such purpose. 5. The term passive in this context refers to the fact that PIR devices do not generate or radiate any energy for detection purposes. PIR devices work entirely by ability to detect the energy given off by other objects. PIR sensors don't detect or measure ""heat""; instead PIR sensors detect the infrared radiation emitted or reflected from the object. 6. A PIR-based motion detector is used to sense movement of people, animals, or other objects. A PIR-based motion detector are commonly used in burglar alarms and automatically-activated lighting systems. A PIR-based motion detector are commonly called simply ""PIR"", or sometimes ""PID"", for ""passive infrared detector"". 7. When an object, suppose a human, passes from in front of the background, such as a wall, the temperature at that point in the sensor's field of view will rise from room temperature to body temperature, and then back to the normal again. https://en.wikipedia.org/wiki/Absolute_zero https://en.wikipedia.org/wiki/Human_eye https://en.wikipedia.org/wiki/Heat 8. the sensor then converts the resulting change in the incoming radiation into a change in the output voltage, and this triggers the detection. 9. the sensor is generally mounted on a printed circuit board containing the necessary electronics required to deduce the signals from the sensor. 10. the signals from the sensor itself will then be converted to the digital information through the ADC (Analog to digital converter). 11. These digital values will be used by the robot for detection of human bodies trapped in the turmoil of destruction caused by the calamity. Flowchart:"
Multiplepressuretransducersandothersensorsinstalledonvehiclewillidentifytheaccident intensityanditsimpactonpassenger(s)andsendsignaltoitsconnectedmicrocontroller. Microcontrollerwillanalysethescenarioandtransmitasignaltovictimsphone.Theinterface onthephonewillsendmessageofimmediatehelprequiredalongwithGPScoordinatestoa predefinedgroupofindividualsincludingnearonesandnearesthelpserviceslikeambulance andpolice.InthiswayhelpinghandscanreachASAPatthelocationofaccident.
When the user can speak a word of alphabet or an number the printer part of system will print that word on the paper with giving an feedback of that word. that word is used for the giving space in between words. When the line of paper will commpleted then the coursor goes on next line. Voice processing: The voice input is given to the device that means the input voice frequency is different by dippending the users. It can accept all type of frequency by the human voice. Firstly the voice signal is amplified as the refernce input to the device. After the amplifieng input signal the analog to digital convertor is used. the amplifieng input signal is parallely sends to the microcontroller ic . Microcontroller : the microcontroller can stored the digital data and the microcontroller ascii codes. the amplifieng input signal is compared with the already stored data of digital alphabets. And according to the digital signal the ascii code of that alphabets is sends to the printing side of the device the amplifieng input signal is ascii signal of the alphabets.before the printing of the alphabet that letter is given to the microphone as it is a feedback signal to the user. Dot matrix type small printer: The printer is dot matrix type printer and The printer is small in size. The printer is having input is ascii form and The printer having some controlling signals to start printing and moves to next line.
"Why we need AH2SM 1.O? There is some data Which is observed by we in these factors of the populations and urbanisation which is major factors for which we implemented our project. Home to 1.21 billion people (about 1/6th of world’s population) •Around 72% of India’s population lives in villages. •The sex ratio has fluctuated between 927 –934 between 1971 to 2001. •The total fertility rate declined from 4.8 to 3.7 in rural areas and 3.4 to 2.5 to urban areas during 1982 to 1997. •Life expectancy at birth has increased from around 30 years at independence to 60.7 years in 1996.This section should contain details regarding the implementation of the proposed project idea. Road Accidents : •Emergence of Road Traffic Injuries (RTIs) a leading cause of Deaths & Disabilities •India : 2011 :Accidents 4.97 lakh (annual) (1 every minute) Deaths 1,42,485 (one death every 3.7 minutes) •Accidents impose significant costs 3% GDP for India (1999-2000) 1% GNP for low income countries 1.5 % GNP for middle income countries 2% GNP for high income countries Was 9th leading cause of death in 2004 and expected to be 5th leading cause of death by 2030 world wide. By this implementation of the project the project can automatically reduce all aspects of accidents and the human will be must Number of Road Accidents, Number of Persons Killed and Number of Persons Injured Per Lakh Population: 1970 –2011 Number of Road Accidents, Number of Persons Killed and Number of Persons Injured Per Ten Thousand Vehicles: 1970 –2011 Number of Road Accidents, Number of Persons Killed and Number of Persons Injured Per Ten Thousand Kilometres of Road Length: 1970 –2011 As by above observation the death rate increases by the accident in the following years so we are implementing the solution by we project AH2SM 1.O Solution: AH2SM 1.O In our project we have to detect that there are drunken, unfit ( diabetic patients, heart patients, mentally unstable ) driver or is there any high temperature while driving in automobiles. For this we are using LM35 (Temperature sensor), Alcohol sensor, ADC 0808 (Analog to Digital Converter), LDR, Break Indicator, Relay, LCD (Liquid Crystal Display), pulse sensing device which is implemented by the power supply or ignition of the system . LM35 is precision integrated circuit temperature sensor. LM35 output voltage is linearly proportional to temperature (in Celsius). LM35 thus has an advantage over linear temperature sensors calibrated in° Kelvin, as the user is not required to subtract a large constant voltage from LM35 output to obtain convenient Centigrade scaling. AD converters are used virtually everywhere where an analog signal has to be processed, stored, or transported in digital form. For example : drunken driver driving the car, then alcohol sensor detects alcohol sensor and passes the information through ADC to Microcontroller. Then Break Indicator stops the car and bulb will OFF automatically and displays LCD. the car and bulb are controlled by Microcontroller. Heart Rate Sensor: The Smart Q Heart Rate Sensor monitors the light level transmitted through the vascular tissue of the fingertip or the ear lobe and the corresponding variations in light intensities that occurs as the blood volume changes in the tissue. The EasySense unit can detect that The Smart Q Heart Rate Sensor is connected and the range The Smart Q Heart Rate Sensor is set to. The proposed heartbeat and temperature monitoring device is intended to have the following features: ulations generated by electrical or physical variations in the heart movements. both patients and doctor. Helpful in emergency period. Useful for remote areas. s access to health care while decreasing the healthcare delivery costs. for better portability of the system. me and date of the measured data. Block Diagram of the Complete System System Flowchart: The flowchart of the system is shown in Figure 6. the system is started by initializing the device by connecting the system to a power source. Caution is to be taken while connecting to positive end to a positive portion and negative end to a ground. Then, the microcontroller is initialized by default. The GSM module looks for the network from The GSM module operator. The GSM module may take a while to get the device on and working. After waiting for all the signals required for the set-up, a SMS is to be sent to the device, typing STATUS. If the message is received, then put your finger on the fingertip sensor consisting of photo diode and bright LED. Also, hold the temperature sensor LM35 with other two fingers from other hand. the device will now start to calculate the heartbeat and body temperature from the patient. After the body temperature and heartbeat are calculated, the data or information is sent to a mobile device for display and further analysis where the doctor or physician will be available. Hence, the data or information is displayed on a mobile device along with the date and time at the instant a mobile device was measured. Flowchart"
The plan is to design and initially implement the system in prototype model using fire bird robot. Then plan to implement this idea in actual office environment. Figure 1: General layout of office
"In this project firstly we make a white line path that robot will follow this line as shown in Fig.1. Now robot will start moving and detect the node for the customers place, we also added program to avoid obstacle that robot will stop when robot will detect an obstacle in front. Then as robot will stop at particular nodes or in front of chairs this will stop at the chair for a while if the customer wants to enter code then robot will stop there for longer duration till robot get the code from keypad via customer, then robot will sent the message to kitchen and to billing department for serving the customers in terms of the serving food and for the preparation of billing for that chair number. So as the customers completed after taking food the customers will get bill from billing department and pay to the hotel. So this project work line a person that place order in kitchen and for billing. The flow of process is shown in Fig.2. as robot starts it will follow the line then stop at the chair then place order via sending through GSM then after completion of task the chair will further following the line to attend next customers. Fig 1. Track for Service Robot Fig.2. Flow chart for Medical Service System"
"We are going to use Arduino, CC3000 WiFi chip, Bluetooth Module HC 06, Relay module and current sensor to make an WiFi/Bluetooth controlled smart socket. With this We will be able to control the switching of the device connected to the socket from smart phone, computer, or from any device connected to the local WiFi network or via bluetooth. Hardware configuration​: The Connections are made between Arduino, wifi module, bluetooth module, relay, current sensor. For WiFi prototype module The Connections are as follows WiFi Module Arduino IRQ → pin 3 VBAT → pin 5 CS → pin 10 MOSI → pin 11 MISO → pin 12 CLK → pin 13 Vin → 5V GND → GND The VCC of relay is connected to 5V pin, GND to GND of arduino and SIG is connected to pin 8 of the arduino. Similarly for the current sensor, VCC is connected to 5V pin, GND to ground pin and output to the analog pin A0 of the arduino. After these connections with the help of the breadboard and jumper wires it look something like this The lamp is finally connected as shown in the following schematic The male power plug is connected to the main power supply. Controlling the Lamp​: The arduino code required is uploaded to the arduino. To control the lamp a browser is opened from mobile or pc and to turn on the light the following is typed on address bar: http://arduino.local/digital/8/1 To turn off the light the following text is typed: http://arduino.local/digital/8/0 In place of arduino.local the IP address of the board can be typed Building the interface​: The interface is built and we will be able to control the project from the computer. Using The interface we will be able to control the switch via WiFi, also to see in real-time power consumption of the device connected to it. The interface is based on Node.js that will basically run a web server on a computer. http://arduino.local/digital/8/1 http://arduino.local/digital/8/1 http://arduino.local/digital/8/0 http://arduino.local/digital/8/0 After the successful creation of The interface we can open the web browser that would give the following interface after we visit the webserver created using node.js Bluetooth Control​: For bluetooth controlled prototype connection are as follows Bluetooth Module Arduino Rx → Tx Tx Rx Vcc →​ Vcc Gnd →​ Gnd Further development​: Here we are controlling the lamp using Bluetooth control from an app using voice commands or using the interface in the app. the lamp is controlled from a browser with energy monitoring integrated in the website itself. But this can be further developed by making an app from which we can control the switching of the lamp, monitor the lamp power consumption, schedule the lamp for turning on and off, set the on and off time of the lamp with specifications like date and time, monitor the temperature of the device connected to the smart socket and much more."
"This project is used to control the home appliances like bulbs, fans and water motor, and also give the security for the home, from unauthorised persons. Control part: in control part we are having Bulbs, Fans and water motor (whenever a person enters into the room automatically the bulbs and fans are in the room switched ON. If No one is there in the room automatically bulbs and fans are switched OFF. No one is there in that room automatically bulbs and fans are done using sharp sensors.) Security Part: in security part we are having door locking with digital password, and window security (if an unauthorised person enter into the room through the window automatically buzzer will gives the sound and also camera module is turned to the window. If a person tries to open a door with wrong password automatically the outside camera module is turned towards the door. No one is there in that room automatically bulbs and fans are done using proximity sensors) No one is there in that room automatically bulbs and fans are controlled and monitored by the arduino module"
"The sensors will be placed on the inner surface of each manhole. Whenever a blockage occurs in any pipeline, a blockage will obstruct the flow of sewage water. sewage water gets accumulated and the sensor [8] senses this water overflow and sends signal to the BWSSB. The authorities at the board will analyse the data and according to the priority The authorities at the board will assign the jobs to the technicians. The technician along with the robot will go to the assigned place and fix the robot onto the track present inside the manhole. the robot will move down with the help of motors fixed on the robot. After the robot reaches the bottom of the manhole the robot will sense in which direction there is a blockage and the distance of blockage from the robot. Then the robot will engage the pneumatic system. the pneumatic system will send the telescopic cylinder beyond the blockage and an arm will extend out and bend to 90 degrees downwards towards the blockage which is mainly composed of soil and human waste. Then the telescopic cylinder will retract sweeping the sewage waste onto the robot. the telescopic cylinder will be collected at a compartment placed at the bottom of the robot. the robot will again goes vertically upwards back to the surface along with the sewage waste. As the blockage is cleared, the waste water flows freely."
"The proposed system would be implemented in an prototype working model which is capable of doing following functions: • Detection fire hazard and Actuation multiple water sprinklers to extinguish fire. • Speed reduction and stopping of Bus. • Opening of back panel of bus for speedy exit of passengers. Steps involved: • Literature survey: A study on previous incidents of fire hazards in buses from past decade will be carried out to determine prominent cause of fire hazard. Key spots where probability of fire catching is high. Pattern of fire expansion. • Design of prototype model: A conceptual prototype model will be designed to the particular dimensions. • Fabrication of prototype model: As per design the prototype model will be built using the available resources. The functioning devices like fire sensor, actuators and spraying system is fixed as per design. The emergency exit system mechanism will be built. • Testing and analysis: When the prototype model is ready, there will be testing experiments conducted to test the functions of the prototype model. Then the performance analysis will be made. • Conclusion& Documentation: Based on the testing of the prototype model and the results obtained conclusions would be drawn and future scope will be presented followed by project report preparation."
"Magnetic gripper for collecting the iron dust chips is implemented by using the fire bird V Atmega 2560 and a gripper is attached with this micro controller. For moving and identifying the chips can be done by using the IR Proximity sensor and white-line sensors present in firebird V. Path following and identification is done by program written in C. Identified Dust chips were collected by a gripper. a gripper is attached with the metal which is magnetized and demagnetized on required time. a gripper is attached with the servo motor which is controlled by a program. By the gripper movements of up, down, grip and ungrip, the iron dusts were collected and deposited in a second fire bird. · The implementation is increase the working area that is 360 rotations about the fire bird V Atmega 2560.This could help to increase the working area. · Increase Capacity of the collector. · Identification of chips in various places. The attractive force of the solenoid is determined by the following relations, Maxwell’s relation given by, ( ) ( ) Where, P= attractive force, IN = no of amp turns of coil Ac= area of contact of an object with magnet, Ra , Rm = reluctances of magnetic paths through air and metal respectively. ( ) Where, a=gripper acceleration g=gravitational constant m= mass Fs=factor of safety Flow chart:"
"The customer is the end user of our solution. The customer will have to download the app via a FTP website made available to The customer or through the respective app store, at the time of entry to the facility. the app will maintain constant communication with the server. When The customer wants to go to a particular place in the facility, The customer opens the app and enters the destination and points the camera to the nearest room’s number-plate/aisle nameplate. The directions arrive from the server and The customer follow The directions and reach the destination. In case of the requirement of additional assistance, The customer can use another feature in the app which communicates to the centralized server which then finds the nearest available SVBB(which are normally located in the charging station in every floor). The SVBB then reaches the designated customer’s location. Then The SVBB gets paired to the customer’s mobile phone using a HC-05 blue-tooth module. The connection is done through the app. The customer interacts with The SVBB. The SVBB will just be a base, but The customer will perceive The SVBB as a full-sized virtual robot using AR Modeling. The 3D model will be generated using the fiducial markers which will be displayed on the LCD display in response to the customer’s requests. The customer will terminate connection with The SVBB as soon as the additional assistance is not required. There are four stages our solution : - Image Processing, Path Determination, Augmented-Interface Deployment and SVBB Development & Deployment. Image Processing: The photo of the nearest room/aisle is taken using the app (This is done after the destination is selected by the user). The photo of the nearest room/aisle is then subjected to certain OCR techniques (feature extraction) using customized software developed using open source libraries like OpenCV[4] and Tesseract[5]. The room number (numeric text) derived from the image is sent to the server. Thus the source and the destination are set and are ready to be used for Path Determination. Path Determination: The path to be taken by the user is determined by the server(for obvious security reasons). The entire layout of the facility is taken and stored in the form of a graph with the rooms/aisles, stairs and other path diverting elements as nodes with the distance between stairs and other path as the weighed vertices connecting stairs and other path. Then using a simple graph traversal algorithm like Djikstra’s A* algorithm (F(n)=G(n)+H(n), G(n) is the currently traveled distance, H(n) is the estimated distance to destination), we can determine the path[6]. The path is then broken down into linear sub-paths (any path detours like taking a left turn, right turn will be mapped as a separate sub-path). The first sub-path is then sent to the app. Once the end of The first sub-path is reached (This will be determined through image processing once again), The first sub-path is sent. This is done repeatedly until destination is reached. AR Model Deployment: The first sub-path is determined in the server and sent to the app. the app then displays a 3D floating vector on the camera interface on the screen. a 3D floating vector on the camera interface on the screen shows both the direction and the distance to the direction. the direction is determined with the help of the path and geographic north. a 3D floating vector on the camera interface on the screen is made to always point towards the destination even if the camera is rotated in any direction. Once the end of the sub-path is reached, a 3D floating vector on the camera interface on the screen disappears and the next sub-path is received. a 3D floating vector on the camera interface on the screen is generated. SVBB Development and Deployment: The SVBB is developed using the FireBird V (Or similar mobile robot) as a base. The SVBB is then attached with a bluetooth module and a large LCD display, which is kept tilted towards the customer. After the hardware modifications are done, the SVBBs are programmed with functions and tasks which the SVBBs needs to perform, while displaying the corresponding fiducial marker on the LCD display to interact with the user. It is also programmed to navigate through the floor while avoiding obstacles. Once The SVBB is ready, The SVBB is sent to the corresponding floor The SVBB is programmed to operate in. If the user wants to go to a location not in the floor, The SVBB calls and transfers the user to another SVBB in the other floor. The SVBB then returns to The SVBB station."
"Robot path will be predefined and Robot path will consist of black path. Robot path will design for four plants. The main unit of robot is Fire-Bird V, which will control all the activities. We will use servo-arm for picking and placing water container as servo-arm are easily available and affordable. Also servo motors are less power consuming than stepper motors. Soil moisture sensor would be fix at gripper. 1) Path following: The path in Robot path will be of 1 cm width. Robot path will consist of four nodes of 3cm x 3cm. Three white line sensors are interface with Fire-Bird V. Threshold value for black colour detection would be calculated. Robot will follow the path to reach at plants or at water container. Robot path would be designed as shown in figure (a). 2) Moisture Detection: Moisture would be attached at the gripper of servo motor. The probe of soil moisture sensor which will insert in soil is of 6cm x 3cm dimensions. Approximately, it would be deep in the soil for 3cm to detect moisture of soil. Analog output of the sensor would be divided in three ranges, likewise quantity of water would be selected. First robot will detect the moisture of all plants one by one. And will store the output value. 3) Picking water container: Robot will pick the water container after the moisture detection. Picking task would be performed by two servo motors. 4) Watering plant: Three ranges would be predefined for the output of soil moisture sensor. If quantity to water Watering plant is large then Robot will tilt the water container for large angle. If quantity to water Watering plant is medium then Robot will tilt the water container for less an angle. If moisture content is more then Robot will not water Watering plant. The watering would be given twice a day. The side view of watering plant would be shown as follow."
"1) Protection from wild animals: When animals or persons try to cross the fences, it’ll produce an unwanted sound and will also send the SMS to farm owner with a predefined text which will tell to farm owner that someone tried or is entering or crossing fences of your farm and one LED will also glow. 2) Ability to sense and give weather info: Because of weather sensing mechanism installed and because of Sensors it’ll absorb and test the moisture and temperature of Environment which will help to give weather forecasting information. 3) Locating location of straying animals: There will be a low frequency tag on the neck of animals which is connected indirectly and wireless with the network and circuits of robots which will help to find exact location of animals."
"Modified Things Samba Software: Samba config file has been modified to achive the following things. Why Samba config file is modified? · To access the Directory of External USB Storage Device. · To Add Authentication Security Feature. Lunix Kernel: Why Lunix Kernel is modified? · To Put the file System on a network. · To access the files/data with read-write permission on a network. Step 1: Flash Kernel · Developer board is flashed with AirDrive Kernel (Modified Lunix Kernel). Step 2: Installing Operating System · Computer consisting of flashing tool is used to flash OS in Developer board. Step 3: Attach the display and program Samba Software is installed · Edit the samba config file to achive following things Ø To access the Directory of External USB Storage Device. Ø To access the Directory of External USB Storage DeviceExternal USB Storage Device. Step 4: Reboot The Developer board. AirDrive can be accessed in two ways- 1) AirDrive creates AirDrive own hotspot and other devices through which we wish to access data can be connected. 2) The sharing can be made possible between AirDrive and devices (i.e. computer, laptop, Mobile Phone, tablets etc.) By connecting both to common Wi-Fi network."
"Electrical energy of the battery is converted to mechanical energy through a set of blades designed to achieve cutting operation. The electric circuit ensures power transfer from the battery to run the D.C. motor, whilst the solar panel power to continuously recharge the battery while in operation. The cutting blades tap power from the D.C. motor. When the power switch is on, the electrical energy from the battery powers the motor which in turn actuates The cutting blades tap power from the D.C. motor. The solar panel generates current to recharge the battery, thereby compensating for the battery discharge. The cutting blades tap power from the D.C. motor continuously cut the grass as the mower is propelled forward and the cut grass. Height of cut is adjusted by means of the link mechanism via the lift rod. 4 Sequence Flowchart:"
"The objective is expressed as in the flow chart pattern as flows, FLOW CHART: Start Sensing activity starts. No Is water level high? Yes Microcontroller activates pump for suction Display about the motoring action Halt The complications during water flooding and heavy rainfall are solved here. The situation of water flooding in the arena is sensed by our optical water level sensor. If the water level is high with respect to furrows, our optical water level sensor gives the signal to controller. The controller which in turn actuates the relay connected to the gear mechanism of the pump. the pump is initiated to suck the water back from the arena pour into the nearby sump. the pump is connected to the shaft of the motor. After the pump reaches to the optimum level, our optical water level sensor gives the STOP signal to microcontroller for tending to occlude the pumping action. Thus the process is repeated with displaying the activity. These actions are partly divided into various sections, Sensing Pumping action Adaptive controlling Display unit Block diagram: Sensor Microcontroller Relay Motor Pump"
"The implementation of this project would require the deciding of the size and shape of the duster to be used. Once this has been decided then the rate of chalk dust eliminated must be known and according to the force applied by the user we need to decide the rating of the motor to be used. The D.C motors are now available in almost all required ratings and speed. The more the speed of the fan is, more vacuum pressure is created, and better wiping occurs. This is a very basic phenomenon that can be realized using the available resources. The next step in the process of implementation goes into the selection of the appropriate battery that serves as a power house for the functioning of the entire set-up. This involves the lithium-ion batteries which have the maximum capacity up to 4V, and in case any extension is required then several batteries can be used in series to improve the rating and hence more efficient cleaning can be done. This constitutes a part of the rechargeable circuit, several batteries are replaceable too. If implemented this would be the most efficient way of avoiding the threat caused due to the infinitesimal particulates due to the rubbing of the dust can be minimized. Block Diagram Depicting the Visualization Of The Prototype For Dustless Wiper Lithium ion battery Electric fan with blades D.C.Motor"
"The nutrients required for effective plant growth are Nitrogen(Ammonia or Nitrate), Phosphorous and Phosphate. If the soil is rich in The nutrients required for effective plant growth, then the soil is rich in these nutrients aids for the effective plant growth. In this project we use robot to know the content of major nutrients in the soil. robot takes decision whether to sow the seed or not depending on the major nutrients present. To know the amount of major nutrients robots will be deployed with Nitrate, Potassium and Phosphorous measuring instruments. robot also has container which has seeds in robot, from which seed can be fetched for sowing. The robot checks for the Nitrogen, Potassium and Phosphorous content if the content in the soil is sufficient then the actuator inside fetches the seed from the container to sow the actuator inside in the field. robot now moves few meters ahead depending on the plant sown. If the soil tested doesn’t have enough major nutrients then robot marks that area so that farmer can add fertilizer selectively to that area. By this way robot covers the whole field and the seeds get sown all over. For sowing robot uses the algorithm that if the ratio of nitrogen to phosphorous to potassium ratio is 4:2:1, the soil has enough proportion of major nutrients so the soil decides that soil is suitable for farming and sowing the seed. . Nitrogen is used by plants for lots of leaf growth and good green color. Phosphorous is used by plants to help form new roots, make seeds, fruit and flowers. Phosphorous's also used by plants to help fight disease. Potassium helps plants make strong stems and keep growing fast. The majority of plant-available nitrogen is in the inorganic forms NH4+ and NO3- (sometimes called mineral nitrogen). So it is important that major nutrients are in correct proportion."
"1) Arduino Uno R3:- It is an open source platform for controlling various sensor. We are using this for detecting and controlling water level of Water tank. 2) Ultrasonic Sensor: - This is a Sensor which is use to sense the water level in the tank and give corresponding output to Arduino. 3) WATER PUMP: - We are using Water Pump for filling Water tank depending upon the output of Ultrasonic sensor. · Working :- We are using Arduino Uno R3 for the implementation of water level detector and controller. For the Water level detection, Ultrasonic sensor is used. Square wave of certain frequency is passed through Ultrasonic sensor. The output of Ultrasonic sensor is in terms of start time and end time. Using proper conversion, Actual depth of water level can be calculated. If the Water level is below the minimum level, Arduino will send a signal to Water Pump through ULN 2003 and Relay. Once Water Pump turns on, Water level goes on increasing. On reaching to certain specific level, again corresponding signal is given by Arduino and corresponding signal will automatically turn off Water pump. 1) Android App: - Android App will receive notification when moisture level of soil will be below some particular threshold value. Android App contains Eclipse Paho Library integrated in Android App to interface App to CloudMQTT. 2) CloudMQTT: - This is a broker which intake the published topic from Android App and display the message on WebSocket. This is bridged with Mosquitto broker which bridges the messages from CloudMQTT to Mosquitto Broker. 3) Mosquitto Broker:- It is a broker which intakes message from Cloud and display It on Raspberry pi. (Here we have pointed Mosquitto to Cloud host, so as soon as message is received by CloudMQTT, mosquito broker will display the message on Raspberry pi). 4) Raspberry pi: - As soon as we click ‘ON’ button on the App Raspberry pi gets message through CloudMQTT and mosquito broker, so depending on the message the App Raspberry pi will trigger the action (Here Sprinkler is triggered). 5) GSM Module: - Along with online module, we can also use the same system offline using sim900A GSM module. As soon as the App Raspberry pi receives message offline through GSM module some triggering action will take place. · Working:- Soil humidity/Moisture/Temperature sensor is placed in the field underneath soil. As soon as the humidity/Moisture/temperature of the soil decreases to certain threshold, the soil will send signal to the App Raspberry pi. The code is written in a way that as soon as the output of the sensor falls down certain threshold the App Raspberry pi will publish a topic /soil/humiditycheck/low with a message “Humidity of soil is low, please take some action on “Humidity of soil”. Mosquitto broker is responsible to publish the topic on CloudMQTT and the app is bridged with CloudMQTT. So that the app will receive the notification as soon as the humidity level is low. Now here we can apply two cases such as 1) When Farmer receives the notification about low humidity Farmer takes action through the app, i.e. App contains a button that turn on the sprinkler via Internet(App->CloudMQTT->Mosquitto->Raspberry pi->Motor- >Sprinkler) 2) When the Humidity is low the App Raspberry pi automatically gives signal to sprinkler and the farmer interaction is avoided Here the 1st case is used during the off season. Suppose the off season is over and the crops are not yet plugged, so ultimately the soil moisture level would be low. In the 1st case we give powers to Farmer to take action on it. Here is the app, when the send button is pressed, the send button will turn on sprinkler. Fig. the app As soon as the send button is pressed the topic is publish on CloudMQTT, Raspberry pi is pointed to Cloud host. So as soon as CloudMQTT receives the message mosquito connects to Raspberry pi (mosquito subscribes to the topic) and the message is received by Raspberry pi and the message takes triggering action according to the message. (Here triggering action is to turn on sprinkler) When message received by Raspberry pi is “ON” message received by Raspberry pi turns on sprinkler Fig. Raspberry Pi Console This is Raspberry pi console in which the code is saved (pah.py). This resembles that when payload “ON” is received by Raspberry pi it will trigger some action."
"The structure of a robot is as a stone. The structure of a robot can shoot with the gun, and operator can handle the gun with wireless camera. The structure of a robot runs on an off road or any type of a ground without any problem. The structure of a robot works better than a soilder The structure of a robot can run and easy to control. The structure of a robot will be smaller and structure is as a stone which is not easy to visible. The structure of a robot can be control with Laptop,Computer ,Smartphones and the reciver. The structure of a robot can run at any situationand any condition. But The structure of a robot will have a chain tires. Instead of a normal tire."
f vision based intelligent home automation and security system https://www.researchgate.net/publication/269297095_
- The project can be practically implemented in the field.
"There will be a number of robots (say 5) operating in the restaurant. Each robot will consist of an arm structure mounted on a differential drive mobile car. Each robot will follow a route of a black line made on the floor of the restaurant. All robots use unicycle model to move with PID controller to minimize the error in movement. All robots will be resting in standby mode in the standby zone(probably near the kitchen). Once a customer is seated on his table, a robot will be assigned to his table. All the lines on the floor will be pre-recorded in Each robot's memory in form of a graph. All tables in the restaurant will act as a vertex in that graph. Each robot will go to his table finding the shortest path from Each robot position by minimizing cost (time taken + avoiding bumping into costumers and other bots). Algorithm such as Dijkstra or A- Star can be used to traverse the waiter robots along the black line.Bots will take order through a tablet screen mounted on Each robot's chest (though fixing Bots on the table is a good option too). order will automatically flash on a screen in the kitchen for chefs. Each robot will go back to the standby zone and wait for order to be cooked. Once order is ready, chef will call Each robot to serve order. Then Each robot will again use the shortest path algorithm to traverse back to the destined table. Future Goals : We can also make a Database of the customers, the customers previous orders and recommend the customers dishes which will raise costumer experience. Further we can also automate other jobs in the restaurant like cleaning tables after a customer leaves."
"This robot can be implemented at any place where person to person cash transaction is carried. This can be used at Bus station and Railway station for the automation purpose. This is also useful at medical stores as an accessory to the wending machine dispensing general medicines. This is used on petrol pumps and gas stations to in order to make petrol pump manless. Government can use this device to automate electricity billing system, water billing system. this device can be used to automate the mobile phone recharge process. this device dispensing food items, eatables, refreshments, tea, and coffee etc. this device will change the entire experience of cash transaction taking this device to a new level. this device has few units which carry different operations and processes. few units which carry different operations and processes are as below: 1] Cash intake unit: This unit accepts cash in two forms i.e. coins and notes, which classifies This unit in two sections. Coin intake unit starts with a slot of rectangular cross section through which coin is inserted and allowed to roll through Coin intake unit. The height of rectangular slot is decreasing linearly with depth which causes coin to stop at a certain position according to coin diameter. All the standard sized coins will trigger a circuit which is halfway to make sure that coin is genuine. Trigger will activate an electromagnet which is connected with a variable resistor and ammeter in series. Electromagnet will lift the coin up. Current through Electromagnet will be directly proportional to the weight of the coin. This test will ensure that the coin is genuine by the coin dimension as well as weight also identifies the value by comparing the coin to the currency coins. This comparison will be done through a processor using a program. Coins will be sorted and stored in different containers according to Coins value. Note intake unit starts with a pair of roller and rubber belt rolling over Note intake unit. This rubber belt has conducting foil on This rubber belt both edges which are in contact with brushes and each other. As a note passes through This rubber belt, the silver line on the note [which is sign of originality of note] will complete the circuit, and the note is passed for further confirmation. the note will then be checked for the note size by passing through a belt having grids of small holes. At one side of this hole an LED is mounted and on other side a photo sensor is mounted. This test will verify and compare the dimensions of note to standard notes and determine This test value by means of a program. Notes will be sorted and stored according to This test value. 2] Calculation unit: 2] Calculation unit will calculate the total money inserted, compare 2] Calculation unit with the amount to be deducted, and will calculate the amount to be paid back. 2] Calculation unit is contained in a processor programmed with necessary information and operations needed. 3] Change dispensing unit: 2] Calculation unit is programmed to dispense the amount to be returned with minimum number if coins and notes. 2] Calculation unit takes coins and notes from previously sorted and stored notes and coins from various containers, and keeps track on the amount available in the machine. Currently we are working to make the machine able to accept and scan multiple notes simultaneously as this design is only able to scan and sort multiple notes one by one. we also desire to scan notes graphically for the important marks and symbols on it. The advancements and developments will soon be added."
"The length of fish is about 1.2m, spine made out of aluminum alloy, ribs made by hollow polystyrene, skin made up of polyurethane elastic fiber yarn. The 8 vertebras are driven through an elaborate system of pulleys and cable tendons by 6 brushless DC servo motors mounted outside the fish above the waterline inside the carriage support structure. These tendon drives are the mechanical analog of the biological fish's muscles. These tendon drives not only could maintain both low power consumption and high efficiency in the sustained swimming, These tendon drives also achieves highvelocity mobility in the outbreak swimming. The biometic robot fish, takes Median and/or Paired Fin (MPF) swaying model as its bionic prototype. A variety of fish has A variety of fish own numerous unique swimming patterns, and A variety of fish are significantly better than the Unmanned Underwater Vehicle (UUV) in terms of mobility, acceleration ability, and boost efficiency. Utilizing biomimetic robot fish, people could not only do exploration of underwater resource and test quality of water area and find out contaminated area people can also do the exploration of bottom topography and underwater archeology and military reconnaissance. The schematic diagram of the tail mechanical structure is shown in Fig. 2. the tail mechanical structure is composed of two parts: Oscillate part and Drive part. The Oscillate part simulates the fish tail motion by two joints designed according to the tail parameters calculated. The Drive part of the tail is composed of a pair of cams and two slide bars connected to joints. These two cams rotate in reverse directions to push slide bars in the direction of body-axis to drive all joints and the tail fin to oscillate. By calculating the appropriate cam shape, we may implement the position control of slide bars at all the sampling points, which may drive the tail to fit the carangiform propulsive mechanism. DC motors are adopted in this paper instead of step motors or servo actuators, which may offer more propulsion power. Fig. 2 The tail mechanical structure"
"A robot with the mounted camera will be placed at the required site. One camera mounted on the front with ultra-sonic sensors will detect the path A robot with the mounted camera has to follow and the objects, which will be pre-defined. Then A robot with the mounted camera will move and start taking pictures of the crops. The operation of A robot with the mounted camera is illustrated with block diagram as shown in Fig. 1. Afterwards, The operation of robot will send these images wireless to the server and then the server will run A robot with the mounted camera learning algorithms hence detecting the condition of the crops. After A robot with the mounted camera has successfully classified the crop to most affected, moderately affected and least affected the next step will be sending signal to spray the pesticide. the pesticide will have four constituents, namely – Robot movements, Image Processing, Verification/Classification, and Spraying Pesticide. Fig. 1 Crop disease detection using a robot. Robot Movement: The selected area will be entered in the pesticide. The selected area would generally be crop field with a particular crop. A robot with the mounted camera will follow a desired path so that every crop is covered. A robot with the mounted camera will have a camera and an ultra-sonic sensor detecting objects between the path. these images will be sent to the server for further processing and A robot with the mounted camera will have mounted pesticides to be sprayed in case of a crop disease present. Image Processing: The image sent to the server will be put through the Machine Learning Algorithm and will be classified using MATLAB. As the crops will be covered on one side at a time hence there will be two cameras on the robot, which can take data from both sides of the crop. MATLAB software can be applied in the image processing section, applying color detection algorithms which will help in analysing a crop disease present. Classification/Verification: Classification/Verification will be based on the severity and symptoms that can be observed and recorded through a statistical analysis. On analyzing the data and classifying the images the type of disease will be identified and the necessary step will be taken which will be spraying Pesticide. Spraying Pesticide: Pesticide will be sprayed on the data sent from the server after the classification and hence helping the farmers in saving the farmers crops in real time. Then the data will be uploaded on the database and the robot will move to the next grid. Again the process will begin in a loop. Flowchart: Sequence Diagram:- The current crop disease detection algorithms and projects have certain limitations regarding the automation, coverage and then, The current crop disease detection algorithms and projects also required a lot of manpower for conducting surveys and providing information about the same. In order to automate this entire process and provide a more efficient and optimal solution, we decided to come up with an idea of crop disease detection, prevention and soil monitoring by using image processing and automated spraying of pesticide. Due to the automation applied, the probability of getting optimal references increases. Problems like limited coverage of plants and manually viewing the crops, and analysing data required large cost input which can be managed easily. Transfer of processing techniques from old paper-pen methods to completely automated methods guarantees correct and optimal results with the added advantage of less manpower consumption."
"Design: As shown in the architecture (Figure 1), many useful features can be implemented in school bus. If any important announcements are to be made, the school staff can upload the audio message or the scrolling message through an app which is sent to the database and then later will be broadcasted in the school bus through the IoT device. The audio message will be broadcasted through speaker whereas messages will be displayed through a digital display. Along with this the location can also be tracked and the next location can be displayed with the help of scrolling messages through internet. Attendance status of the student is implemented with the help of RFID chip. RFID chip can be implemented in the ID card of the students and can be easily scanned by the sensor which will be placed inside the bus. This will take the exact count of the students in the bus. RFID sensors interact with IoT devices which then sends the information to database in Internet. Parents are notified regarding status of the bus, location of bus, college announcements and others extracting data from the database in the Internet. Figure 1: System Architecture"
"TGMDDS, a GSM-GPS enabled & Camera Equipped Drone, routinely monitors the level of Toxic Gases in the atmosphere. The system fetches the concentration of the constituents of the air as input to The system as shown in fig1. The Intensity of the toxic gas above the threshold can result a complication in the environment. Fig 1: Overview of"
We will install sensors in different sections of bike and different sections of bike digital output will be collected through a microcontroller. a microcontroller will read and understand this data and will send appropriate coded voice signal to Bluetooth module. The receiver will be fixed on the helmet which will forward this signal to speaker. Also We will implement two way interaction via introducing a mike which will send data to microcontroller. But two way interaction is possible only after one way is implemented. Flow Chart: MotorBike Sensor Input 1 Sensor Input 2 Sensor Input 3 Microcontroller board Bluetooth Sender
"It is a robot which is used to extinguish the fire . It is manual handed robot controlled by the remote control fitted with a camera by which the person who is handling or working on a robot which is used to extinguish the fire can see the location of the place where the massive destruction is causing by the fire. the robot work according to the fire causing situation as a robot which is used to extinguish the fire is placed in the fire causing area a robot which is used to extinguish the fire is work according to the person instruction who is handling a robot which is used to extinguish the fire . a robot which is used to extinguish the fire is designed in such a way that arm is set in the projectile motion,. combination of chemical is being exposed from a robot which is used to extinguish the fire then then chemical substance which thrown on fire, combination of chemical is being exposed from the robot then then chemical substance which thrown on fire will explode and changes into dust and smoke . the idea is to prevent or to extinguish the fire which is caused by different reasons like by electric short gas leakage, chemical explosion in various places . a robot which is used to extinguish the fire is a prototype of the actual one. Sensors used here are simple infrared (IR) photodiodes that detect IR rays coming out of the fire. The sensor board mounted on top of a robot which is used to extinguish the fire’s chassis is circular in shape so that ’s chassis gives a robot which is used to extinguish the fire all-round detection view of 360°. Sensors are equally spaced at 45° each. These act as the eyes of a robot which is used to extinguish the fire. ​ ​A DC pump is used for the purpose of extinguishing fire. DC pump pumps out chemical material stored in a bottle.​ DC pump is combined a foam container with non-CFC and cannot be flammable Stage 1: Fire detection (autonomous mode). IR photodiodes are connected in reverse bias as shown in the circuit diagram of the sensor module . Anodes are commonly connected to the ground and cathodes are connected to the 5V via resistors of 1MΩ each. Voltage across the photodiode is given as input to ADC pins (PA0 through PA7) of ATmega16. When IR waves fall on the IR photodiode, its resistance decreases from 650kΩ to 150kΩ , reducing the voltage across the photodiode, thus changing the input voltage at the ADC pin. By proper quantisation, the presence and absence of the flame can be distinguished. Similarly, eight IR photodiodes mounted in a circular fashion on the sensor board help detect the fire; the corresponding LED glows if fire is detected. The cone of detection of the IR photodiode is large, thus decreasing the resolution of the system. This problem can be solved by properly shielding IR photodiodes. Code to detect the presence of fire using ADC is as follows: { unsignedcharv; v=read_adc(0); if(v>=0 && v <=128) //Stores the digital value of the analog voltage at ADC 0 fire_detected();if(v>128&&v<=255) fire_not_detected(); } Stage 2: Extinguishing fire. ​Constant feedback from sensors is fed to the main module through CON4, and hence position of the fire with respect to the robot is determined. The main module includes an ATmega16 microcontroller, two L293D motor driver ICs to drive motors, a water pump and RF receiver RX1. The circuit diagram of The main module is Circuit diagram of the main module (robot) The basic function of the algorithm is to orient the front sensor in front of the fire so that the nozzle of the pump comes directly above the fire source. When this is achieved, the pump starts and extinguishes the fire. the robot moves with the help of two motors, whose sense of rotation is controlled by the controller, depending on the feedback from the front sensor in front of the fire. Stage 3: RF communication and manual control (manual mode). the robot is controlled by the operator with the help of a wireless remote (circuit diagram is shown ) that uses an RF module for communicating with the robot. Circuit diagram of the RF remote Switches, push buttons and joysticks are provided on the remote that controls various tasks such as autonomous mode selection, reset and starting the pump. For each command, the remote sends a specific character that is received by the robot and the corresponding operation is performed. Software program Programming of the AVR is done using embedded C language. Software program Programming of the AVR is similar to C language but includes all functionalities of C as well as access to the AVR pins, peripherals and controls. C code is converted to hex code using WinAVR. Hex codes generated are burnt into MCUs for the main module (robot) and the remote module. Working of the robot is explained as comments in the main module (robot) and remote module source codes. the robot jumps to the main function where the object code actually starts. At remote module, a DIP (DIP1) switch is interfaced using which you can select operating mode (autonomous or manual), switching of the water pump, reset all settings or LED indicators test mode WinAVR is a suite of executable, open source software development tools for Atmel AVR series. the robot includes GNU GCC compiler for C and C++, Programmer’s Notepad, Makefile, etc."
"The user will be using the brain wave sensor. The commands through the brain wave sensor will be linked with the BCI board. the BCI board is interconnected with the computer which is interlinked with the arduino. As soon as the brain wave sensor senses the command from the user’s brain, the arduino gets an input. Based on the response from the brain wave sensor, the arduino instructs the micotran to perform the corresponding actions which are empowered with a BlDC motor. Some home appliances like fan and lights can be made on or off from the place of the user , by using the switch in the robot or through brain wave sensor. Block Diagram: Brain Wave Brain Controlled Sensor Interface Board Battery Arduino Micotran Home Automation Battery: We can make use of a 24v LIPO battery to operate a wheel chair motor which is nothing but 24v dc motor . Brain Wave Sensor: At the root of all our thoughts, emotions and behaviors is the communication between neurons within our brains. Brainwaves are produced by synchronized electrical pulses from masses of neurons communicating with each other. Brainwaves are detected using sensors placed on the scalp. They are divided into bandwidths to describe They functions (below), but are best thought of as a continuous spectrum of consciousness; from slow, loud and functional - to fast, subtle, and complex. Brain Controlled Interface Board: Open BCI is an open source brain computer interface platform. Open BCI boards can be used to measure and record electrical activity produced by the brain (EEG), muscles (EMG), and heart (EKG). Brushless dc motor: Brushless DC electric motor (BLDC motors, BL motors) also known as electronically commutated motors (ECMs, EC motors) are synchronous motors that are powered by a DC electric source via an integrated inverter/switching power supply, which produces an AC electric signal to drive the motor. In this context, AC, alternating current, does not imply a sinusoidal waveform, but rather a bi-directional current with no restriction on waveform. Additional sensors and electronics control the inverter output amplitude and waveform (and therefore percent of DC bus usage/efficiency) and frequency (i.e. rotor speed). http://www.brainworksneurotherapy.com/what-are-brainwaves http://www.brainworksneurotherapy.com/what-are-brainwaves https://en.wikipedia.org/wiki/EEG https://en.wikipedia.org/wiki/Electromyography https://en.wikipedia.org/wiki/EKG https://en.wikipedia.org/wiki/Synchronous_motor https://en.wikipedia.org/wiki/Synchronous_motor https://en.wikipedia.org/wiki/Direct_current https://en.wikipedia.org/wiki/Direct_current https://en.wikipedia.org/wiki/Inverter_(electrical) https://en.wikipedia.org/wiki/Alternating_current https://en.wikipedia.org/wiki/Sinusoid https://en.wikipedia.org/wiki/Sinusoid Electronic Speed Controller: An electronic speed control or ESC is an electronic circuit with the purpose to vary an electric motor's speed, its direction and possibly also to act as a dynamic brake. ESCs are often used on electrically powered radio controlled models, with the variety most often used for brushless motors essentially providing an electronically generated three-phase electric power low voltage source of energy for the motor."
"As per the above images, the firebird will have a vision sensor having cameras, a long stand having all the sensors for diagnosing basic tests and more. The implementation of this type of equipment on the bot will be economical. the bot can collect the live video feed and store the bot in the storage bank. When needed, the respective tests to be taken are chosen by pressing the buttons in the long stand having sensors. The height can be adjusted by adjusting the long stand. There are various diagnostics like checking pulse rate, Urine analysis, glucose analysis, blood analysis, etc. The various sensors used are · Pulse sensor to measure the heart rate (clip it on your finger tip to measure heart rate) · nMIS sensor which detects biomolecules in urine · Glucose sensor to measure level of glucose in the body (keep the tip of the finger in the shown area) · Biosensor having urine test strips with small square coloured fields are dipped into the urine sample and then after some time and the resulting colours are compared with a colour table using colour sensor. It shows which colours indicate normal and abnormal values · ECG sensor module is used to take ECG readings by manually placing the leads in the body · Micro Silicon MEMS device for counting RBC’s and WBC’s or · Optical sensor-driven device for counting WBC’s through the skin or · Automated blood cell analyzers for complete blood count · And more. There can be a user interface for selecting the types of tests to be performed for the patient. The priority of the tests can also be controlled. Then the user needs to place his body parts in the respective area for the tests to be taken like placing his finger for checking pulse rate etc. The syringe needles used in the bot should be replaced with a new one before another test. All the basic test results are readily available in the storage bank of the bot. the bot can prioritize the tests based on which is needed first for identifying the disease of the patient."
"Bag Manufacturing Process Reduce Design Time and Improve Performance for Bag Making Manufacturers. This white paper takes a closer look at the key technologies and critical automation solutions available for building high performance based bag making machines. 5. Optical Sensor High performance 6 6. Pneumatic cylinder Single acting 3 1000 3000 7. Pneumatic cylinder Double acting 2 1000 2000 8. Aluminum Frame L- Shape, 15 Mtr. 500/Mtr. 7500 9. Pneumatic Pipe 500 10. D.C. Valve Solenoid operated 3/2 3 1500 4500 11. D.C. Valve Solenoid operated 5/2 2 1500 3000 12. Wire 500 13. Connector Male / female 200 14. Screw Driver set 1 400 15. Drill machine 1 1300 16. Drill bit set 1 500 17. Hexa blade 10 200 18. Hexa handle 1 200 19. PLC FX5U-32MT/ES 1 None 20. HMI GS-2107-WTBD 1 None 21. VFD FR-D720S -025-EC 1 None 22. Servo system MR-JE-20A 1 None 23. LVS MCBs 1 None Bag making typically has certain main functions which make up of material feeding, sealing, cutting and stacking. 1. Power supply section: In Power supply section we are using two alternative ways to supply power to complete assembly one is conventional power supply and another is solar panels. By adding solar panels to supply the power we are adding one more advantage to the design or we can say by adding the design we are saving the electricity. 2. PLC (Programmable Logic Control): PLC section consists of inbuilt power supply, input model, output model, programmer and programming device. PLC section is used to automate the process by programming. With the help of PLC we can reuse the model for another process by reprogramming the model. 3. HMI (Human Machine Interface): AHMI is the input-output device through which the human operator controls the process, and which presents process data to a human operator. HMI (Human Machine Interface) provides the information in graphical form to monitoring person. 4. Feeding Section: Feeding section consist of aluminium base, papers, pneumatic cylinder and sensor. In this section a bunch of papers are kept over the aluminium sheet. Below the aluminium sheet there is paper sensor which senses the paper available or not. If there is no paper present in the aluminium base paper sensor which senses the paper available or not will detect that and the switch will automatically stop the further manufacturing process. the further manufacturing process feedback is given to the pneumatic cylinder, which helps to role the paper into another section (i.e. gluing section). Fig: Block Diagram of System 5. Pasting Section: Pasting section consist of aluminium base, gluing mechanism, folding mechanism and stacking mechanism. In this section it takes the paper from this section. There are two sensors available at the right end of the aluminium base, which detects whether the paper is perfectly placed or not. The feedback of two sensors available at the right end of the aluminium base, which detects whether the paper is perfectly placed or not is given to this section to stop feeding the paper to this section. Once paper sensor which senses the paper available or not senses the paper paper sensor which senses the paper available or not starts the gluing mechanism. The gluing bottles are supported by the pneumatic cylinder, which is used to glue the sides of paper. The pneumatic cylinder is placed on rack and pinion mechanism. Apart from the gluing mechanism there is another gluing and stacking mechanism present on both sides of paper. There is atray in which glue is filled and glue consists of a flat plate for gluing. There is also a rack available above this tray which is filled with the bag handle. Again by using The pneumatic cylinder, glue pushes the bag handle on the glued portion. The base consist a u shape of folding mechanism. After the gluing and stacking part is over, glue folds the paper from middle. After folding is over again gluing mechanism starts. glue glues both the sides of the paper. There are plates available at both comers of The base for last folding of paper at the corner. the gluing mechanism is made possible with the help of motors. There is also a flipping mechanism, which flips the paper bag to the next section (i.e. stamping section). 6. Stamping Section: Stamping section consists of aluminium base, stamp, pneumatic cylinder and ink pad. the next section (i.e. stamping section) accepts the paper bag from the second section. There is a sensor which senses whether the paper bag is present or not and the paper bag feedback is given to the stamping motor. There is a stamping stand which can move in both clockwise and anticlockwise direction (i.e. 90 degree).if paper bag is present the stamping stand will rotate anticlockwise towards the ink pad. the stamping stand will soak the ink from the ink pad and then again comes back in clockwise direction for stamping. After stamping the pneumatic cylinder is activated with the help of feedback given from the stamping mechanism. The finished paper bag is the rolled out with the help of the pneumatic cylinder. In the tray there is a sensor which senses The finished paper bag and The finished paper bag feedback is given to the pneumatic cylinder to get deactivated. Flow Chart: Fig : Process flow algorithm Sequence Daigram: Paper Feeding Handle Loading Handle Pasting Paste Distribution Phase I Paper Folding Paste Distribution phase II Product Shifting Printing Final Product Stacking"
"The basic block diagram for myoelectric prosthetic hand is as shown below: The block diagram of myoelectric sensor system is as shown below: Myoelectric Sensor System Robotic Arm Myoelectric Pickup Instrumentation Amplifier – AD620 Low Pass Filter Myoelectric Pickup Instrumentation Amplifier – AD620 Low Pass Filter Myoelectric Pickup Instrumentation Amplifier – AD620 Low Pass Filter Myoelectric Pickup Instrumentation Amplifier – AD620 Low Pass Filter ADC AT89c51 Micro Controll er 3 The first and most important component of myoelectric sensor system is myoelectric pickup. This is essentially a surface electrode similar to ECG electrode and constructed using three steel or silver plates. Dimensions of the plate depend on the size of muscle under inspection. Two plates are connected across the muscles under study and third plate that acts as reference on connected to any muscle at rest. The instrumentation amplifier amplifies the difference of signal between the two plates with respect to the reference plate. The primary requirement of instrumentation amplifier is that it must have high CMRR since pickup is having high common mode noise. The output of instrumentation amplifier is applied to Low pass filter to remove high frequency and line frequency noise. Finally the signal is converted to digital form using ADC. A multichannel ADC is more preferred because system may have multiple signals from muscles from different position. Microcontroller is used to process myoelectric signals and decide appropriate servo motor to produce appropriate hand movement. Microcontroller sends Information about motor and Microcontroller movement to robotic hand system. Robotic Arm: In Robotic Arm, number of servo motors required depends on Degree of Freedom required in the hand. Usually for every finger 3 motors, wrist motion 2 motors, elbow motion 1 motor and shoulder requires 2 motors. The block diagram robotic arm is as follows: AD620 Instrumentation Amplifier VCC + - Muscles Output AT89C51 Microcontroller Servo Driver 1 Motor 1 Servo Driver n Motor n . . From Myoelectric sensor 4"
"Block Diagram: In this project we are designing the agricultural autonomous Robot which will sense the conditions in real time and then decide which plantation is best suited for that particular field. For this, we are analyzing the field parameters such as, Temperature, humidity, soil Moisture etc. Robot will also have a Plough to plough the fields, and then a seed dispensing mechanism, Watering mechanism so, in all this is a completely autonomous robot. The main feature of Robot is the Ability to sense the health of plants using Image processing. For this we are using a special purpose Web-cam which will take photos inside the field and analyze the growth according to the height, colorization of leaves etc. A vision- based row guidance method is presented to guide the robot platform driven along crops planted in row. And the offset and heading angle of the robot platform driven along crops planted in row are calculated by detecting the guidance row in real time in order to guide and control the robot platform driven along crops planted in row. Vision-based row guidance is to use camera to detect and identify crop plants and then to find accurate and stable navigation information from the binary image. The gripper arrangement with arm is used for planting, harvesting, and to spray the pesticides to the plant whenever required. The camera is used for monitoring the growth of the plant. IR sensor is used to detect the insects or animals present in the field. The requirements of the water are identified by IR sensor. The level of pesticides and fertilizers can be detected by IR sensor. If the water resources or pesticides are insufficient an alerting buzzer sound is produced. In the concerned field the fire bird v robot is placed to move around the fire bird v robot. 4 Flow Chart: For Plant Health Indication N N Y START START ROBOT SEND COMMAND TO START CAMERA IS CAPTURING DONE? IS WORK DONE? END INDICATE PLANT HEALTH IMAGE PROCESSING 5 Flow Chart: For Water Spraying N Y START ROBOT Fill water in robot tank Is tank empty? y IS TEMP<SET POINT? N N IS WORK DONE? END START SPRAYING Y 6"
Step-1: Real Time data transmission between mobile robot and control room (computer with MATLAB). Step-2: Gathering data and Step-2 transmission with multiple ultrasonic sensors to control room. Step-3: Building a map on MATLAB by received data. Step-4: Fuzzy logic based algorithm will be used to move the robot in the environment without collision with any object. Step-5: GPS module will be used to avoid the multiple mapping of environment.
Step-1: Whole area will be captured as an image by a digital camera interface with MATLAB on a PC. Step-2: Using image processing toolbox the free path or Whole area will be found and as well initial position and destination position. Step-3: Using fuzzy logic a path will be created and the command profile will be sent to Robot. Step-4: The real time image will be captured after few seconds and The real time image will track the correct path of Robot if there is any change in the environment. Step-5: Robot will save Robot to collide with any object using sharp sensor.
"As we have seen number of the times the dustbins are getting overflown and concern person don’t get the information within a time and due to which unsanitary condition formed in the surroundings, at the same time bad stinky smell spread out due to waste, bad look of the city which paves the way for air pollution and to some harmful diseases around the locality which can be easily spreadable. The project we proposed based on an innovative system which will help to keep cities clean and it can be effective step in SWACHH BHARAT ABHIYAN. an innovative system which will help to keep cities clean monitors the garbage bins and informs about the level of garbage collected to directly to the main office. For this we an innovative system which will help to keep cities clean uses IR sensors placed at the top of side of bins to detect the garbage level. After detecting the levels, when the bins are full system sent message to main office and through main office message is transferred to the robot which depart to the garbage box and replace the full garbage bins with empty bins. we can provide unique id to each garbage bins so that it will be easy to identify which garbage bin is full. Details can be accessed by the concern authorities and take immediate action to clean the dustbins. Dustbin is divided in two parts one parts have decomposed waste and other have non decomposed waste. non decomposed waste converted into compost which is used by farmers in non decomposed waste land. According the figure the different block indicates different areas of the cities and the numbers indicates the unique identity of the particular bins. Whenever the garbage is full the garbage transmit message to the main office with the some information like bin id or coordinates. Then office transmit message to the robot with bin information then start and reach the following coordinates and take the full dustbin and replace which garbage bin with empty one. Then the robot with bin information take the garbage bin which is full to the main office and which garbage bin machine send instruction to the robot with bin information to take the garbage to the garbage collection store and leave which garbage bin there and after the robot with bin information move to which garbage bin parking area. At the garbage collection store which garbage bin handle the decomposable and non-decomposable waste. And then do further process to convert the decomposable and non-decomposable waste into compost and used the decomposable and non-decomposable waste efficiently in farming and rest of waste is done for recycling."
"The system is divided into two major components: Virtual Reality Farming System Fire Bird Virtual Reality Headset I. FIRE BIRD : Fire Bird is a robot built over the ATMEGA2560 that navigates around the farm. Fire Bird is equipped with a HD web camera (an Infra Red LED light is attached to Fire Bird for night vision) which is capable of rotating and capturing a 360-degree panoramic view of the farm. This is accomplished by sensing the head movement (through the smartphone’s accelerometer and gyroscope) of the farmer when the farmer wears the VR headset, into with the farmer phone is inserted. Hence, the camera’s rotation is synchronized with the farmer’s head movement. The front and back movements of the FireBird are remote-controlled by the famer. Not only does it successfully capture the farm view in the dark, but also is wind and waterproof. The size of the the FireBird prototype is about 2-3 feet. Fire Bird is mounted with multiple sensors to allow Fire Bird to capture the desired information about the soil and weather conditions. Since the moisture level of the soil varies throughout the farmland, data about the moisture level is collected every few feet. the FireBird the FireBird is GPS enabled and hence does not, in any case, cross the farm boundaries. In addition, the FireBird the FireBird is solar powered and charges the FireBird through a solar power charging station present on the farm. Figure 1: Firebird"
"Robot initially moves from Robot starting point When Robot move to Robot first node Robot checks whether the node count limit is reached its first node maximum or not. If NO then Robot display the number of Tamil and English issued. If YES Robot checks the colour which is placed at the mansion. the colour which is placed at the mansion is predicted with the help of Proximity sensor by measuring the colour which is placed at the mansion distance which is reflected from the box. If the colour which is placed at the mansion is ‘blue’ then Robot will deliver the Tamil newsletter. The count of Tamil newsletter issued and the node value is incremented by 1, then The count of Tamil newsletter issued moves to its first node. If, NO The count of Tamil newsletter issued move to next loop. The count of Tamil newsletter issued checks whether the colour is red or not. If YES then Robot deliver Tamil newsletter and increment English newsletter count value by 1 after that Robot moves to its first node. If, NO Robot moves to another loop. Here Robot checks for the Green colour. If Robot is Green then Robot will deliver both English and Tamil newsletter and increment Tamil and English newsletter count value. If NO then Robot will move to its first node. The above process continuous till The above process reach the end points, once The above process reach the end point The above process displays the no. of Tamil and English newsletter delivered. FLOWCHART: Yes No No Yes No No Yes Yes Start Set T=0 , E=0 ,N=0 Move to node(N) if N<=limit In this loop this loop checks whether the node reaches this loop final destiny or not Check the colour by measuring this loop distance from the proximity sensor Display the number of Tamil and English newsletter issued Stop If Colour =blue Deliver Tamil newsletter Increment T&N If Colour =Red Deliver English newsletter Increment E & N If Colour= Yellow Deliver both English and Tamil newsletter Increment both T,E and N T-Tamil newsletter E-English newsletter N-node"
"The TONQUEBOT is a moving, integrated robot contains proximity sensors, taste sensors which identify the tastes . The TONQUEBOT is controlled by a hand held device which controls The TONQUEBOT locomotion. The taste sensors are coupled with which send back info about the taste to the user. Movement : a moving, integrated robot moves about with four set of wheels coupled to a servo motor and proximity sensors to tell about a moving, integrated robot surroundings. a moving, integrated robot moves about by accepting command from the hand held remote . Taste sensor : a moving, integrated robot is connect to an arm coupled with the servo motor whose tip contains the taste sensor. an arm coupled with the servo motor whose tip contains the taste sensor can be moved only in the vertical and horizontal directions . Thus dipping and removing the taste sensor. The sensor identifies and senses the taste and replicates the taste sensor to our system present , which shows our the readings."
"Basic implementation begins from the doctor who writes Prescription. Prescription then printed as QR code, which been done by the nurse. Then as usual, prescription taken by a person to buy Pills to the medical shop. In Medical shop, employee receives prescription and gives to the bot. Here the automation begins that the bot scans the QR code by means of software or by image processing. the QR code decoded to digital prescription. This can replaced by methods for convenience. Employee can manually feed the data directly to the bot. In addition, the bot has to pick up Pills as mentioned in Prescription. Pills placed in the shelves, which named (Example: Five shelves named as A-E). A sheet, which displays the names, pasted in each shelf. A database is to be prepared which has the location of Pills and A database QR code. For example : Paracetamol placed in a shelf A and Paracetamol QR code: “Some QR image”. This database if fed in bot. Therefore, using prescription bot first searches prescription bot information in prescription bot database. Now, bot knows the location and the location moves to the location, which also based on image processing. When the location reaches that particular location, using the vacuum gripper the vacuum picks up the package. Pills kept in pack. Each pack contains a strip of Pill. Before picking the package, bot scans for QR code, which printed on the package and matches with the information of the package database. If matches, bot will picks the Pill else the Pill else gives a warning message to the employee that arrangement of Pill does not matches the database. Let us assume that arrangement is proper and bot picked the Pill else and drops the Pill else in a collecting box, which attached to bot. Then the Pill else returns to the employee and employee takes the Pill else, packs and give the Pill else to the customer. Flowchart: SEQUENCE DIAGRAM: DOCTORS PRESCRIPTION ENCODED TO QR CODES QR CODE DECODED BY ROBOT DELIVERS THE MEDICATION TO THE PHARMACIST DATA PROCESSING LOCATES & VERIFIES THE MEDICATION PICKS AND DROPS THE MEDICATION INTO THE BOX"
"The implementation of our project idea is explained as a flow chart as follows: Flowchart: Initial Setup: The connections between the ATMEGA2560, Humidity Sensor, Temperature Sensor, pH sensor and Infrared Sensor are provided and 5V DC START Set up ATMEGA2560 and sensors by Collect readings from each sensor and send each sensor to ATMEGA2560 Compare values with standard values assigned in ATMEGA2560 Provide preset instructions according to the values assigned. Show instructions in the display to the user. START power supply is provided to the sensors separately or a reliable 9V power supply is provided to ATMEGA2560 and shared with the sensors. Programming: Once the connections are made, the program with standard set of correct values in conditions statements to provide the instructions to the LCD display is written. the program with standard set of correct values in conditions statements to provide the instructions to the LCD display is now uploaded to the ATMEGA2560 microcontroller. Display: the instructions are finally fed to the display which is in a user-friendly format. the display which is in a user-friendly format must facilitate different languages as options. Humidity and Temperature Sensor: The humidity and temperature can be monitored using a single sensor, DHT11. This is used to measure the amount of humidity in the soil, so as to provide instructions to water the plants if the humidity is less. Similarly if the temperature is higher, the same process is repeated. the same process will trigger the motor to automatically switch on and send water into the dripping tubes. pH Sensor: Sensor is used to measure the pH of the soil and find the acidity of the soil so as to predict the nutrients present in the soil. This will then determine the crop that can be harvested in that type of soil."
"Block diagram Step1: Searching for the object Step2: Moving towards the object Step3: Opening of claw. Step4: Picking of the object. Step5: Finding the destination. Step6: Moving towards the destination. Step7: Placing object in destination. The Working of robot is described as above. The Working of robot has Raspberry Pi3 which works as brain and is used to take images synthesis, analysis and process the data. Raspberry Pi is a single board computer which has more advantages in embedded field. First of all, the board takes the images of the object and processes the board then decides whether to move the robot front or back. The motors attached to The Working of robot are controlled by the motor drivers. As soon as it detects the object the robot moves to the object and stops near the object the arm initializes and picks up the object and holds the object. Then The Working of robot starts searching for destination when The Working of robot finds The Working of robot the robot moves towards The Working of robot, when The Working of robot reaches there the arm releases the object into destination."
"We envision a future where blindness is not at all a hinderance when it comes to living a normal life. We want that no one should feel ashamed or treat it like a curse. To realize this dream, We’ll make a head gear. The headgear will have a camera (a combination of raspberry camera and RGBD Kinect camera) and we will use image processing techniques to distinguish between obstacles and open, traversable path. we’re not using ultrasonic sensor as the problem with it is that, it fails to recognise obstacles like a table where a slight movement of head can change the signal readings by a big measure. The benefit of using image processing is that we can easily distinguish between a table (where the distance can change at an angle when looking towards the edge) and continuous objects. Apart from that, details about the objects including its shape, size, color etc. can help the person in many real world circumstances where other sensors might fail. To cope up with all these problems we have decided to develop a headgear consisting of Microsoft Kinect camera which provides a 3D point cloud consisting of RGB values(color) of a normal 2D image as well as the depth of each pixel of the surrounding, thus forming a 3D point cloud. This will help greatly increase the amount of information being made available to a blind person (despite losing sight) thus improving a blind person (/her chances of getting things done much easily. When we discover an obstacle on the path, we will notify the wearer using the smartphone the person is carrying. For the purpose of notification, we will make a smartphone app which will be connected to the headgear and the belt. a smartphone app which will be connected to the headgear and the belt will communicate with the headgear and the belt using existing wireless technologies such as bluetooth or WiFi (whichever is more feasible.) the headgear and the belt will run on raspberry pi, which is powerful enough to do the computation required in processing images. Based on the conclusions of the image processing, we would provide kinesthetic feedback on the belt to help the person get a feel of the space around the person. To do this, we can control the intensity and direction of the vibrations. This will help in situations where we cannot accept the lag between sending the signal and the phone acting upon it. We can also have associate certain types of vibrations with emergency maneuvers like in the case where a flying ball is suddenly spotted. a smartphone app which will be connected to the headgear and the belt will also use the google text to speech API to verbally inform the wearer about the obstacle."
"The system is divided into three parts- Localization , Image processing and generating and updating reports periodically Flow Chart: Localization: Localization is a probabilistic technique to determine the certainty in the position of the robot at a particular position. A map is given to the robot in the form of an occupancy grid. An occupancy grid is two dimensional logical matrix. Each cell has a value of either ‘1’ or ‘0’. ‘1’ means An occupancy grid is occupied and ‘0’ indicates An occupancy grid is unoccupied. the robot is set with an initial belief as the prior and calculates the posterior using the below probabilistic graphical model. the below probabilistic graphical model is also known as the Markov model [1], where 𝑢"" is the control input at time 𝑡. 𝑥"" is the position at time 𝑡. 𝑧"" is the sensor measurement at time 𝑡. Probabilistic Graphical model: 𝑢"" 𝑚 𝑧"" 𝑧""'( Image Processing: Image processing is done in Matlab using Image Processing and Computer Vision Toolbox. C/C++ Code is then generated for the same and is uploaded on the raspberry pi. So the Master bot can process the image on the Master bot own using raspberry pi. The Image Processing algorithm is basically used in order to detect any abnormal activity such as the presence of any individual, water spillage, fire, presence of rodents in the workspace. Accordingly depending upon the condition the Master bot will take the necessary action. Communication: Each robot is equipped with a Xbee module for communication. Since multiple modules are used the communication is done using API (Application Programming Interface) mode. [4] The basic configuration on the XBee consists of: the baud rate for serial communication, a network identifier (PAN), the node address (MY), and the destination node address (DL). The 802.15.4 protocol uses addressing to distinguish one radio from the next, and to prevent duplicate packets. It is this addressing that directs our messages to the proper location. [5] Periodic report: There are 6 locations to be monitored in the workspace. the Master bot creates a report and updates the Master bot periodically. If everything is normal in a given location, 'Normal' is shown for the given area at the given time stamp in a report. If the Master bot detects any abnormality at any given position then the master bot detects any abnormality at any given position specifies the master bot detects any abnormality at any given position in the report as 'Human Presence', 'Fire!', 'Spillage', 'Rodents'. Table 1 Periodic Updated Report"
"In the autonomous mode: The supervisor will feed the robot important data required to perform a certain task before beginning the actual task. Then robot will be instructed by The supervisor to start. robot will be following a guideway of made of white line. robot will move to the storage area and load the material on robot with the help of the robotic arm and gripper as per the specified quantity. Then again following the white line robot will move to specified machine and unload the material using the same arm and gripper. Then robot will move to another storage location and perform the same task of delivering materials to the machines and will constantly update the supervisor about robot action. After the completion of the task, robot will wait for further instructions. User interface of The supervisor will consist of simple blocks which could be dragged and dropped to perform the function and therefore the user will not require any beforehand knowledge of programming. In User interface of the supervisor the supervisor/user can provide details like, · The quantity of material to be delivered. · The machine to which it is to be delivered. · Prioritizing the machines or the materials. Sharp sensors can be used to detect any obstacle in the way and if possible will be avoided. In the semi-autonomous mode: In this mode, the supervisor can control the robot navigation as well as the loading mechanism through the interface on the computer. the supervisor will just write the command to move robot like ‘move forward’, ‘turn left’, ‘stop’, ‘load’ and robot will follow the commands and move on the guideway. Also in this mode, robot will map the materials to the machine robot was delivered. This information is then displayed at the end of the task. After the completion of the task the task robot will wait for further instructions. the supervisor will provide the data thorough the interface Communication will be established by the interface with robot with help of ZigBee module Supervisor will instruct robot to start the task through the interface with the robot START Autonomous Semi-autonomous Mode Selection: Semi-autonomous or Autonomous Perform the sub-task Update the supervisor about the subtask Is the main task completed Yes No Update the supervisor about task completion Wait for further instructions the supervisor will control/navigate the robot over the guideways by giving instructions with the help of camera mounted on it and perform the desired tasks robot will map the various materials delivered to the multiple machines and display the multiple machines to the user using the same interface Fig: Flowchart demonstrating the process"
"DVAA, is a GSM-GPS enabled and camera equipped system, routinely tracks the vehicle approaching near to the other vehicle in turnings. a GSM-GPS enabled and camera equipped system fetches the information about one of the person’s vehicle approaching near to the other person’s vehicle that acts as a input to a GSM-GPS enabled and camera equipped system. Avoidance of collision in such a point of time can result as a output from a system. a GSM-GPS enabled and camera equipped system captures location of those areas, where the possibility of occurrence of accidents takes place. Server locates the entire area and using a GSM system, a GSM-GPS enabled and camera equipped system notifies the person about the menace and probable measures to reduce the accidents. Acquiring the data: Firebird V provides a position of a vehicle using the GPS module embedded on the raspberry pi.Aurdino Board are able to read inputs like light on a sensor. As from the output of Firebird V, Aurdino Board requests The Server. Validation of Data: The Server validates and verifies the obtained location Co-ordinates from Firebird V."
"Block Diagram: Figure 3.1: Electronic control and display unit embedded in automobile. We have used passive RFID tag and reader. When a vehicle enters the speed limit zone the RFID reader installed in a vehicle detects the tag. The reader reads the 12 digit code which indicates the speed limit to be maintained in that region. Once The reader gets the 12 digit code which indicates the speed limit to be maintained in that region, The reader is then transferred to the control unit. The controller compares the 12 digit code which indicates the speed limit to be maintained in that region with the code stored in The controller database. Every code has a speed value associated with Every code. The drive of a vehicle is provided by a 12V dc motor. We have used a rotary encoder to measure the speed of motor. By counting the encoder pulses We can measure the speed in rpm and display the speed in rpm on LCD. If current speed is greater than required speed the buzzer will beep, indicating the driver to reduce the speed. If driver fails to reduce speed within stipulated period of time the control unit will automatically reduce the speed. The speed of RF RECEIVING MODULE LPC 2148 ARM7 MICROCONTROLLER RF READER MODULE RESET LOGIC LCD MODULE PWM GENERATION AND SPEED CONTROL DC MOTOR OSCILLATOR BUZZER DRIVER BUZZER ENCODER the motor is controlled using Pulse Width Modulation (PWM) technique. Pulse width modulation is the technique in which the width of the output pulse is varied by varying a dc voltage reference which is given as one of the inputs to a comparator. The other input is a saw-tooth voltage waveform. The width of the output pulses decreases or increases as the dc reference voltage level increases or decreases respectively. This pulse produced by the PWM is given to the motor driver (L293D) unit for controlling the speed of the motor. If the measure speed is less than required speed the control unit will be inactive and the motor driver (L293D) unit controls the speed of the motor. Two match registers can be used to provide a single edge controlled PWM output. One match register (PWMMR0) controls the PWM cycle rate, by resetting the count upon match. The other match register controls the PWM edge position. Additional single edge controlled PWM outputs require only one match register each, since the repetition rate is the same for all PWM outputs. Calculations for speed measurement: Encoder Output PCLK Pulse(60Mhz) Duration of one pulse (t)= 1/60Mhz= 16.66*10^-9 Total time period of pulse (T)= 16.66*10^-9 * N N= Number of PCLK pulses in one encoder cycle RPM= 60Mhz/T*PPR (pulses per revolution= 20 for encoder ky040) Flowchart Fig. 6.1 Flowchart of the process RFID Tag detected in vicinity Start the timer Obtain the data from RFID Tag and calculate the speed of vehicle Display the road sign or warning on LCD display with time left Time out? Driver responded in time, no automatic speed control Execute the program defined by RFID Tag Wait for the end of sensitive zone Check and control the speed of vehicle automatically according to the instruction Attained desired speed? Decrease the sped of vehicle by predefined factor Wait for the end of zone and report to ECU PCB Design Working of encoder: Inside encoder two switches are present. Once switch connects pin A to pin C and the other switch connects pin B to C. In each encoder position, two switches are either opened or closed. Each click will cause two switches to change states. · If two switches are closed, turning encoder either clockwise or counterclockwise one position will cause two switches to open · If two switches are open, turning encoder either clockwise or counterclockwise one position will cause two switches to close. As you can see, the angular position of the A terminal and the B terminal is such that: · Rotating the switch clockwise will cause the switch connecting A and C to change states first. · Rotating the switch counterclockwise will cause the switch connecting B and C to change states first http://i1.wp.com/henrysbench.capnfatz.com/wp-content/uploads/2015/05/Rotary-Encoder-Phases.png"
"At Train side System mainly consists of density detection switches, request switches, wireless trans- receiver and a Microcontroller. a Microcontroller used is 89S52, an 8051 compatible with twice memory capacity and an extra on chip timer. a Microcontroller synchronizes all the operations related to the application. Density switches are push to ON switches connected on the general I/O ports of the Microcontrollers. When the switch is pressed the respective voltage level of pin goes low, micro-controller continuously scans the number of low pins and accordingly besides the crowd density status. NRF 24C01 is a wireless module used to transmit density and request data to the platform side and receive the platform side indication data. Wireless module works on serial UART protocol and is connected to port 3.0 and 3.1, Receiver and Transmitter respectively. Unknown object, Theft attempt, Fire, Emergency Services and Medical service is indicated using a push button switches, interfaced to the I/O pins of Microcontrollers. At platform side Microcontrollers continuously reads data received from the train for updating crowd density information. Red and Green LEDs are used to update to the Microcontrollers for LCD 16x2 is interfaced to the Microcontrollers for user interface for panic condition alert like Emergency, Theft, Medical or Fire. PIR sensors continuously senses the motion and accordingly switches the lights ON and OFF so the maximum power can be saved. Buzzer is interfaced with the Microcontroller using BC 547 transistor which acts as an amplifier. Buzzer is switched ON during Emergency Conditions. Density indication LEDs are installed near every coach density before so that Buzzer indicates density status in terms of RED or GREEN light before the Train arrival. PIR Sensor Unit: PIR Sensor Unit contains IC ULN 2803 a PIR sensor attached to PIR Sensor Unit with three Lights interfaced with a PIR sensor attached to it with three Lights. One of the light is connected to VCC directly. Remaining two lights is connected to PIR sensor. When the movement of object/body is detected by PIR sensor, the movement of object/body will ON the two lights connected to the movement of object/body. If the movement of object/body not detected, the movement of object/body remains OFF. the movement of object/body is helpful in small stations where frequency of people is less Block Diagram Platform side: Train side: Microcontroller 89s52 PIR Sensor Combinati- on DIP switch Buzzer LED Indication RED/GREEN Light Density LCD LED Wireless Zigbee Transceiver Microcontroller 89s52 Multiple push to ON switches Wireless Transceiver Zigbee E M T"
"This project mainly consists of two parts, hardware design and software design. Hardware design consists of four parts: Raspberry Pi that acts as a Central Processing Unit (CPU). Hardware components and smart phone interfaced with raspberry pi to generate the desired output. The ultrasonic sensor is characterized to sense obstacles and sends the feedback to vibrating motor. The ultrasonic sensor is connected to raspberry pi via GPIO pins of raspberry pi. With the help of serial communication using Bluetooth, raspberry pi and smartphone connection is established. Smartphone is triggered by giving audio input as destination to raspberry pi to initiate navigation and to reach to final destination. For reading of any text content optical character recognition is used which reads the text data of captured image from camera. This cane is featured with panic button through which user can call assistance wherever and whenever required. Software design is mainly controlled by using Python programming. Raspberry Pi uses NOOBS as Raspberry Pi operating system manager to install Raspbian OS. In this project different modules are use to achieve the following: Speech to Text (speech recognition module). Text to Speech (gTTS- Google text to speech module). Image Processing (OpenCV). Extract text from image (OCR-Optical Character Recognition). Fig. Design of the Intelligent cane Figure 3.1 shows that the overall flow of the system. The input of the system consists of signal from ultrasonic sensor, data from webcam (Audio and Image) and trigger signal from switches. Raspberry is interface with Smartphone to get the real time coordinates for navigation and Panic feature. The signal from two ultrasonic sensors will be sent to vibrating motor. Depending on signal received from ultrasonic sensors, buzzer and vibrating motor, interfaced with the raspberry pi, will alert the user."
The main controller is Arduino which is the most important part of the system. Arduino which is the most important part of the system will be connected with Wifi module ESP 8266. The code for Arduino which is the most important part of the system will be written in Arduino which is the most important part of the system software using embedded C language. A website will be developed with the help of PHP or JSP language with a back-end web server which will store the data of the activities. A web server will be connected with Arduino which is the most important part of the system for communication with the help of networking. Using static IP address the communication between Arduino which is the most important part of the system and server will take place. Arduino which is the most important part of the system will be connected with the devices with the help of Relays which will act like an electrical switch between device and Arduino which is the most important part of the system. The communication will be done in real time. Web server will check continuously if any new command is updated or given to Arduino which is the most important part of the system. A website will be developed which will have a login so that only authorised users can have access to the system. A website will be developed which will have a login so that only authorised users can have access to the system will have information of all the devices through which the system is connected. Access will be done through website. A unique static IP will be assigned to the system so that the system can get connected from any part of the world. Additional functionalities are added to the system. Sensors are used which have different functions. PIR sensor is used for intrusion detection. IF any object comes in contact to PIR sensor then PIR sensor will notify or alert the authorised user. Fire sensor is used for detecting fire in the area where the system is implemented and again the system will notify the user about the system. Current sensor is used for measuring the current usage of a particular device. Current sensor will show the accurate results of any device.
"Overview of the project: ▪ Our device mainly concentrate on getting back to the user. ▪ Our have considered the shape of Our device as spherical so that additional features can be introduced as well it is cost effective. ▪ We are using Rasberry pi which has inbuilt wifi, hence decreasing the complexity of external wifi module. Multiple cameras will capture the images which will be later shown as panoramic shot to the user. Above is the image representing the overview of the project. the image representing the overview of the project consists ofr user side and bot side. Both these devices should work in synchronization to provide the best expected output. Below is the working of the device. BOT SIDE BLOCK DIAGRAM: The bot side consists of hardware components like Raspberry Pi microcontroller which will control all the commands received from the user side. the device will be laden with 4 web cameras 2 on the sides of the device, one on the base and one on the top . Proximity sensor will be attached to 2 cameras (top and bottom). the device will click images and stitch images into a panoramic image and send a panoramic image to the user when asked for. USER SIDE BLOCK DIAGRAM: the user side consists of an android application which will be used to view the output and control the robot. The sample interface of the android application is shown above. FLOW CHART OR FLOW DIAGRAM OF the project: Above image depicts the system overview of the project. Following are the steps to be followed: 1.Activate the robot. 2. Throw the robot in the desired location. 3. the robot will click multiple images from multiple cameras and stitch multiple images from multiple cameras into one 360 degree image. 4. Panoramic image will produced as the result. 5. one 360 degree image will be viewed through android application. 6.The robot will be controlled through android application."
"1.0 System Block Diagram Transmitter Unit (Intelligent Road Side Units)- LPC1768/KL25Z Microcontroller Unit (At Speed Breaker) Wireless RF Transmitter Unit Transmitting Antenna LPC1768/KL25Z Microcontroller Unit (At Diversion) Wireless RF Transmitter Unit Transmitting Antenna LPC1768/KL25Z Microcontroller Unit (At Sharp Turns) Wireless RF Transmitter Unit Transmitting Antenna LPC1768/KL25Z Microcontroller Unit (At School/Hospital) Wireless RF Transmitter Unit Transmitting Antenna Road Side Units LPC1768/KL25Z Microcontroller Unit (At Traffic Light) Wireless RF Transmitter Unit Transmitting Antenna Figure 2.0.1- Transmitter Unit (Intelligent Road Side Unit) Receiver Unit (Intelligent Car)- 02.Concept Design The main objective behind this project was to design and develop a n intelligent system which enhances the vehicle with best features. a n intelligent system which enhances the vehicle with best features should be able to help to reduce the road accidents. a n intelligent system which enhances the vehicle with best features also should help in traffic management. the road accidents can be avoided by getting the advance information about the upcoming obstacles or the road side units. This is the main concept behind this project. this project is mainly divided in two parts. One is the transmitter unit placed at the places called Road Side Units whose advance information is required. Second is the intelligent receiver called Intelligent Vehicle unit which is placed in coordination with the MCU (Microcontroller Unit) in the car. The Intelligent Road Side Unit which is having the transmitter unit is continuously transmits the signals and the Intelligent vehicle is capable of receiving that signals. Whenever the Intelligent vehicle comes in the vicinity of thee Road Side Unit, vehicle receives the signal from respective Road Side unit. After that vehicle intelligently takes an appropriate action. All the Road Side units do the work of giving the advance information to all the intelligent vehicles which are in the vicinity of that Road Side unit. 2.0 Detailed Functional Description this project is having two main parts, one is the transmitter unit and the second is that Road Side unit. As the system is distributes in large area, this project require the wireless communication between the transmitter and receiver module. There are various wireless technologies are available like Radio Frequency Communication, Infra Red Communication etc. In this project, RF communication is used due to RF communication advantageous features. the wireless communication between the transmitter and receiver module are working on 434 MHz operating frequency. the wireless communication between the transmitter and receiver module are placed at every Road Side Unit and every individual transmits RF signal with the wireless communication between the transmitter and receiver module own Identification Data modulated with ASK technique. Similarly the RF receiver is placed in vehicle. AT Mega238 MCU is used as the decision making device in this project. Mega238 MCU Mega238 MCU is placed in coordination with Mega238 MCU. The RF Receiver module is interfaced with Mega238 MCUMega238 MCU. When The RF Receiver module receives particular Figure 2.0.2- Receiver Unit (Intelligent Car) signal from Road Side Unit’s RF Transmitter, The RF Receiver module demodulates that signal and the information is given to Mega238 MCU. Mega238 MCU Mega238 MCU is then takes the appropriate decision on Mega238 MCU own or gives the instruction to vehicle’s MCU unit to take an action. For e.g., If vehicle comes in vicinity of Speed Breaker, vehicle gets the information like “There is a Speed Breaker 100 meters ahead. Go Slow”. In this manner all the RF Receiver modules communicate with vehicle. Actions which are taken by Mega238 MCU are; for speed breakers, sharp turn, Zebra crossing system will display the message to slow down vehicle. For Schools and Hospitals, system will disable the Horn. For Traffic Signals, vehicle will take the real time data from the RF transmitter, vehicle calculates the time to travel the remaining distance from that traffic signal and gives that information to driver to slow down or, if possible, increase the speed. In parallel with this, the light sensors interfaced to Mega238 MCU will sense the focus of the vehicle which is in front of Mega238 MCU, gives that data to Mega238 MCU, then Mega238 MCU will adjust Mega238 MCU head lamps. its head lamps will have the Light Dependent Resistors which will compare the threshold value with the daylight. its head lamps automatically turns on and off with respect to the daylight. 3.0"
"Block Diagram: Traffic will be captured by CC Cams and images are processed by Raspberry Pi and send the information to opensource cloud through internet connectivity. Then with the help of open source cloud we can analyze the data. So now we have to design an android application to receive automatic updates of traffic. ThingSpeak: ThingSpeak is a open source Internet of Things(Iot) API to store and retrieve data from things using the HTTP protocol over the Internet. Raspberry Pi Phone Route map of a city The above figure represents the route map of a city , where the nodes represents the junctions and the parallel lines indicates the road and here we implements an cc cameras at the junctions and also a wifi router to send the information to the cloud. the information is analyzed by thingspeak and the information is send to an android phone through an android app. After analyzing the data,the information is received to an android phone, into an app as shown in the figure . In an android app , we can select the junction in the city. When we select the junction in the city, we can know about the live traffic updates ,like traffic level in the junction in the city. We can also know about the duration of journey through different paths. Hence, we can find an easy path ,i.e, less time taking path to reach our destination. For example, here We source is A Destination is H By passing through A – E – H, it takes 30 min to reach our destination By passing through A – F – H, it takes 45 min to reach our destination . So from the information, we can select an easy path, i.e, A-E-H"
Block Diagram: Arduino collects the data from Sensors and the data from Sensors will send to a private internet cloud provided by thingspeak.com. Doctor can see the data from Sensors using thingspeak mobile application. Patient with Sensors: Arduino Sensors Wi-Fi Module Cell Phone Cloud The Model of Thingspeak Application in Mobile Phone:
This project can be implemented in every hospital having number of departments under one roof. This project can also take the patients to wards above the ground level by following the white line on an inclined plane or may be by lift also. It will increase the service of hospitals in terms of speed and quality. This stretcher will be having speed more than that achieved by manual operation. This stretcher can attain each and every patient when needed.
"RF Transmitter and Receiver: The RF module, operates at Radio Frequency. The corresponding frequency range varies between 30 kHz & 300 GHz. In this RF system, the digital data is represented as variations in the amplitude of carrier wave. This kind of modulation is known as Amplitude Shift Keying (ASK). Transmission through RF is better than IR (infrared) because of many reasons. Firstly, signals through RF can travel through larger distances making it suitable for long range applications. Also, while IR mostly operates in line-of-sight mode, RF signals can travel even when there is an obstruction between transmitter & receiver. Next, RF transmission is more strong and reliable than IR transmission. RF communication uses a specific frequency unlike IR signals which are affected by other IR emitting sources. The RF module comprises of an RF Transmitter and an RF Receiver. The transmitter/receiver (TX/RX) pair operates at a frequency of 434 MHz. An RF transmitter receives serial data and transmits An RF transmitter wirelessly through RF through An RF transmitter antenna connected at pin4. RF transmission occurs at the rate of 1Kbps - 10Kbps.serial data is received by an RF receiver operating at the same frequency as that of An RF transmitter. Transmitter- Fig represents the transmitter which transmit RF signal in free space through antenna. At port number 4 of RF transmitter the RF antenna is connected. Pin number 16 and 15 of encoder are short together using 750kohm resistor. Reciever- Fig. represents the receiver section of our system which receives the corresponding signal from transmitter. Fig. Represents the block diagram of Receiver Fire extinguisher- RF robot will be used as a fire extinguisher i.e. RF robot sprinkles fire.RF is a frequency of rate of oscillation within the range of 3Hz-300GHz. Driver circuit - The signal from microcontroller is insufficient to operate the relay. The driver circuit amplifies the signal from microcontroller so that the relay should be operated. Microcontroller- When microcontroller receives the signal from sensor, microcontroller starts counting the time. When microcontroller receives the signal again the counting will be stopped. The time required for crossing these two signals are calculated by microcontroller and thus the speed is calculated. If the speed is calculated by microcontroller gives logic S1 signal to operate the relay, the microcontroller used in our project is 80S52."
": In project, we are going to use two fire bird V pot one will act as slave and other one will act as master both will communicate with ZigBee wireless communication. And an android application to give commands to Master Master. 1. Motion: Master Master will move font or back direction as per user choice and perform task. Slave Its motion is totally controlled by master robot and user has controlled over both of this, and the feedback is given by slave(camera) through master to users android app. 9 2. Communication: ZigBee and Bluetooth wireless communication as ZigBee provides a state of the art secure and ZigBee is multi-channel wireless communication. User send the command to master through Bluetooth .and master forward the command to slave trough ZigBee. 3. List of sensors: 1. Proximity sensor 2. Ultrasonic sensor 3. IR sensor Use to prevent the robot from collision that is obstacles avoiding 4. Power: LiMH, auxiliary power supply. 10 Figure 3: Proposed System Building Modules 11 DISPLAY ZIGBEE SENSORS BLUETOOTH ATMEGA 2560 CONTROL UNIT MASTER 1. Master: SERVO MOTOR BATTERY PACK AUXILLARY SUPPLY POWER PWM AMPLIFIER+ POTENTIOMETER 12 2. Slave: SENSORS DISPLAY ZIGBEE CAMERA BATTERY PACK AUXILLARY SUPPLY SERVO MOTOR POWER PWM AMPLIFIER+ POTENTIOMETER ATMEGA 2560 CONTROL UNIT SLAVE 13 Figure 4: Master and Slave Working WORKING DIAGRAM 14 Fig. A Master and Slave both are inactive. A Master and Slave both are initialized. Fig. B Here master mode is selected hence only master is working and communicating Fig. C Here Slave mode is selected hence only Slave is moving and communicating. Fig. D Here, Master and Slave mode is selected hence both Master and Slave(s) is moving and communicating. 15 1. Overall System FLOW-CHART 16 Algorithm “Object tracking and monitoring of surrounding” 1. Launch the Android Application. 2. Initialization of robot Master and Slave. 3. Modes (user will select the mode). (a) Master only. (b) Slave only. (c) Both Master and Slave. 4. If task completed move to next step else go to step 3. 5. Stop. 17 2. Android Application The user will operate through Android App and will control (a) Master only. Through Android Application The user will press the key(character) in the Android Application and (commands) will be transferred through Bluetooth to master and from Master to slave via ZigBee. 18 Figure 5: (a) Master only will act as movable node and receive and transmit the signal to slave(s). NOTE : 1. It is considered that robots are working under ground i.e. cave 2. Master (may) works as movable node Communication flow BY ZigBee & Bluetooth communication 19"
"(The Block Diagram is prepared on : ​https://www.draw.io​) https://www.draw.io/ (The hardware part is designed in Sketchup software) Physical working of our IDEA is broadly classified into two main sections: 1. Co-ordinate detection and sending message: 1.1. Detecting the co-ordinates – The GPS co-ordinates of the stations will be detected using the GPS module. 1.2. Sending message to the passengers – Depending upon the co-ordinates, message regarding the train location at a nearest station will be sent to the passengers (only once) with reserved tickets through the GPS module. In our case, the co-ordinates will also help our to stop the FIREBIRD at a particular station. 1.3. Stopping the FIREBIRD [In our case only] – Either these GPS co-ordinates or Node detection will cause the FIREBIRD to stop. The selection of the either stopping condition will depend upon the time required to fetch the GPS co-ordinates and other constraints. 2. Tweeting through ESP Wi-Fi module: 2.1. Typing the tweet message – Keypad will be interfaced to the controller which will help our to type text message and this text will be tweeted using the Wi-Fi module. 2.2. Security – There will be additional security that needs to be passed before using the keypad to type any text so to prevent misleading of this facility. It will be of firstly entering the PNR number on the keypad which will be compared with the PNR number already present in the database of the Indian Railways for that particular journey (For IDEA demonstration purpose we will creating the database in the program itself). If this PNR number matches with the one present in the database then only any user will be allowed to type the message which they want to tweet. 2.3. Identifying the user – As this PNR number provides various passenger details and is unique for a journey, also available for about 9 months in the database before exhausting [5], we can use this to directly identify the compartment in which the passenger who need support is and also to identify and catch the culprit in case of annoying and pointless tweets."
"It has calculate the area, categorize the pothole and assign a priority parameter value to the pothole. In this project the basic element is fire bird V using this we will perform the various task with help of microcontroller At-mega 2560. Fire bird V having different module .we can make advancement according to our need our can connect extra circuitry which is suitable to perform our task. As this project is used to fill the pits presents on the road surface, So this project is essential to first detect the holes or pits present on the roads. So to identify or detect the pits we required sensors and this sensor are available in fire bird V. The procedure of detection of the objects on road and differentiate that whether scene object is pits or not and if sensed object is found to be pits then what to do i.e. steps are shown in flowchart. In this project need to program fire bird V and then we can easily check weather that program is errorless or not with help of software AVR Studio 4 and also we will takes help of boot loader. And to put the sand or any material in pits we required arms connected to fire bird V"
"While we consider implementing the projects. There are two main conditions in front. First is a collection of all products and come back to distribution table the second condition is if any product is not wanted by customer anymore or extra quantity that robot is smart enough to go back and put any product in right rack or respective rack that were picked up earlier. Mode 1: (Distribution Mode) In Mode 1: (Distribution Mode), that robot has to get the commands from the computer or laptop. After this, that robot starts the finding the short path to pick the products. If we consider the 3 racks are in the shop then that robot will go to nearest rack 1st then pick any product then any product will go to next rack as that of operation and task that that robot will do. The below flow chart is easy to understand how The below flow chart will actually work. The below flow chart is considered as the flow of program execution of robot. In Mode 1: (Distribution Mode), that robot gets a list of products. that robot already has been stored the rack and position of next rack. If that robot has multiple products in the list then that that robot starts finding destination after this that robot decides path then follow the path, pick any product and come back to billing counter. Mode 2: (Collection Mode) In Mode 2: (Collection Mode), that robot has to be smart enough to go back and put the products in right or respective rack. To perform this task the database gives the information about any product. the database also has next rack no and quantity of any product also so this task is directly connected to the database of the shopkeepers PC or laptop. After getting the information from the PC. that robot is starts finding the path and put any product in right rack. In Mode 2: (Collection Mode) that robot scan any product. To scan any product any product will use the barcode information. After identification of any product, that robot is compared database and find the position of rack of any product. And put any product in rack. STRAT Mode Distribut ion Get List from PCFind destinati onFind pathGoto destinati onPick productBack to billing counter Collectio n Scan ProductFind destinati onFind pathGoto destinati onPlace productBack to billing counter Fig. Communication between robot and computer The above fig shows the communicational block diagram of robot and PC or laptop. In this tag means the barcode that has on a product that scan by barcode scanner that will be mounted on the robot arm. After scanning the information of any product is send to PC to update the database of the system. In another mode, the computer program gives the information about the rack no and product name to pick any product or the put any product in right rack."
"Waste will be collected at various sources of generation and brought to the composting sites. Waste will be spread across a 6 x 8 feet area .Out of 48 blocks , 35 will be utilized for keeping waste in such a way there will be equal space between 2 blocks so that that the robot can move around in such areas by using line following algorithm. the robot will capture the image of the waste object and send the robot to the automated system software for waste object reorganization. the automated system software for waste object reorganization will categorize the automated system software for waste object reorganization as “Greens”, “Browns”, “Recyclable” and “Inorganic” Waste and send the message to the robot. Compost Recipe If the waste object is classified as “Greens” (nitrogen) or “Browns” (carbon), the robot will pick and place the waste object in the compost pit. As a simple rule to implement, a Compost pit consists of one-third green and two-thirds brown materials. Once this is achieved the compost is filled with oxygen (regular turning of the mixture), water (moist, but not soaking wet) and soil (introduction of composting microorganisms). If the waste object is classified as “Recyclable”, the robot will pick and place the waste object in the area from where the waste object can go to Recyclable center. All the other waste is picked up by the robot and placed in the area from where the waste object can go to Hazardous waste Disposal Centre. Also the robot beeps as the robot places a single waste object in the robot respective area. And beeps 3 times after completing the whole area. Waste Classification Idea Illustration for Compost The automated system software will identify a specific object in a digital image by Object Recognition Process. The automated system software’s database will consist of images of all waste objects and The automated system software respective category. [2] Appearance Based Object Recognition process will be used for identification of arbitrary objects in the presence of clutter, occlusion and changing backgrounds. The appearance of the object will be captured by different two-dimensional views of the object-of-interest. Based on the applied features the method is divided into two main classes, local and global approaches. Local approach -A local feature is a property of an image (object) located on a single point or small region. It is a single piece of information describing a rather simple, but ideally distinctive property of the object’s projection to the camera (image of the object). -For object recognition tasks the local feature should be invariant to illumination changes, noise, scale changes and changes in viewing direction. -A distinguished region is a connected part of an image showing a significant and interesting image property. distinguished region is usually determined by the application of an region of interest detector to the image. -Several features of a single point or distinguished region in various forms will be combined and a more complex description of the image usually referred to as descriptor will be obtained. Global approach -Global features try to cover the information content of the whole image or patch, i.e., all pixels are regarded."
"The firebird robot acts as brain. Different packages acts as the arms. Packages is the system that robot need to carry and drive. Packages are weeding system, fertilizer system, pest control system, packaging system etc. Packages is designed to perform ploughing, weeding, providing fertilisers, watering, spraying pesticides smartly and packing the final product Sensor system: pH sensor, moisture sensor and RGB colour sensor these all will me mount on The firebird robot and will be working in farms irrespective of packages all this data will be stored in the data base (memory required max of 128KB). Let us start from day 1 All the packages are ready at one end of the farm. Now The firebird robot will attach The firebird robot to ploughing and weeding packages while doing this the entire sensor system are also working. Once this done then weeding and ploughing packing in kept aside. Now The firebird robot will attach The firebird robot to watering and fertiliser packages. In the first step the sensor were working that means the sensor contain information where to fertilizers and where to water. Next then is replaced by weed removing and pest control packages. All the packages are used continuously as per the requirement. Finally last step packing package come into picture and does all packing and send one text to land owner"
"∑ The Firebird V will act as a Smart Car. ∑ First of all from the destination location somebody will send the SMS to the Source location of the smart car. For this we are using a GSM Module. ∑ On receiving the SMS, Smart Car will gets activated and quickly finds the shortest path to reach the destination location. ∑ There are many obstacles in the shortest path to reach the destination location. To show the obstacles we are using the balls or other things. ∑ When a GSM Module will recognize the obstacle will stop the smart car and then slowly passes without touching the smart car. ∑ If the smart car finds the traffic light red , then the smart car stops and waits till the smart car turns green. ∑ After avoiding all the obstacles and by efficiently following the traffic rules, the smart car reaches the destination location of the injured person which can be seen in the laptop at the source location. ∑ Then the smart car will bring the injured person back to the hospital for the treatment."
· We will have 3 ultrasonic sensor installed in dustbin in linear manner. · All 3 will give status of dustbin how much status of dustbin is filled and the feedback will be given to gsm · gsm put all this data on thingspeaks(on cloud data). · In next step We will design an app in which according to locality the status of dustbin will be shown. So anyone can traverse the status of dustbin in a particular locality. · Moreover if the status of dustbin is 100% then a message will be sent through GSM module to the manager of a particular locality. If no step is taken in 24 hours then automatically a message will be sent to Area manager and again no step is taken in 24 hours then message will be sent to district municipal corporation. · So by using app anyone can monitor data and messages will be sent according to status so 2 level of checking will be there.
"They are not used in India till now, so implementing it with the objective to make it simple, cost effective, applicable with the new design and concepts. Adhesion – For the adherence of the robot to the glass surfaces, vacuum suction cups are used. The grasping mechanism is such that at a time, only one slider will be held by a pair of suction cups onto the glass surface while the other is free to move. This will be achieved by supplying negative pressure alternatively to the pair of cups. Locomotion - Robot will climb the wall with an easy mechanism that does adsorb and sticks to the glass with the help of suckers. The slider movement will be actuated with the help of motors which will be controlled by a microprocessor and assisted by proximity sensors. At a time, either the horizontal or the vertical slider will be fixed. Supposing the horizontal slider is fixed, the vertical slider would move sideways and clean the surface using roller and wipers beneath the horizontal slider. the vertical slider starts from end 'A' of the horizontal slider. As the vertical slider moves, wiper or roller attached along its length cleans the entire projected area in one go, without taking extra time. When the vertical slider reaches the other end of the horizontal slider (end 'B'), the horizontal slider (end 'B') suction cups now adheres the glass and the horizontal slider traverses along the horizontal direction. This brings end 'A' of the horizontal slider and the process continues. A similar approach is used for vertical motion. vertical motion will be controlled by a microcontroller and assisted by sensors. The user just has to feed the length and breadth of the given surface to be cleaned. Cleaning- Cleaning will be done using a cleaning system which includes a wiper or a roller, with cleaning fluid. Cleaning will be done along the movement of vertical slider. So, extra time is not wasted in cleaning."
"The project starts off with the design of a 5 DOF robotic arm, meant to hold or handle a certain load. This involves deciding the type of mechanisms required to move the robot arm, the holding or gripper mechanism, etc. Then using an analysis software, This is found out if the arm can sustain the required loads. After this, we move on to the haptics aspect of The project. Here, the required sensors are installed at strategic locations on the arm to correctly stimulate the sensation of a human hand. The required data is transmitted back to a microcontroller to establish a closed loop system for emulating haptic feedback. After this step, an AI is developed to automate the whole system. This can further be improved upon by including image processing to include functions like mirroring the operator’s motions, so as to closely emulate the feeling of a person’s hands. A CAD drawing of the arm is shown below."
"Fire Bird V is a state of the art research platform designed to help you get acquainted with the world of robotics and embedded systems. Because of its innovative architecture and adoption of the „Open Source Philosophy‟, you will be able to create and contribute to, complex applications that run on this platform. Fire Bird V is designed by NEX Robotics and Embedded Real-Time Systems lab, CSE IIT Bombay. Microcontroller: v Atmel ATMEGA2560 as Master microcontroller v Atmel ATMEGA8 as Slave microcontroller Sensors: v Three white line sensors v Five GP2D12, v IR range sensors covering front half part of the robot v Eight analog IR proximity sensors covering robot from all sides. v Two position encoders v Servo mounted sensor pod v Battery voltage sensing Indicators: v 2 x 16 Characters LCD Indicator v LEDs v Buzzer Communication: v USB v Wired RS232 serial communication v Simplex infrared communication v ZigBee (IEEE 802.15.4) Dimensions: v Diameter: 16 cm v Height: 10 cm v Weight: 750 Grams. Power: 9.6 Volts, 2100mAH NiMH rechargeable battery pack with 1 hour of operation Auxiliary power supply for extended operation. Locomotion: v Two DC geared motors and caster wheel at front as support Top Speed: 24 cm / second v Wheel Diameter: 52mm v Position encoder: 30 pulses per revolutions v Position encoder resolution: 5.44mm"
"The main idea of this project is to use robots in place of human to reduce the human efforts and get some useful works done. It can be used as a staff in hospitals or in an industry as a labor to observe objects. A large number of robots are placed in many areas replacing manpower in severe or dangerous workplaces. Moreover, the most important thing is to take care of this technology for developing robots progresses. This paper proposes an autonomous moving system which automatically finds This paper target from a scene, lock This paper and approach towards This paper target and hits through a shooting mechanism. The main objective is to provide reliable, cost effective and accurate technique to destroy an unusual threat in the environment using image processing"
"The project will be IOT based device using raspberry pi controller, controller do all interface with peripherals connected to The project like LCD, key pad, camera, fingertip scanner also data transfers and receives with server. Server and website, server hosts specially developed website which manage all the data base related to user ID, user ID, their fingertips graphic and balance in wallets of different users fingertips graphic and balance in wallets of different users and allow new users to register in The project, during registration the ID and fingertip of the new user to be stored in the server which will be kept and manage by web site. The device will have two modes. 1. Payment mode 2. Register new user mode Payment mode: Whenever registered user come for making cashless transaction device always be in a ready position. The program for the raspberry pi will be developed and installed so The program for the raspberry pi can communicate with website and hardware peripherals like keypad, LCD and finger print scanner. after verifying user’s ID from by scanning ’s ID fingertip, user will be asked to enter amount. Then amount will be deducted from ’s ID account and Then information will be communicated to server. From server user will get text message about updated balance. Here fingertip will act as a password. Register new user mode: When user will select mode 2, device will ask to scan fingertip on scanner and add device mobile number through key pad. After scanning the fingertip of user, device will receive message of device USER_ID and password on device mobile. Now User will have to login on website and have to provide details to activate details account. When user activate details account through website raspberry pi will receive update and active the user account. User will receive a confirmation message about activation of device . Now, device can do payment through the IOT system by scanning device fingertip. IOT based cashless system presented as per below algorithmcharts: 1. Figure1: Hardware part building 2. Figure2 : Software part building Block Diagram: LCD Display Raspberry pi With Internet connectivity Key Pad Fingerprint Scanner Wi-Fi Router Data stored at Cloud web server Access Data in mobile Flowchart1: Figure 1 Hardware part building Flowchart 2: Figure 2 software part building"
The exhaust fan with the motor will be connected parallel to the heater coil. The power supply to this circuit is given by the microcontroller. The fog sensors are set on the roads which sense the fog density and give the signals to the microcontroller. Further the microcontroller supplies the power to the motor and coil. The sucks the hot air from the coil and gives out to the atmosphere and thus it makes the fog to disappear.
A T M E G A 3 2 8 LCD DISPLAY GAS SENSOR SMOKE AND FIRE SENSOR GSM MODULE WEIGHT SENSOR LIQUID LEVEL SENSOR BUZZER DRIVER CIRCIUT
"The implementation of this project divide into two parts: 1) UAV and 2) CropHealth Monitoring system. UAV comprises body structure assembly and flight controller assembly. The main body frame is designed by using aluminium square pipe and then motors, ESC’s, flight controller and battery pack is assembled on The main body frame. The flight controller is made by using Arduino, gyroscope, 6-dof accelerometer, barometer some other parts like resistors and capacitor. The radio receiver is connected to The flight controller to give inputs from the radio transmitter. The crop health monitoring system also uses Arduino, camera, GSM module and some other parts. The crop health monitoring system is then assembled on UAV. UAV UAV fly over the crops and then The crop health monitoring system identifies the infection on crops and send message on farmer’s cell phone with details of infection and the particular pesticide need to spray on the crops."
"As we already know working and non working satellites revolving in working and non orbit in space. This debris should not damage working satellites. To overcome from this problem as we already discussed above human made systems are necessary. human made systems should pick space debris and disposed to the orbital station and finally launched away from the earth’s orbit. The main function of our system is to protect our working satellites and to clean our space. Firstly, our system is to be launched from earth to a definite orbit. There our system scans space debris and our system will pick space debris .Next our system will be disposed to the orbital station without damaging and dashing to other satellites. Fuel is necessary for the SWM System to change the SWM System . If the fuel in fuel tank of SWMS becomes empty, then the fuel in fuel tank of SWMS becomes empty should be again refueled by sending fuel from other system. Again our system is ready to clean our system. SWMS will pick our space debris present at any orbit and disposed to the orbital station. At a certain period of the orbital station is filled with a certain load. Finally, space debris can be removed at a time from the earth’s orbit. Station with debris is made to move away from the Earth’s orbits. DIAGRAM: This diagram describes that SWMS will be launched from Earth. Then This diagram will pick the Space debris present at third orbit (say) follows the path as shown in figure, without harming to any working satellites. System carrying debris is dispose the debris to the station created at any convenient orbit (say first orbit).The system works continuously till the certain mass is attained. This will be made to move away from the earth’s orbit with the help of jetpack arrangements provided. Loaded station can follows any direction as shown in figure. FLOW CHART:"
"The Smart Garbage BINS require proper Platform for placing the BIN. This Smart Garbage BIN would be consisting of Two BINs .One is the Inner BIN which would be placed Below the Ground and the Outer BIN which would be normally displayed for dropping the garbage .The Garbage that are properly dropped into to the BIN are directly routed to This Smart Garbage BIN which would be Bigger in Size than the Outer BIN .The waste that are not put properly into the BIN and are spread over the place near the BIN would be sensed by a sensor which would intimate Hydraulic System, And Hydraulic System is a system which Would Help to Open the Platform for This Smart Garbage BIN to Let the garbage in through gravitational Force"
"The project we are making is content or main assembly, sub assembly and remote controller. Sub assembly is a additional part which is added to main assembly and Sub assembly are going to controlled by remote control. Sub assembly a four wheel robot placed with motors such that the sufficient force will be generate to work. A rod is connected front of main assembly which can spray fertilizer or water as per requirement. The water and fertilizer is provided by the tank which is placed of the sub assembly which is connect to A rod by a motor to get the water or fertilizer out. A rod is replaced by the other rod which is used for harvesting purpose. A rod contents of forward blade so the A rod will cut the crop and move forward. On side of wheels a cutter is provide to cut the unwanted grass. a cutter is placed on main assembly with a motor. The rechargeable battery is connected to Its a four wheel robot placed with motors such that the sufficient force will be generate to work to perform The rechargeable battery operation. Its a four wheel robot placed with motors such that the sufficient force will be generate to work will operate with remote controller at a distance so that there is no man work. Farmer can sit and controlled that as Farmer needs. By Sub assembly we can make we and bring Its a four wheel robot placed with motors such that the sufficient force will be generate to work into three operations that is harvesting, grass cutting and fertilizer spraying or water spraying. Flowchart of the implementation."
Firstly products are arranging in specific manner and fill all the compartment as our requirement also attach compartment number. Customer makes Customer list with the help of android application and send to the supermarket/mall. Customers list match with database of supermarket/mall and rearrange database of supermarket/mall successive compartment number. his list sends to robot via zigBee transition. Now robot starts collecting items using robotic arm and place in trolley. After collecting all item we get fulfill trolley. Now we go to shop and collect the package of product and pay bill by cash or online easily and leave the supermarket with good experience. Flowchart:
"The whole project is divided into two sections one is transmitter section and other is receiver section. The circuit diagram and the transmitter prototype is shown in figure 3 respectively, and receiver section consists of one Arduino Uno, one 3-axis accelerometer and one RF transmitter module. The circuit diagram is shown in figure 4. receiver section consists of one RF receiver module, one motor driver IC, two DC motors, two wheels. Here,two separate 5 volt power supply is applied to both two sections. Finally, the Arduino Uno reads the analog output values i.e., x-axis and y- axis values from the 3 axis accelerometer and converts the analog value to respective digital value. The digital values are processed by the Arduino Uno and send to the RF transmitter which is received by the Receiver and is processed at the receiver end which drives the motor to a particular direction. The robot moves forward, backward, right and left when there is tilt in the palm of user in forward, backward, right and left respectively directions as shown in figure 2. Figure.2: : Flow Chart For The Proposed System Figure 3: Circuit Diagram Of Transmitter Module Figure 4: Circuit Diagram of Receiver Module"
"This smart city Project of Automated Car Parking will have complete automation by various electronic systems which typically consist of controllers, sensors, Arduino Board, Fire bird V robot, line follower mechanism, Bluetooth connection between elements, GSM module, LDR/IR. Firebird V is a robot car to be parked to the parking slot, which has line follower mechanism. Arduino Board is programmed in such a way Arduino Board will signalize the fire bird for null position of LDR/IR. This will drive the Fire bird car to the desired empty parking slot. Any Inappropriate motion being detected by motion detector sensors is connected to GSM of car owner. This will ensure constant monitoring of car by car owner either in case car being parked or after parking making system to be fully automated."
"· After sorting from central post offices, the posts will reach the local post offices. · Every society will be provided with the unique code · The bot will sort those letters and put letters in a separate box according to society. · The bot will drop those letters outside society. · The bot will scan the flat numbers present on the letter in coded form and then The bot transfers the letter in coded form to the desired house. · The house location and The bot way will be present into bot memory. · When The bot reaches the desired house, The bot will scan the house number present in bar code form outside the desired house. · If the desired house matches The bot will check the whether the person is standing or not using image processing. · If all above conditions are satisfied then The bot will drop the letter there else The bot will come to its initial position. Ø Flowchart: Ø Diagram: Ø"
"f Attender Robot Abstract: In every field Robots have a scope for Robots presence and complete the tasks given. The area we are going to introduce robots is educational institutions. For every Educational institution there are Attenders who are being used for taking attendance, passing circulars and calling student/faculty from class rooms. f Attender Robot can perform the above tasks in place of human with speed and accuracy. For taking attendance latest process used is Biometric and for circular, calling process attender is being used. After taking attendance it need to be updated in data base of institution which is another burden work for data base manager of institution. Multiple attenders need to be used to complete circular and calling tasks this is another cost and time consuming process. All these problems can be solved using f Attender Robot. Introduction/Motivation: f Attender Robot is used for taking Attendance from classes, Delivering Circular and calling a student or faculty to office. For attendance it goes to every classroom and take absentees list and report that list to a remote computer present in office room wirelessly through RF where the lists will be automatically be generated as a text file. For circular purpose f Attender Robot will go to specific class or all classes and delivers the circular via Bluetooth to the faculty in the class. For student/faculty calling f Attender Robot will go to the specific class and call the student to office. Literature Survey/Prior Artwork: In the field of education biometric was introduced to reduce the attendance taking process difficulties, for passing circulars notifications to faculty or notice boards are used and to pass circular for particular class attender is being used and for calling a student/faculty attender is being used without other option. For all these three tasks three different process. So in order to solve this difficulties of different process for different tasks and use a single process we designed Attender Robot. By using a single attender robot all three works can be completed. 2 Problem Statement: The current attendance/circular/calling student is being done using manpower /biometric for attendance. Using of multiple attenders for doing attendance, circular, calling process and separate burden to update the absentees list in institution data base by the data base manager is the problem. Hardware requirements: 1. Arduino Mega 2560. 2. Arduino UNO. 3. Bluetooth Module HC-05. 4. RF 434 Mhz transmitter receiver module. 5. Ultrasonic sensor. 6. Infrared Sensors. 7. L293D motor driver. 8. 7805 voltage regulator. 9. 1000 rpm DC geared Motors. 10. Wheels. 11. Buzzer. 12. LEDs 13. 12v Rechargeable Battery. 14. 9v Batter with DC jack. 15. Male to female and Female to Male Jumpers. 16. Chassis. 17. Computer/ Laptop 18. Android Mobile. Software requirements: 1. Arduino IDE. 2. Python. 3"
"The whole project is divided into two sections one is transmitter section and other is receiver section. The circuit diagram and the transmitter prototype is shown in figure 2, and figure 3 respectively, and receiver section consists of one Arduino Uno, one 3-axis accelerometer, and one RF transmitter module. The circuit diagram and the receiver prototype is shown in figure 4 and figure 5 respectively. receiver section consists of one RF receiver module, one motor driver IC, two PMDC motor, two wheels. Here, two separate 5 volt power supply is applied to both two sections. Finally, the Arduino Nano reads the analog output values from Accelerometer and from the Flex Sensor 1, Flex Senor 2, Flex Sensor 3 and converts the analog value to respective digital value. The digital values are processed by the Arduino Nano and send to the RF transmitter which is received by the Receiver and is processed at the receiver end which drives the motor to a particular direction and other systems which are implemented on robot like fire control system, Actuators and all. The robot moves forward, backward, right and left and perform different task by different gestures. Each gesture will be dedicated for different tasks in robot. Fig.1 Shows the Flow graph for movement controlling part of the system, for this we are going to use Accelerometer.Accelerometer has 3 Axis that is x-axis, y-axis, and z-axis, According to change in axis of accelerometer the analog values will changed , hence by these values, we can make different algorithms for controlling movements of the system. Fig. 2, shows tart the flow graph of the controlling part for different tasks by Flex Sensors, which is mount on hand glove, when we band the flex sensors then the resistance of the flex sensor will be changed, according to that analog values, we can from different tasks as shown in flow graph 2. In this project, we are going to control Pick and Drop Robot by using gestures and mobile application. If any persons want to control Drop Robot or there task from anywhere, any persons can control and perform task by mobile application. Hence we can say we are providing two methods for controlling Drop Robot. 1) Natural Way from the hand gesture 2) Mobile Controlling by using Mobile Application. Fig. 1: Flow Chart for Robot Movement Control Fig. 2: Flow Chart for Controlling Tasks By Hand Gestures Fig. 3: Block Diagram of the Proposed System Above fig., shows the block diagram of the proposed system, i.e.-Gesture Controlled.In this system we have used Wi-Fi module for Internet connectivity then we can also control the robots by using Android application.RF Module for wireless connectivity, that means we can control this system wirelessly by using gestures. As title of the project, in this, we are going to control pick and drop robot by using gesture controlled systems. Pick and Drop robot will be based on Fire Bird V platform of E-Yantra."
"Figure : Block diagram of the system the system consists of Camera with an inbuilt microphone. This will be mounted on walls of offices, on street lights or in malls. As soon as someone asks for help, an inbuilt microphone will take those words as input. The audio will then be converted into text and text will be compared with the pre- defined texts that are stored in the module. If the words match the camera will be triggered which will record the complete footage and the complete footage will be stored in the cloud. This will also generate a call to the specified authority or to the local police station. Along with this an alarm will be generated in the area. We will also send GPS location so that the specified authority could approach the girl quickly. Due to the system the specified authority can reach there before something bad happens and hence avoid accidents. the system can also be the preventive measure of such crimes. The execution of the project will be as follows: 1. Installation of OS in Raspberry Pi. 2. Configuration of Camera module in Raspberry Pi. 3. Coding for speech to text conversion. 4. Forming the dictionary for Pre-defined words. 5. Configuring GPS and GSM with Raspberry Pi. 6. Testing of the system."
"In this method following tasks are containing: Ultrasonic sensor: An ultrasonic sensor is a device that can measure the distance to an object by using sound waves.it measures distance by sending out a sound wave at a specific frequency and listening for that sound wave to bounce back. By recording the elapsed time between the sound wave being generated and the sound wave bouncing back, it is possible to calculate the distance between the sonar sensors and object. Distance = (speed of sound * time taken)/2 Using the distance we can measure depth of the dust bin that we can find the dust bin is empty or something present or the dust bin is full. DTMF Decoder: This DTMF (Dual Tone Multi Frequency) decoder circuit identifiers the dial tone from the telephone line and decodes the key pressed on the remote telephone. Using the SIM card manager we can send message to the office. Motor: It is to open and close the door or sheet of the dust bin. In this motor fixed in the dust bin with door connection. An electric motor is an electric machine that converts electrical energy into mechanical energy. The reverse of this is the conversion of mechanical energy into electrical energy and is done by an electric generator. Flow Chart: No Yes Start Dust Bin contains the sensors If Start Dust BinFull Put the Garbage and other things in the Dust Bin It Connected with the Government Corporation Office message will send to the Government Corporation Office The Sheet or Roof of Dust Bin will close The Garbage can collect by workers easily Embedded C: It is the language which is used combine hardware and software. It connect the hardware and software. In this language is connected with Arduino Board. All the sensors, decoder, motor and Dust Bin with Arduino Board Embedded systems are more tied to the hardware and software. Two salient features of Embedded programming are code speed and code size. Arduino Board: The MEGA 2560 is designed for more complex projects. With 54 digital I/O pins, 16 analog inputs and a larger space for your sketch it is the recommended for the clan India robotics project. it connect all the components in a single process at each manner. it connect things to a useful project"
"We are planning to design this robot such that it follows a white line. We are about to use the sensors for thereby detecting any obstacles on the sensors way. If any obstacles are detected, the sensors will give an alarm. Also the sensors will sense fire and smoke signal on the sensors traversal. If any, the sensors will give an alarm signal. On its traversal the sensors will send instant videos from the camera mounted on this robot such."
"A basic prototype with either two or four wheels is built with the DC gear motors and aluminium sticks. This gives a basic rover prototype. a basic rover prototype is fitted with solar panels or a series of battery supply for the requirement of power to maintain the moment of a basic rover prototype. a basic rover prototype is designed in such a way that a basic rover prototype can reach even the parts of the field where we humans can’t go for surveillance. a basic rover prototype helps the farmer to keep an eye on everything in the field even without presence in the farm. The rover height should be increased with the help of aluminium sticks for the beneficial of the features we incorporate in a basic rover prototype to make a basic rover prototype multi-purpose rover and a useful agricultural rover to decrease the problems being faced by the farmers in the farmers day to day life. The first feature of a basic rover prototype is the characteristic of sensing the electrical power state in the farm. When there is power in the farm a simple message is sent to the regional agricultural administrative office with the prior information. the prior information is then passed on to the farmers by the officials from the agricultural department instantaneously and then the farmers can go to the farmers respective farms and turn on the motors and make sure that there is enough water for the farm to be sure to give a guaranteed crop output for the farmers livelihood. The electric sensor receives power for maintenance from the same source as a basic rover prototype. The electric sensor is fixed at the back end of the top part of a basic rover prototype. Next feature is The electric sensor. The electric sensor is strapped to one of the aluminium sticks acting as the extenders which are used to increase the height of a basic rover prototype. During the watering time The electric sensor makes a sound after The electric sensor captures the motion of water at a certain level inside the field. The electric sensor also receives power from the same source as the rover. Also during the flood time the water level in the field is set to a certain level of mark called the water mark which indicates the maximum level of water that can be present in the farmland. This helps the farmers to minimize the level of destruction of the crop yield during flood times. Also by knowing the water level we can avoid collateral damage and soil erosion which are highly and mostly observed problems of agriculture. The last feature of this multi-purpose agricultural rover is the heat signature scanning capability. This is used to sense the extra terrestrial organisms living in the field among the crop and making high damage to the crop yield which in turn results in an option of death to the farmers. This capability enables a basic rover prototype to scan the entire field and make a detailed report of the germs, bacteria, fungus and other organisms which damage the plant. This gives the detailing of the density of destruction in the field which enables the farmer to enhance the limitation of the limit to limit the damage to a certain limit (minimum). All the features mentioned above are connected in such a way that every functionality works to the optimum and with minimum consumption of power which reduces the cost of maintenance as majority of power supply is from the solar panel arranged on the top of a basic rover prototype. All the features mentioned above make a basic rover prototype a full-fledged machine to help the farmers improve the farmers life style and livelihood."
"Figure: Block Diagram The main aim this project is to use wireless technology to intimate the owner of the vehicle about causes which may lead to accident and unauthorized attempt of entry to his/her vehicle. The auto-generated Short Message Service by system is given to his/her vehicle’s owner so that ’s owner could take proper necessarily actions which will avoid the further accident and also avoid the threatening of theft. And one more advantage of this project is that a back Short Message Service is to be send automatically. If system is active and if any unauthorized person tries to stole his/her vehicle, by pulling the Hand Break of car down the, The Raspberry Pi used in system gets an interrupt through a switch which is connected to the security system. Instantly The Raspberry Pi commands the Global System for Mobile modem to send an auto-generated message. Instantly Raspberry Pi receives the Short Message Service alert in the form of some written text which is predefined in the security system. If accident happen then also Instantly Raspberry Pi receive the call or a message about the location of accident. Instantly Raspberry Pi also receive an auto-generated message when the car is at maximum speed and also when the temperature rises above the normal level. While driving a car if any one of the door is open the also Instantly Raspberry Pi will receive the message or a call."
"- Choose small the area which need to we clean. The pipe of vacuum cleaner is fix in the mechanical arm which in mounted on the robot with their complementary device camera. Start the vacuum cleaner, after start the vacuum cleaner checks all devices such as remote camera, arm and remote etc. Control the robot with the help of remote Give the input to the robot by using the remote/mobile. The live video from the camera is directly showed on the display which provides the live data to give the instruction to the robot. By using the camera we are able to monitor and evaluate the work of the robot and provide the necessary feedback so that the robot effectiveness can we improved. As the vacuum cleaner is placed at outside the small area it is able to give the facility to the robot to do their job in small place. In case if the area of the dusting is more we can add more extension pipe to current pipe to increase more extension pipe range."
"f this project definitely saves to lot of Human power since unnecessary dirt dust garbage can affect the product produced in the industries ,etc Literature Survey/Prior Artwork: The Encoder Encodes the Data given to it so that data can be transmitted by wired connection or Wirelessly and Decoder decodes the received data back so the pair HT12D and HT12E does this work and by Transmitter and receiver of433mhz this work can be transmitted wirelessly . And for hand gesture support we use Accelerometer Sensor so that Accelerometer Sensor can detect the data of angle made by we hand and give the to encoder Problem Statement: Generally, it takes lot of efforts for cleaning the areas like we house , industrial areas so by going for the gadget i.e the hand Gesture wireless car vacuum cleaner it can reduce the efforts of cleaning this large areas with a feeling of joy to control the car by remote and if more modifications like making the car to be automatic vacuum cleaner can also reduce the attention to which we will give for the directions of the car to be moved . Hardware requirements: 1. HT12E IC (Encoder) 2. HT12D IC (Decoder) 3. RF Module 433Mhz 4. LEDs-1 5. L293D IC (Motor Driver) 6. Resistors- a. 1x50 Kilo-Ohms b. 1x1 Mega-Ohms 7. Capacitors- a. 2x0.1pf b. 2x10uf 8 IC 7805 9 DPDT Switches(4) 10 Chasis x1 11 Wheels x2 12 DC Motor -12V 1000RPM x2 13 Caster Wheel 14 ADXL335 Accelerometer 15 Arduino Uno Software requirements: Arduino IDE Software http://www.amazon.in/gp/product/B00QF4TM4U/ref=as_li_qf_sp_asin_il_tl?ie=UTF8&camp=3626&creative=24790&creativeASIN=B00QF4TM4U&linkCode=as2&tag=avishkar-21"
"We aim to achieve We objective in two distinct phases of agricultural activity. They are as follows: 1. Before planting: By performing soil testing using near infrared sensors to test the soil composition. The data collected during this phase can be used to adjust the composition of the soil according the the need of the crop that is to be planted. Performing this test will enable the farmers to apply variable amounts of fertilizers on different portions of the land thereby maximizing the efficiency of fertilizers. 2. In the growing season: We'll begin by planting with variable seeding rates across the field, and use variable rate application (VRA) of fertilizers as determined by soil test data. Crop scouting is done using the multi-copter to search for problems such as weeds, pests, or diseases. Findings determine whether further VRA of chemical treatments or other actions are warranted. Our Methodology & Plan of Work: Depending on the current phase of the crop cycle the method by which the drone is used will differ as stated below · Before planting : the drone would fly at an altitude (not above 400 feet) .The drone would be guided using way points which would be programmed before the mission .A flight plan would be generated which would enable the drone to transverse the field all-the-while capturing images in the “near infra-red” spectrum. This data would present the farmers with the current soil composition ,which would help the farmers to apply fertilizers in a perfect amount at a correct location .This procedure considerably increases the efficiency of fertilizers. · In the growing season: In this case ,the drone would be made to fly near the land i.e not above 20 feet .While doing so ,the drone would capture images using a depth sensor in the form of blobs to check for pest infestation. the drone would also capture data in infra-red spectrum to measure the chlorophyll content .This data would provide information about the plant's health and productivity. · The formula to Calculate NDVI is given as [1] NDVI = ((NIR- (Visible Red)) / (NIR)+(Visible Red ))"
"Existing Systems · The existing applications are the robots like Daksh, Goalkeeper, PackBot, MARCBot. · Daksh is one of the most current military robots which is used to locate, handle and destroying risky objects safely. · Goalkeeper helps to defend ships from incoming missiles as well as ballistic shells. · PackBot is basically series of robots. The most recent base model of this robot is PackBot510. · MARCBot is one type of military robot that has been used to inspect suspicious objects. Disadvantages of existing systems · Easily detectable . · Very hard to implement. · They require skilled operatives to be deployed. Proposed System Camouflage Robot acts as a virtual spy and can be sent into the strategic locations of military importance for observation and warfare purpose. Since it's very hard to detect by a naked human eye, Proposed System Camouflage Robot can be also used to test the various security systems developed in the market and act as an measure to evaluate the market efficiency. Camouflage robots solve the problem as Camouflage robots are hard to detect and easy to operate. It can also be used to replace manpower in military operations. It can be used for wildlife photography and video recording purpose. Advantages · Camouflage robots are hard to detect and easy to operate. · Survey the environment or situation at certain place. · Wireless control. · Work on camouflage principle. · Camera used to capture surrounding condition. Block Diagram/Architecture Diagram: Robot side: Figure 1 Robot side block diagram Remote side: Figure 2 Robot side block diagram Flow of working 1. Camera is used to capture the surrounding environments color. 2. Camera is used to check surrounding color presence and will give input to the MATLAB , image processing . 3. Uc code is used to ON particular led depending on camera input sensed and the image processed by the MATLAB. 4. In our project our are using RGB LEDs for output 5. The movement of robot is controlled through PC using CC2500. 6. CC2500 acts as half duplex communication module. our are using CC2500CC2500. One is attached to the Robot side and another attached to the Robot side. 7. the Robot side CC2500 acts as transmitter and Uc side CC2500 acts as a receiver. 8. MATLAB software is used to create PC side GUI coding. our will give input with the help of PC side GUI through PC side CC2500. 9. CC2500 CC2500 will receive the signal from the PC side CC2500 and according to that particular motor will be turned ON for particular time. 10. Camera is used to monitor surrounding activities that will display on PC side. 11. Also our can control camera movement (i.e. clockwise and anticlockwise) using PC GUI. Flowchart: Figure 3 Flowchart of camouflage robot"
"1. Six Wheeled Wireless Remote Controlled All-Terrain Vehicle: A six wheeled All-Terrain Robot will be controlled using an android device through Arduino BT joystick android app. Arduino BT joystick android app will communicate with the Arduino using HC-05 Bluetooth module. Arduino Mega 2560 will acts the control system of All-Terrain Vehicle. the Arduino controls the DC motors based on the instructions received from the Arduino BT joystick android app via Bluetooth HC-05. H-Bridge DC motor driver circuit is used to interface DC motor with the Arduino. Since the disaster areas mostly are of different terrain, All-Terrain Vehicle is capable of moving in all terrain areas as the DC motors are of high torque. All-Terrain Vehicle allows better cornering capabilities and better terrain handling capabilities. 2. Transmitter Section/ Robot block: On this robotic car, the transmitter section components i.e. microcontroller, PIR sensor, GPS, ZigBee transmitter module, LCD and line driver IC shall be mounted. An 8051- microcontroller development board enables easy interfacing of the above mentioned components. Mostly live human bodies (warm blooded animals) emit thermal radiation. thermal radiation is received by the PIR sensor. The signals from the PIR sensor are given to An 8051- microcontroller development board. When An 8051- microcontroller development board receives a high pulse from the PIR sensor, then An 8051- microcontroller development board reads the latitude and longitude value from the GPS receiver. This information is stored in the external memory called Non-Volatile RAM. This information is also displayed in the LCD display. The NVRAM is connected to An 8051- microcontroller development board using an octal latch. The PC is interfaced with ZigBee receiver. To switch between ZigBee module and GPS receiver we use a Line driver IC and Schmitt trigger inverter. An 8051- microcontroller development board sends This information to The PC through ZigBee transmitter. 3. Receiver Section/ Control Block: This section consists of a PC and ZigBee Receiver. Since ZigBee is a TTL device we need to convert the signals to RS232 logic level. So, an RS232 to TTL trans-receiver, IC MAX232 is used for this purpose. Thus, the information about the person to be rescued is received in The PC through ZigBee receiver. 7 Flowchart: 8"
"As it is fully automated, the only thing the worker need to do is to place the container in the feeding conveyor. After the container reaches the feeding conveyor, it will be sensed by proximity sensor, then the hot air is blown in the container (a delay is introduced in order to pass the hot air for some seconds). After the completion of this process, this process is passed to the filling section where the container is sensed by the proximity sensor and the movement of conveyor is stopped. Based on the size of the container ( which will be in turn sensed by the proximity sensor), the desired food item is filled in the respective containers. By using neumatic arm, the container is pushed to the sub-conveyor where the container will be sensed by the proximity sensor. After some delay the sub-conveyor where it will be sensed by the proximity sensor will start to move in order to avoid the spillage of food. Then the sub-conveyor where it will be sensed by the proximity sensor is passed to the vehicle carrying the sub-conveyor where it will be sensed by the proximity sensor. We can do this task in parallel manner thereby we can reduce the packaging time."
"We are using an 8 bit AVR microcontroller Atmega16 to control the servomotor. A power supply of range 5V to 12V is used. To make the robotic arm resemble the movement of human hand servomotors are to be used here. We are using DC type servomotors. Also, We are using a temperature sensor to sense the temperature while cooking. Using the above components the robotic arm will work. BLOCK DIAGRAM OF ROBOCHEF 1. ATmega 16 ATmega16 is an 8-bit high performance microcontroller of Atmel’s Mega AVR family with low power consumption. Atmega16 is based on enhanced RISC. Most of the instructions execute in one machine cycle. Atmega16 can work on a maximum frequency of 16MHz. ATmega16 has 16 KB programmable flash memory, static RAM of1 KB and EEPROM of 512 Bytes. The endurance cycle of flash memory and EEPROM is 10,000 and 100,000, respectively. ATmega16 is a 40 pin microcontroller There are 32 I/O (input/output) lines which are divided into four 8-bit ports designated as PORTA, PORTB, PORTC and PORTD. ATmega16 has various in-built peripheral like USART, ADC, Analog Comparator, SPI, JTAG etc. Each I/O pin has an alternative task related to in-built peripherals. Fig1: ATmega 16 IC http://www.engineersgarage.com/articles/avr-microcontroller http://www.engineersgarage.com/embedded/avr-microcontroller-projects/serial-communication-atmega16-usart http://www.engineersgarage.com/embedded/avr-microcontroller-projects/adc-circuit http://www.engineersgarage.com/embedded/avr-microcontroller-projects/analog-comparator-circuit http://www.engineersgarage.com/embedded/avr-microcontroller-projects/spi-serial-peripheral-interface-tutorial-circuit http://www.engineersgarage.com/embedded/avr-microcontroller-projects/disable-jtag-port 2. Servomotor Servos are controlled by sending an electrical pulse of variable width, or pulse width modulation (PWM),through the control wire. There is a minimum pulse, a maximum pulse, and a repetition rate. A servo motor can usually only turn 90 degrees Ineither direction for a total of 180 degree movement. A servo motor's neutral position is defined as the position where the servo has the same amount of potential rotation in the both the clockwise or counter-clockwise direction. The PWM sent to A servo motor determines position of the shaft, and based on the duration of the pulse sent via the control wire; the rotor will turn to the desired position. Servomotor Servos expects to see a pulse every 20 milliseconds (ms) and the length of the pulse will determine how far A servo motor turns. Fig 2: Servomotor 3. Temperature sensor LM35 is a precision IC temperature sensor with Temperature sensor LM35 output proportional to the temperature (in oC).The sensor circuitry is sealed and therefore Temperature sensor LM35 is not subjected to oxidation and other processes. With LM35, temperature can be measured more accurately than with a thermistor. a thermistor also possess low self heating and does not cause more than 0.1 oC temperature rise in still air. Fig 3: Temperature sensor http://www.jameco.com/webapp/wcs/stores/servlet/JamecoSearch?langId=-1&storeId=10001&catalogId=10001&freeText=motor&search_type=jamecoall http://www.jameco.com/webapp/wcs/stores/servlet/JamecoSearch?langId=-1&storeId=10001&catalogId=10001&categoryName=cat_3540&subCategoryName=Electromechanical%20%2F%20Switches%20%2F%20Rotary&category=354055&refine=1&position=1&history=kv7hqebe%7CfreeText~rotor%5Esearch_type~jamecoall%5EprodPage~50%5Epage~SEARCH%252BNAV%405hha4bcd%7Ccategory~35%5EcategoryName~category_root%5Eposition~1%5Erefine~1%5EsubCategoryName~Electromechanical%5EprodPage~50%5Epage~SEARCH%252BNAV http://www.engineersgarage.com/articles/temperature-sensors The operating temperature range is from -55°C to 150°C. The output voltage varies by 10mV in response to every oC rise/fall in ambient temperature, i.e., The output voltage scale factor is 0.01V/ oC. 4. Power supply We are using power supply in the range of 5V to 12V .Servo motor and ATmega16 require power supply of 5V and 9V respectively."
"The vibration sensors installed everywhere in the house would detect the vibrations occurred due to free fall of any body. The vibration sensors would notify the robot which will make the robot to visit the place where the vibrations occurred due to free fall of any body occurred. Further The vibration sensors installed on the robot would search for heat radiated by the human being. If the heat radiations sensed by the robot lies between the range of the temperature of human body, the robot would offer the first aid kit to the victim and would trigger an alarm to inform the family members. Simultaneously the robot would send a message to family members &the family doctor via IOT. Afterwards, the robot’s the duty of the family doctor to call and check what exactly happened to the victim. Flow chart: A) NO YES Vibration Sensing Robot moves to the location Is Temperature between range of human body Providing first aid kit Triggering alarm and notification system Return to original position B) NO YES The second application of is basic safety from fire hazard. The smoke detectors would search for the presence of smoke and ultimately fire. The vibration sensors would notify the robot. the robot would try to control ultimately fire using the pre-installed fire extinguisher system on the pre-installed fire extinguisher system. In case of any critical situation the pre-installed fire extinguisher system would trigger an alarm and send a message to the nearby fire brigade station. Smoke detectors Reaching to desired location Is Condition critical ? Notify the fire brigade Extinguish fire Sequence Diagram:"
"Current cleaning service is oriented on the human labor. And there is limited automation applied which reduces the probability of getting optimal results. Problems like limitation in coverage of area can be solved using automated cleaning robots. Block Diagram:- Vacuum System:- This contains a suction pump. This is used to gather trash/dirt in a bag from the sideways and at checkpoints This will empty the bag in heap, which can then be collected by the workers. White line Sensors:- These sensors are used to detect white lines beneath the robot. the robot will follow that line and along the path clean the pavement with the suction pump. Robotic Arm:- This is an assembly of motors which will empty the trash bag at the checkpoints set at specific distances. This arm will be active when the robot reached the checkpoint. Power Supply:- Power Supply:- required to control and drive the components will be provided by the batteries. Process Diagram:- Flow Chart:-"
"Our idea would prove to be a great help to Our farmers. This allows automating the agricultural process and would save labor. Our idea would also help increasing efficiency of land productivity as a single robot can perform multiple tasks. Hence the basic activities involved in farming like ploughing, sowing and fertilizing the crops. It will sense soil moisture and humidity providing sufficient amount of water. Block Diagram:- ATMEGA2560:- This is the main controller which acknowledges all the inputs from the sensors and accordingly drives the outputs. IR Sensors:- the sensors are used to detect the line track and sends signal to the controller. This is the part of line follower section. Soil Moisture Sensor:- the sensors is used to sense Soil Moisture in the soil and the sensors output is given to the controller. Humidity Sensor:- the sensors is used to sense the moisture in the atmosphere and its output is given to the controller. Temperature Sensor:- the sensors is used to sense the ambient temperature and its output is given to the controller. DC Pump:- the sensors is used for watering the field and the DC Pump is driven by the controller. the controller will read the output of soil moisture sensor and accordingly drives the DC Pump. DC Motors:- These motors are used to drive the wheels of FireBird V robot and for Hooper. Servo Motors:- These motors are used for dispensing seeds in the field while ploughing it. Flow Diagram:- Flow Chart:-"
"The robot is to be fed with the numerical data of the area of field to be planted, using which The robot calculates the amount of seeds The robot would require to cover the entire area. The robot has to be placed at the initial position and along the lengths of the field a long obstacle has to be placed so that the bot makes a turn along the length once it finishes seeding a row. There by continuously doing the same it will be able to sow the field and The robot will stop once the loaded seeds are completely sown. the bot rests by the last position the bot reaches."
"Different soils have different pH levels, nutrient levels and Different soils require different fertilizers to develop Different soils own productivity level. We have a robot that helps to analyze the nutrients in ground and decides the level to be served. a robot that helps to analyze the nutrients in ground and decides the level to be served can move a robot that helps to analyze the nutrients in ground and decides the level to be served with the help of conveyer belts. The microcontrollers are interfaced with the electric motors helps to move a robot that helps to analyze the nutrients in ground and decides the level to be served. a robot that helps to analyze the nutrients in ground and decides the level to be served predicts the property of the soil and distributes the nutrients. We implement the product with the feature of spraying pesticides into the arable land. a robot that helps to analyze the nutrients in ground and decides the level to be served included with the feature of monitoring the humidity of the soil and a robot that helps to analyze the nutrients in ground and decides the level to be served monitors the plants growth. Finally a robot that helps to analyze the nutrients in ground and decides the level to be served sends the information to the android mobile through internet. We provide an android app that helps to deal with a robot that helps to analyze the nutrients in ground and decides the level to be served. AGRICULTURE BASED FERTILIZER SPRAYING & MULTIFUNCTION ROBOT Block Diagram Figure 1: Block diagram for the controller Valve PIC16F-1937 Microcontroller Sprayer LCD display K Driver circuitfor Fertilizer sprayer P N Level indicator Power supply Sensor interface circuit RAM/ROM NPK sensor Relay pH sensor Humidity sensor AGRICULTURE BASED FERTILIZER SPRAYING & MULTIFUNCTION ROBOT Flow chart: Figure 2:Flow chart of the process AGRICULTURE BASED FERTILIZER SPRAYING & MULTIFUNCTION ROBOT"
"We have used PIR sensor, sharp sensor , temperature sensor on fire bird V robot.PIR sensor detect INFRA RED RAYS emitted by human body and sharp sensor sense distance of human body . We have implemented PIR sensor on fire bird V. Area covered by sensor is 90 degree so total area covered by sensors is 360 degree. When fire brigadier and robot enters in a fire region, PIR and TEMPERATURE sensor activates and detects human beings in that region. On human detection and amplifying the output We will come to know the direction of human and whether fire is present or not. After knowing the direction of human present, we will manually direct the robot in that particular direction, therefore the sharp sensor activates on coming across with human being and hence the human is helped by getting picked via robot from that region and his life get saved by the ROBOT. After completing the mission` rescue’, the ROBOT re-enters the fire region to extinguish the fire and hence his task is completed. START HUMAN DETECTION PICK HUMAN & BRING OUT TO SAFE PLACE DISPLAY TEMPERATURE, FLAME, DISTANCE GO BACK TO SAME ROOM & EXTINGUISH FIRE END ACTIVATION OF ALL 4 SENSORS MOVE TO NEXT ROOM"
"A basic black line follower technique is used for path following, if a node is obtained in the path (black colour covering all the three sensors) then a node stops there for 10 sec in the mean while the driller starts drilling using another motor, the seed sowing hopper driven by the same motor (by means of a wheel like structure connected to a node) will put the seed in that hole. Likewise the robot continues to follow the black line and the cyclic procedure goes on like this, till the end of the black line , if is not present then the robot stops there."
": A plastic injection moulding machine should be altered to facilitate the idea. The hydraulic cylinder of A plastic injection moulding machine should be removed and the arm must be electrically connected to the amplifier. The coding of the Arduino must be such that when the arm is to be moved inwards the arm should generate a pulse to run the motor. The stroke length, which is the amount of distance to be moved, is determined by the intensity of the pulse generated by the Arduino which is constant for a particular product. Therefore the coding need not be changed for every cycle. Once a particular product is manufactured upto the required number, the coding can be altered for manufacturing the next required product. The output from the Arduino is connected to the motor driver and then to the amplifier. the amplifier provides the motor the required power to run. The screw shown in the image is to be actuated by the Arduino control. The hydraulic cylinder of the machine can be removed and electrical circuits can be placed."
": The implementation of the proposed idea two robots. 1. Waste collecting Robot. 2. RobotRobot. Both robots works under co-ordination robot The proposed project consists of a setup where garbage collector bins will be placed at certain corners of the area. The mass can deposit The mass wastes and garbage in the bin. As Waste collecting Robot gets filled above a certain level, Waste collecting Robot senses and transmits a message to a trained robot in order to collect the wastes from the bin. Robot reaches out to the bin, and collects the wastes and deposits Robot to the waste segregation area and gives the information to waste segregation robot. Here, a waste segregation robot is used which automates the sorting process of degradable and non-degradable waste. the wastes and deposits it get segregated into degradable wastes such as paper, food waste etc. and non-degradable wastes such as metal cans, glass bottles. Again, if Robot receives message to collect the waste from any bin, Robot does the same and brings Robot to the waste segregation area. In this manner, waste collection and segregation gets automated and a waste delivery system can be implemented that would minimize human interference in the waste collecting and segregation process. Fig: arena layout Flow chart of Waste collecting Robot. No Yes Start Initialize Inputs and Outputs Information From Waste Box Identify the place Robot move the waste segregation area by following line and return to Segregation area Delivery the waste and information send to Segregation Robot Flow chart of RobotRobot. No Yes Red Other No Yes"
"/ Working : Working is based on capillary action phenomenon, surface tension difference between oil and water, the magnetic property developed in Nano Particle, which will help to separate the oil from water and getting highest recovery of oil spill .Robot contain automatic detection of the oil spilled area using biosensor (CMS 4000), along with expelling the marine animals for the marine animals protection using acoustic wave device. It is autonomous GPS & LED device to indicate the process. Robot is powered by solar & tidal energy (H2O power battery) which are renewable source with advance technologies. Fig. 1 shows the functional units of the system Fig. 1 Block diagram of the system"
"The System is divided into following sub heads - ❏ Importing the image by digital processing using IP camera module(IMAGE ACQUISITION) ❏ Transmitting The System to the laptop through SD Card ❏ Analysing the image using OpenCV ❏ Report based on image analysis Image captured by the IP Camera boarded on the Arduino Controlled Flying Drone is sent to the laptop using wifi/bluetooth. Once the Image Acquisition is done, the Image Acquisition analysis is done using OpenCV. Analysis using OpenCV is further divided into the following sub head : ★ Pest Detection System Following are the image processing steps which are used in The System. >Color Image to Gray Image Conversion Therefore, images are converted into gray scale images so that images can be handled easily and require less storage. The following equation shows how images are converted into gray scale images. I(x,y)=0.2989*B +0.5870*G +0.1140*B > Image Filtering The​ PSNR value ​is calculated for both the average and median resulting images .The average filter provides better result as compared to the median filter. So this paper uses average filter for further processing. > Image Segmentation To detect the pests from the images, the image background is calculated using morphological​ ​operators which is most critical after this image is subtracted from the original image. So the resulting image will only have the ​objects with pixel values 1 and background pixel values 0. >Noise Removal Noise contains dew drops, dust and other visible parts of leaves. As only the object of interest was to be visible on the images,so the aim was to remove the noise to get better and effective results.​ The Erosion algorithm has been used to remove isolated noisy pixels and to smoothen object boundaries ​. After noise removal,the next goal was to enhance the detected pests after segmentation which was performed by using the dilation algorithm. >Feature Extraction Different properties of the images are calculated on the basis of those attributes using which image is classified. ​ For image properties, gray level co-occurrence matrix and regional properties of the images are calculated. ​These properties are used to train the support vector machine to classify images. >Counting of the pests ​on the leaves is the main purpose, so that the leaves can give an idea of how much pests are there on a leaf.the leaves uses ​Moore neighborhood tracing algorithm and Jacob's stopping criterion Flowcharts: ●"
": The implementation of our proposal has many areas involved. First our would like to assemble the two Fire Bird V modules one above the other with a mechanical alignment such that the module above could be placed at various heights. The Fire Bird V module which is in the bottom will take care of navigation of the robot and also The Fire Bird V module which is in the bottom detects objects and moves accordingly. We may face a situation that We may face another human in the shopping mall. For such situations the robot must navigate accordingly to avoid collision. For these processes we will be using IR sensors, proximity sensors, wireless CCD camera and PIR sensor modules. The Fire Bird V with gripper module which is stationed above should be brought at various heights to be suited for the various shelves that will be found at a shopping mall. The Fire Bird V with gripper module which is stationed above will be used to identify the product using various image processing techniques. The Fire Bird V with gripper module which is stationed above gripper will be used to pick and drop the product to the attached shopping cart along with the robot. We are using obstacle detection, Image processing, Gripper Module, Wireless Communication and Wireless CCD camera and by weaving in all these areas in the robot We would like to ensure efficient help to be provided to the user in the process of shopping and making them more comfortable."
": The Android phone/computer is act as a master which sends the information to the slave of the Firebird V Robot (Pastoral Robot). Now latitude and longitude of the GPS information is locate by a Google earth application software. the GPS information is passed to slave of the pastoral robot communicating through IoT. Master Slave Let us discuss about the parts of the pastoral robot like sensors, GPS, Gripper arrangement, Camera. Sensors: White line sensors can autonomously walk in white line. Avoiding obstacles with its Ultrasound scanner and IR proximity sensors covering robot from all sides. PMD with application software Monitor Control Cultivation Seeding ATMEL ATMEGA 2560 controller (GPS, Sensors, IoT, Gripper& Camera) Fertilizing Irrigation GPS: “Global Positioning System”, GPS sensor used to identify the Exact location of the land and GPS sensor also getting the latitude and longitude information from the Google earth. Gripper arrangement: In this gripper arrangement of mechanical setup having different components like as cultivation machine, seed store setup, water tank used for irrigation purpose, and fertilizers of insecticides stored tank with pipelines. Camera: A CMOS camera is using to monitor the robot is what to do? Working Method: The master and slave has work on different operations like as, Master: Monitor, control Slave: Cultivation, seeding, irrigation, fertilization A PMD (Personal Mobile Devices) is used to tag the location of the land. Then the Robot which access the information then go to the exact land followed by GPS. If any obstacles are found by an ultrasonic sensor then choose another way to move the place. When reach the land, the edges of the land is detected by white line sensor. To take the process upon one by one at synchronous time. Initially to start the process using gripper arrangement. the process is operated on the parallelism concept because of reducing the wastage of time. The cultivation, seeding, irrigation, fertilization process at same time one by one. Flow Chart: Not Access Access No Success Start Turn on A PMD (Personal Mobile Devices) application Turn on Robot Set Latitude and Longitude Get Latitude and Longitude Monitor Control Success or Not??? Stop Access or Not??? Start autonomous work Cultivation Seeding Irrigation Fertilizing Relocate/Return to Home"
": Outprojectisfullyautomation.itwillsavefarmerwork.itwillgiveaccuratevalues. Inthisprojectwewilluselightsensor,airhumidity,airtemperature,leafwetness,cropheight measurementusingLASERtechnology,soilmoisture. Thisallsensorwillsensechangeinfarmandwillprovideaccuratevaluestoprecisionagriculture. Precisionagricultureactastransducer.itwillreceivealloutputofsensoranditwillnotaffectanyother sensorvalues.Itwilldecodeallsensorvalueindifferentformatandtransmittofarmermobile. Farmermobileactasbrainofallsystem.Farmerwillcheckvalues,willcompareallvaluewithstandard value.Farmerwillgivecontrolsignaltocontrolsystem. Controlunithandlealltheoperationitwillturnonswitchesasperinstructiongivenbymobileand mobileisreceivingsensoroutput.controlunitworkonsensorvalue Lightsensoroutput=bulbwillon/off Soilmoistureoutput=waterirrigationsystemon/off Laseroutput=checkheightofcrops Leafwetness=fertilizer/waterirrigationsystemon/off Temperaturesensor=airconditioningon/off"
"Note: Sending and receiving operations are performed used using ZigBee Algorithm: - Start - Update the database system with the tasks - Send the tasks to Master Robot - Master Robot receives tasks and schedule time to each task - Master Robot sends tasks to Slave Robot - Slave Robot receives the task and performs - If Slave Robot cannot perform task in scheduled time (a) Yes, Slave Robot - Slave Robot completes task in the remaining time - Done Update the Database System Master Robot receives tasks Slave Robot - Slave Robot schedules the task Slave Robot receives task If task is not completed by the scheduled time Perform task Slave Robot - Slave Robot complete the task in the remaining time done"
": The whole process of medication through the robot is shown in three categories: For the user level (Patient) level 1. To get the required information from the doctor: After the patient is being diagnosed with Tuberculosis (TB), the doctor will prescribe the medicine and will assign a ‘Patient ID (P_ID). the doctor will also be making a new entry in the database about the new patient, dosage frequency, fingerprint and additional details of the patient. 2. Medication procedure: After getting the data from the doctor, the robot will go to the assigned location of the patient and will ask the doctor/the patient to scan the assigned location of the patient fingerprint. the robot will then compare the input signal quantity with the one in the database and if the entry matches, the robot will check for the dosage of each medicine (no. of tablets/drugs). 3. Dispatching of medicine: Based on the entry in the database, computer will generate control signals which will then be used to actuate the electronic switches to dispatch the medicine into the dish below. 4. Updating the database: As when the medicines are dispatched, ultrasonic sensor senses the dispatch and a control signal is given by the robot to update the database. For the administrator/doctor level 1. Security and authenticity scanning: At first the robot will scan the fingerprint of the administrator (for security and authenticity). the robot will display certain conditions (modifying the database, delete an entry from the database and making a new entry) which will be answerable by the 4x4 keypad. 2. Handling conditions: a. Deleting the record: As soon as the administrator selects the delete option from the screen, the robot will ask for the patient’s fingerprint whose record is to be deleted. the robot will then search for that data record in the database and will display patient ID (P_ID). the robot will also ask for the conformation before deleting the record. the record will be deleted as soon as the confirmation is given by the doctor via keypad. Flowchart: b. Modifying the database: The same procedure of obtaining the authenticity of the administrator and patients will be carried out. the administrator will then be able to modify/alter the dosage levels and frequency of dosage for the called patient. c. Making new entry: the robot will ask the administrator for the patient’s ID (P_ID), fingerprint, dosage levels and the frequency of dispatching the medicines. new entry will be stored into the database internally. Miscellaneous: 1. Refilling the supply: Whenever the drugs present in the storage unit will be below a certain threshold (say less than 3-4 packs), an alarm will be fired along with the LCD displaying the message for filling the storage unit. As soon as the refilling is done by the administrator, the robot will also ask for the new quantity details from the administrator. This new set of quantities will be logged in into the database."
Flow chart:
": Mobile phone which is connected to the robot is kept in auto receiving mode. For the control of robot, we have to make a call to the- mobile phone which is attached to the robot using earphone. Thus two mobile phone are connected via mobile network. When a call to the- mobile phone which is attached to the robot using earphone is received then press the button in- your mobile. DTMF tone is received by the mobile that is- connected with the robot through headphone. These signals are received by the DTMF decoder that- decodes the signal in binary sequence to the microcontroller. Sequences are given in table 1 Due to the programming in controller robot will move- when pressing key in your mobile. Microcontroller outputs are in binary form. The high- output of the controller drives the motor driver to drive the motor in forward direction. Similarly we can move the motor in backward, left,- right motion and stop condition. According to the source code given here key 2 is for- forward, key 4 is for left rotation, key 6 is for right rotation, key 8 for reverse rotation in this robot navigation DTMF keypad frequency Control keys Robot direction 2 Forward 4 Left 6 Right 8 Backward 5 Stop Flow chart of the system"
": The microcontrollers like Arduino and Raspberry Pi are used in both the manual and autonomous mode. And sensors like accelerometer and flex are used over human body to detect the motions and actuators like servo motors are used in robot chassis to control the motion of Shadow Humanoid. Shadow Humanoid will be working on manual and autonomous mode. In autonomous mode, the raspberry pi along with raspberry pi camera will collect data in the form of images and this will be used to recognize the culprit. The culprits photo will be saved in the positive image files for recognizing. As soon as the culprit is identified Shadow Humanoid will be activated in manual mode. In the manual mode the Arduino collects data from sensors like the flex sensor which is used for various body joints like the elbow, fingers and toes whereas the accelerometer is used to collect data for forward, backward, upward and downward movements of arms and legs. This data about the movement of various body parts is collected by the Arduino Uno and sent to Shadow Humanoid using a Xbee Module. The receiver Xbee module then transmits the received data from sender the Arduino Uno to the receiver Arduino Uno which is implanted on Shadow Humanoid. The receiver Xbee module then controls the actuators depending on the received data. Fig : Block Diagram of Shadow Humanoid. Fig : Torso. Fig : Torso. Fig : Shoulder and Arm. Fig : Torso. The movements of all the parts of Shadow Humanoid will be controlled using servo motors. Flex sensors along with accelerometer will be used for depicting human actions which will be present on the human body."
"The project is to clean the roads and to collects the domestic waste in local dump manner. For this we use a Fire bird V robot and a servo motor. the Robot consists of sensors like directional, IR, detection sensors. These are used to move the Robot in a desired direction by writing a code using the software AVR Studio and AVR Boot loader. By this the Robot collection of waste is easy and there is less Human effort. Garbage Pollution free society and Hygienic society. Because many diseases like diarrhea, cholera, typhoid, malaria skin diseases and respiratory allergies are transmitted due to this garbage pollution."
": We have divided the project into two parts (which are combined together in the actual project) 1. Fuel theft alarming system 2. Fuel level indicator Block diagram of Fuel theft system is shown in Fig 2 below Fig 2: Block diagram Working: The fuel will flow from the fuel tank to the carburetor with the valve acting as a switch. The thief will try to steal The fuel by making an incision to the pipe connecting them. This can be sensed by placing a sensitive PIR sensor (motion sensor) in the region where The thief is most likely to make an incision. This motion sensor is interfaced to the microcontroller (Arduino Uno), which is further connected to a piezoelectric buzzer (to produce alarm effect) and to the GSM module which will alert the owner of the vehicle about the activity in the fuel tank-carburetor region. Fig 3: PiezoelectricBuzzer GSM module Fig4: GSM Module GSM module is used to establish communication between the activities that are taking place in the vehicle about the activity in the fuel tank-carburetor region and the owner’s mobile .Global System for Mobile communication (GSM) is an architecture used for mobile communication in most of the countries. GSM/GPRS module consists of a GSM/GPRS modem assembled together with power supply circuit and communication interfaces (like RS-232, USB) for computer. Whenever there is motion, the information is sent to the owner’s mobile via GSM module[3]. PIR SENSOR An individual PIR sensor detects changes in the amount of infrared radiation impinging upon it, which varies depending on the temperature and surface characteristics of the objects in front of GSM module[3]. PIR SENSOR. When an object, such as a human, passes in front of the background, such as a wall, the temperature at that point in GSM module[3]. PIR SENSOR's field of view will rise from room temperature to body temperature, and then back again. GSM module[3]. PIR SENSOR converts the resulting change in the incoming infrared radiation into a change in the output voltage, and this triggers the detection.[2] https://en.wikipedia.org/wiki/Human https://en.wikipedia.org/wiki/Wall https://en.wikipedia.org/wiki/Room_temperature https://en.wikipedia.org/wiki/Room_temperature https://en.wikipedia.org/wiki/Body_temperature Fig5: PIR Sensor Thus by using the above mentioned sensors we can avoid the theft of the fuel.The fuel tank and the carburetor are as shown in Fig 6 below. Fig 6: Fuel Tank and the Carburetor connection Fuel level indicator The conventional fuel indicators as shown in Fig 7 do not indicate precisely how much fuel is remaining in Fuel Tank. Fig 7: Fuel Level Indicator Working: In order to overcome the above mentioned deficiency of a fuel indicator, we can add an ultrasonic sensor at ceiling of Fuel Tank. Ultrasonic sensors are devices that use electrical– mechanical energy transformation to measure distance from the sensor to the target object. Ultrasonic waves are longitudinal mechanical waves which travel as a sequence of compressions and rarefactions along the direction of wave propagation through the medium. GSM module[3]. PIR SENSOR helps us to indicate the distance of the periphery of the fuel surface from the fuel tank ceiling which further tells us the amount of fuel present in Fuel Tank. Fig8: Ultrasonic Sensor The Arduino is interfaced with the ultrasonic sensor as well as a GSM module which sends a SMS of the exact fuel content in Fuel Tank, thus helping the driver keep track of the fuel content in the driver vehicle. By this method we get the exact amount of fuel rather than the ones shown by our conventional indicators proving very useful to the owners [1]."
"This system totally relies on array of proximity sensor, LDR Sensor and Ultrasonic Sensor. Whenever a vehicle is at the starting position of the tunnel, a vehicle is detected by ultrasonic sensor. All lights inside the tunnel will turn on simultaneously. As a vehicle covers a vehicle path inside the tunnel, lights behind a vehicle will automatically turn off. Intensity of lights behind that vehicle will be determined by the lighting condition inside tunnel and outside the tunnel. 3 Figure 1: Tunnel Representation This figure represents a tunnel. a tunnel is divided into various sections so as to illustrate. Each section contains a light and a proximity sensor. Car starts Car journey from section 1 and moves towards section 5. When Car is about to start i.e to enter tunnel car gets detected by the ultrasonic sensor. As soon as This system detects car, all the lights in tunnel will turn on simultaneously with different intensities. When car completes car journey in section 1, and proximity sensor 2(situated in section 2) detects car then light in section 1 will automatically turn off. And so on. Intensity of each light is controlled by microcontroller using PWM whose duty cycle is controlled by monitoring the LDR sensor.this signal is fed to lights through a relay switch. each light section is controlled using relay. 4 Figure: Block Diagram of Automatic Tunnel Efficient Lighting System"
": Flex sensors are analog resistors, which work as a variable analog voltage divider. The Inside of flex sensor are carbon resistive elements with thin flexible substrate. More carbon means less resistance. When the substance is bent, The Inside of flex sensor produces resistance output relative to the bend radius. The Inside of flex sensor achieves great form-factor on a thin flexible substance. When a thin flexible substance is bent, The Inside of flex sensor produces a resistance output correlated to the bend radius as shown in Figure. Smaller the bend radius, higher will be the resistance value [5]. The variation in deflection or bending of flex sensor results in variation of resistance itself. The signal conditioning circuit is used to read these resistance changes and The signal conditioning circuit is given to ADC. ADC converts these values into equivalent digital values. [5] Right hand flex sensors would be used to control the movement of the grippers by the help of the fingers. On the other hand the movement of the robot is controlled by the left hand. The figures below illustrates the movement of the robot in the different direction, i.e. [5] Pointing finger – Move forward Little finger – Move backward Pointing finger + Ring finger – Left Turn in forward Pointing finger + Middle finger – Right Turn in forward Little finger + Ring finger – Right Turn in backward Little finger + Middle finger – Left Turn Turn in backward No Finger – Stands still Move in Forward Direction Turn Right in forward Direction Move in Backward Direction [6]"
"The poultry farming robot system will be implemented in the different stages as follows. Stage 1: Arena Arrangements We consider the arena as shown below in figure 1 to implement the proposed concept. the arena contains a storage rack of chickens (birds) and the robot path. the arena consists of 12 cells and the food feed storage rack which is represented in (Brown Colour) and the egg storage box which is represented in (Blue Colour). The Fire Bird V Robot can traverse in the center path of the area is represented as robot path where The Fire Bird V Robot can be traversed. The junction point, which is not shown, for each cell might be included if The Fire Bird V Robot is filling out the food for each cells. The considered arena design somewhat resembles the real time poultry field which is also represented in the figure 2. Figure 2: Real Time Poultry Farming Field Stage 2: Robot and Gripper Arrangements Fire Bird V Robot consists of the movable arm with gripper arrangements which can move up and down to pick up and drop the eggs and for feeding the food in the corresponding storage rack. This gripper arrangements actuator work based on the sequence. Robot and Gripper Arrangements Fire Bird V Robot. Demonstration can be made into two sequences on the arena continuously. 1) First sequence – Namely, Food Feeding Sequence: In food feeding sequence, the food feeding gripper only actuates remaining gripper arrangements are not actuated. Arm can be moved depending upon the distance. 2) Second sequence - Namely, Egg Collecting Sequence: The another gripper arrangement is used to pickup the egg from the egg storage box of the arena and drop in the dispenser box which is placed on the top of The Fire Bird V Robot. The figure 3(b) is movable arm with gripper arrangement consisting of two grippers. 1) Food Feeder gripper is used to feed the foods for chicken using IR sensor and funnel setup as shown in the figure 3(b). 2) Pick and Drop Gripper is used to identify the eggs present in the storage area using colour sensor which is shown in the figure 3 (b). Stage 2(a): First Sequence - Food Feeding Sequence In the first Sequence, The Fire Bird V Robot feeds the food to concern storage rack. Primarily, the food has been filled by manually into the funnel which is fixed with food feeding gripper. The Fire Bird V Robot initiates the first Sequence by entering into The Fire Bird V Robot path. Using the IR sensor value, The Fire Bird V Robot adjusts movable arm position and actuates the food feeding gripper. Then, The Fire Bird V Robot adjusts the feeder funnel to make The Fire Bird V Robot fit into concern storage rack. This adjustment is based on the programming made on The Fire Bird V Robot. Afterwards the food feeding gripper opens the funnel to feed the food in the food feeding storage rack of the arena. The food feeding is done continuously to concern storage rack. The over flow of the food is restricted by gripper arrangements. Food feeding method is done by The Fire Bird V Robot as shown in figure 4. Stage 2(b): Second Sequence - Egg Collecting Sequence After completing the first Sequence, The Fire Bird V Robot enters into the second sequence which is egg collecting sequence by which The Fire Bird V Robot is programmed to adjust the movable arm gripper, enabling the colour sensor which is fixed in the gripper and the actuators of the pick and drop gripper. The Fire Bird V Robot enters into its path and identifying the eggs using the color sensor. If the egg is identified, then the movable arm adjusts the pick and drop gripper’s position to pick up the egg and drop the egg into the dispenser box which is fixed on the top of The Fire Bird V Robot as shown in the figure 5(a). Dispenser box can carry maximum 50 to 100 eggs. After completing the cycle, The Fire Bird V Robot moves to the egg storage area. By using the same gripper, The Fire Bird V Robot picks up the egg from dispenser box and drops The Fire Bird V Robot into storage area as shown in the figure 5(b). After completing this process, The Fire Bird V Robot moves to the Chicken Storage rack to initiate the first sequence."
": Flowchart of algorithm we use to chose path TO MAKE MACANUM WHEEL Construction of mecanum wheels requires a lot of energy and patience. It took my friend a week to complete the wheels as well as the vehicle. The design of entire vehicle is first designed in solid works. But instead of making twelve rollers you can change The design of entire vehicle and go with eight rollers also like what we have done. Then the dimensions of the wheel are printed on a paper and a paper is pasted on the metal sheet to make the cutting easy. Using the cutting machine cut the sheet metal to the outer lines of the sketch. Now give some good surface finish to the cut surface using the grinding disk and for clean finishing use files (more shining). The finished product is shown in the image section. Use chisel and hammer to cut the portions which cannot be cut using cutting machine. Use files to make sure your work is neat and tidy. Next you will have to drill holes of 4mm on the leading edges using hand drill machine. Now with the help of bench vice bend the edges of the cut to angle of 45 degrees. Once you have bent all the edges your work should resemble something like whats shown in the image. Each wheel requires a pair of these and hence four wheels will amount to eight. Once you are done with two of these and use 4mm nuts and 4mm bolts to clamp these. Make sure these are not tight as this is just to make sure that all the angles and holes are proper. Next with the two of these clamped make holes at the centre of both the metal sheets so that there is enough space for the metal shaft of the motors to pass through. You can also make your own metal shafts if the motor shaft that you are using is fragile or weak. We made We own metal shafts of 11cm long, passed our own metal shafts of 11cm through the holes at the centre and then welded our own metal shafts of 11cm permanently. Once this is done this is time to make the rollers. Take wooden pieces and place wooden pieces on the lathe machine. Make a barrel shaped roller of length 5cm long with 4cm width at the centre and 3cm width on the edges as shown in the figure. Cut wooden pieces using hacksaw and use sand paper to clean any rough edges. Each wheel requires eight rollers and hence a total of 32 for four wheels. Pack cycle tube around the barrel shaped rollers to maximize the grip. eight rollers and hence a total of 32 for four wheels have to be place between two metal which we bent to 45 degree using the nuts and bolts. Spacers are then used if eight rollers and hence a total of 32 for four wheels are loose. Then the motors are fitted into the wheels using shafts. TO MAKE HOME CLEANER ROBOT A number of software and hardware implementation techniques were used to design and develop the system. Fig. 1 shows the block diagram of system. We used a 12VDC motor, L293D IC, Different Sensors, Real Time Clock, Vacuum mechanism and Arduino to develop We system. The operation of the robotic vacuum is going to be based on retrieving data from an array of inputs that will tell the condition of the floor space around the robotic vacuum. inputs that will tell the condition of the floor space around the vacuum include sonar, touch sensors, and a digital compass. Each of these parts will be described in further detail further on later in the documentation. The data from inputs that will tell the condition of the floor space around the vacuum will be fed into the chip(s) which through the chip(s) software program will decide which direction the robotic vacuum should move by sending the control signals out to the motors. Figure 1.1 The initial block diagram for the Autonomous/Mannual Robotic Floor Cleaner Components: 2.1 Microcontroller: Arduino Mega 2560 Arduino Mega 2560 is a microcontroller board based on the ATmega1280 (datasheet). Arduino Mega 2560 has 54 digital input/output pins (of which 14 can be used as PWM outputs), 16 analog inputs, 4 UARTs (hardware serial ports), a 16 MHz crystal oscillator, a USB connection, a power jack, an ICSP header, and a reset button. Figure 2.1: Arduino Mega Front 2.2 Motor Driving IC L239D A very easy and safe is to use popular L293D chip. It is a 16- pin chip. The pin configuration of a L293D along with the behaviours of motor for different input conditions is given in fig. 4. The L293D is designed to provide bidirectional drive currents of up to 600-mA at voltages from 4.5 V to 36 V. When an enable input is high, the associated drivers are enabled. Also the associated drivers outputs are active and in phase with the associated drivers inputs. When an enable input is low, the associated drivers are disabled, and their outputs are off and in the high-impedance state. With the proper data inputs, each pair of drivers forms a full-H (or bridge) reversible drive suitable for solenoid or motor applications. Table 2.2: Behaviours of motor for different input conditions The dc motor and L293D IC has been connected according to the fig. 9. The circuit schematic as shown has been designed using Proteus 7. Figure 2.2.2: Screenshot of DC motor and L293D IC interfacing circuit 10 2.3 DC Motor Almost every mechanical movement that we see around we is accomplished by an electric motor. Electric machines are means of converting conventional energy. Motors take electrical energy and produce mechanical energy. Electric motor is used to power hundreds of devices we use in everyday life. An example of motor used in day to day life is automobiles, food blenders and so is vacuum cleaner. 2.4 Bluetooth (HC - 06) For the communication of the robot with the cell phone or a mobile we are using the Bluetooth device. the Bluetooth device is attached to the robot that receives the data from the mobile and also the Bluetooth device can transmit the data. the Bluetooth device is used for converting serial port to Bluetooth. the Bluetooth device has two modes: Master and Slave. 2.4 Bluetooth (HC - 06) is a wireless communication protocol running at the speed of 2.4 GHz with the architecture of client-server and which is suitable for forming personal area networks. 2.4 Bluetooth (HC - 06) is designed for devices such as mobile phones (low power). Bluetooth protocol uses the MAC address of the Bluetooth device. 2.4 Bluetooth (HC - 06) gives the connectivity between two devices using 2.4 Bluetooth (HC - 06) MAC address. Figure 2.4: 2.4 Bluetooth (HC - 06) Module 2.5 IR Sensor The sensor consists of two eyes. One eye sends the infrared light and the other eye sees the reflection of that infrared light and measures the distance which is then sent to the Arduino through analog input to perform further operations based on the distance. There are three wires coming from 2.5 IR Sensor The sensor .i.e. Red, Black and White or it can be Red, Brown and Yellow. Red is connected to 5V of Arduino. Black or brown to Ground of Arduino. White or yellow to analog input pin of Arduino i.e. in this case to analog pin 0. 2.6 LDR Sensor The light dependant resistor is an electronic component whose resistance decreases with increasing light i te sity. The light dependant resistor is also alled as Photo Resistor or Photo o du tor . The light depe da t resistor uses high resistance semiconductor material. When light falls on such a semiconductor the bound electrons [i.e., Valence electrons] get the light energy from the incident photos. Due to this additional energy, the bound electrons [i.e., Valence electrons] become free and jump in to the conduction band. The electron – hole pairs are generated. Due to these charge carriers, the conductivity of the device increases, decreasing The light dependant resistor resistivity. 2.7 Ultrasonic Sensor 2.7 Ultrasonic Sensor is a high performance ultrasonic range finder. 2.7 Ultrasonic Sensor is compact and measures an amazingly wide range from 2cm to 4m. This ranger is a perfect for any robotic application, or any other projects requiring accurate ranging information. 2.7 Ultrasonic Sensor can be connected directly to the digital I/O lines of your microcontroller and distance can be measured in time required for travelling of sound signal using simple formula as below. Distance = (Echo pulse width high time * Sound Velocity (340M/S)/2) or Distance in cm = (Echo pulse width high time (in us)*0.017) The module works on 5VDC input and also gives an output signal directly for detection of any obstacle up to 4M.Power up 2.7 Ultrasonic Sensor by 5VDC using pins 11 VCC a d GND . First of all a us trigger i put has to e give to the pi a ed Trig o the sensor. This starts one cycle of range conversion and sends 8 bursts of sound waves from the tra s itter. As soo as the sig als are tra s itted the E ho pi goes to high level a d re ai s i high level until the same sound waves are received by the receiver. If the received sound waves are same as what the same sensor transmitted then the Echo pin goes to low level. If no object is detected within 5M after 30ms the Echo signal will automatically go to low level."
": As shown in fig[1] smart grid is divided into 3 hierarchical layers. First layer being the user end, encompasses smart homes, smart appliances, smart electric vehicles, renewable energy sources (such as solar PV plants) where the data is captured by sensors etc.. The second layer is predominantly involved in communication and network, has roles of data storage. All the necessary data that is available at first layer is routed to second layer through user interfaces which has secure access points called as gateways. Third layer being the Power generation layer (master station) is mainly concerned with power generation, transmission and distribution. fig[1]:Cognitive Architecture with various levels of data transfer Data collection: Whenever there is no data transmission happening between the layers of smart grid for a specific period of time, an autopilot UAV is sent to the respective layer of the grid for data collection. an autopilot UAV initialises Zigbee protocol for data reception as shown in fig[2], After receiving All the necessary data that is available at first layer an autopilot UAV returns to the data center and dumps All the necessary data that is available at first layer. Fire extinguishing: If there is a fire at any point in the transmission line or in the grid, the location of the accidental fire is sent to an autopilot UAV through GPS. an autopilot UAV loads the accidental fire extinguisher ball, reaches the site, drops the ball and returns to the data center. fig[2]:Work flow"
: 1. Books to be returned will be kept in the box joined with the robot chassis. 2. With the help of image processing the bar code on the book will be recognized. Either barcode reader can be integrated with the robot or with the help of image processing we can make we own. 3. After decoding the data is sent to the computer and respective rack is known. 4. the robot moves to the respective rack while following the line. 5. Then the robot picks up the book with the help of the hand attached to the book. 6. Robot after picking up the book keeps the book in an empty position.
": In the proposed system, we are going to use water impurity sensors and Hydrodynamic Cavitation system to interface with Arduino. And send these data to cloud through ESP8266 so that, to become conversant about the impurities in the water. After getting data, the relay which is interfaced with Arduino switches ‘ON’ or switch ‘OFF’ the Hydrodynamic Cavitation setup as per the condition sets in the Arduino Board. System Design: In System Design most predominantly, sensors monitor the impurities in water and send a signal to hydrodynamic cavitation module to operate. Water Quality Sensors: Water Quality Sensors will sense the impurities dissolved in water like dissolved oxygen (DO) and dissolved ions as well as Recognize Water Quality Sensors pH, turbidity, conductivity, temperature. Succeeding Water Quality Sensors will send these data to the Arduino Board. 1. TDS Meter: CB18845 Digital LCD TDS3/TEMP/PPM TDS Meter is a digital TDS meter tester, to test the water quality purity, check the performance of your water and for hardness (1grain=17ppm). CB18845 Digital LCD TDS3/TEMP/PPM TDS Meter gives output for TDS but we can use these data for hardness example- if TDS level is 0-70ppm then your water is very soft, 70-150ppm then soft, 150- 250ppm then slightly hard and so on. [5] 2. Gravity: Analog pH sensor: This is a professional Arduino pH Sensor Meter Kit with industrial electrode. This industrial a professional Arduino pH Sensor Meter Kit electrode is made up of sensitive glass membrane with low impedance. a professional Arduino pH Sensor Meter Kit can be used in a variety of PH measurements with fast response and excellent thermal stability. a professional Arduino pH Sensor Meter Kit has good reproducibility, is difficult to hydrolysis, and can eliminate basic alkali error. In 0 to 14pH range, the output voltage is linear. The reference system which consists of the Ag/AgCl gel electrolytes salt bridge has a stable half-cell potential and excellent anti-pollution performance. [6] 3. EZO™ Dissolved Oxygen Circuit (#EZO-DO): • Full range dissolved oxygen readings from 0.01 to +35.99 mg/L • Accurate dissolved oxygen readings down to the hundredths place (+/- 0.2) • Temperature compensation • Salinity compensation • Pressure compensation • Compatible with any microprocessor that supports UART, or I2C protocol [7] Arduino Board: This is a microcontroller board based on the ATmega328p. This has 14 digital input/output pin. This receive the data from sensors and match the data by the condition we put into the data. If the data bear resemblance with the threshold condition then the data bear resemblance with the threshold condition terminates to the next system. [8] Relay: the next system uses the next system as a switch. the next system operates after receiving the signal from Arduino board to switch on the Hydrodynamic Cavitation module. Hydrodynamic Cavitation Module: Before using the process of Hydrodynamic cavitation, it is mandatory that the next system should identify all impurities and parameter in the water as after monitoring; the next system operates as a sole technique or the combination with other techniques such as ultrasound. In this techniques that employ hydrodynamic cavitation for cleaning of water and impurities in water is presented. ESP8266: the next system is used for connecting the Arduino module data to internet. · 32-bit RISC CPU: Tensilica Xtensa LX106 running at 80 MHz* · 64 KiB of instruction RAM, 96 KiB of data RAM · External QSPI flash - 512 KiB to 4 MiB* (up to 16 MiB is supported) · IEEE 802.11 b/g/n Wi-Fi · Integrated TR switch, balun, LNA, power amplifier and matching network · WEP or WPA/WPA2 authentication, or open networks [9]"
": Object Detection Sensor Seed Counter Power Supply Wheel Motors Controller GPS Navigation Left Motor Battery Right Motor First of all, the GPS data relative to the selected area of land to be seeded is obtained for the purpose of synching to the actual GPS. This is achieved by placing a GPS tracker to the machine for allowing the machine to be positioned. The various points to be seeded are selected on the given land and co-ordinates are assigned to each of the selected points. The actual GPS co- ordinates as given by the GPS are obtained and then fed into the machine via using an Android phone. The inputs are taken directly via GPS services like Google Maps etc. and fed into the machine using an APK developed for this purpose. This synching of actual values of latitude and longitude to the machine enables the machine to verify the machine position on the earth. This is done by comparison and decision. The actual values and the current GPS data values are compared with each other and then decision is made by the machine to locate the machine position correctly. Once the points are detected, the electrical signals are sent to the servo motors and this allows the servo motors to move to the first selected points. When the servo motors has reached to the specified points the machine allows only one seed to be sown into the ground per point. This helps in cutting down the wastage of seeds. The account of seeds is kept by using a seed counter for precision. After finishing the sowing process, the machine moves to the next designatedpoint as fed by the user. In the above mentioned manner the first lane of seeds are sown. As the machine reaches the end of the first lane, the machine turns to the left or right of the lane and moves forward to the next point of sowing. the lane ends are precisely determined by the machine with the help of the GPS data as fed into the machine. the servo motors receive signal to rotate to the left or to the right direction thus precisely locating the next lane to be sown. the machine moves in the same manner as described earlier and completes the entire cycle of seeding in a precise and efficient manner. The object detecting sensor is fixed on the front end of the machine for allowing the machine to detect any obstacle in the machine path and thus allowing the machine to steer the machine way around the obstacle to reach the next designated point. All of the systems are powered by powerful batteries which can be recharged for using again."
": Existing System: There is currently no working system that ensures traffic free ambulance service in practice that overcomes the congestion problem. Proposed System: Proposed System is designed to develop a city into smart city. Proposed System is an initiative that is thought to save the life of people. Proposed System uses the concept of Internet of Things and a combination of sensors to solve traffic snarls. Proposed System uses the light and sound to alert the public by using LED and Speakers. Design: The figure below illustrates the design of the Traffic Free Ambulance Service System: Traffic Free Ambulance Service Working Principle In case of emergency, the driver activates the mobile phone application in ambulance which sends signals to the lamp post on the divider in the route through which the ambulance pass–by using the GPS Service and Google Maps. When the ambulance moves the signals are automatically sent. the signals produce sound and light to alert the public to give way for the ambulance. If there is a traffic signal then is RED, the ambulance cannot move further so the solution is to change the signal from RED to GREEN other to RED. To change the signal from RED RED to GREEN before 1km the sensor detects the arrival of the ambulance and changes the signal from RED. This method is implemented, so that there is no further congestion in the way for ambulance. In case of crossroads the change of signal may cause accidents. So a method is designed to subsequently change the other signals to RED by using sensor and GPS. This would ensure safety of public and avoid haphazard. The figure below illustrates the working of the traffic free congestion system. Working of Traffic Free Ambulance System"
": The robot is controlled using Arduino to move left, right, forward and reverse. The program is written such that The robot is controlled using a joystick. A transmitter of range which is well enough to be operated from extreme ends of a tennis field is used for interaction between the joystick and The robot (Usually the tennis court has a dimension of 23 m X 8 m). The user can thus move The robot towards the ball in any corner of the field. The robot has an acrylic sheet as the end effecter. an acrylic sheet would rotate clockwise with respect to X axis. When the ball comes into contact with an acrylic sheet, the force due an acrylic sheet will push the ball inside The robotthe ball . (The working is similar to that of a spinning door. If an object which comes in contact with a spinning door, it will be pushed to the other side, provided the force exerted by the object against the force due the sheet by a spinning door is negligible). Fig 1: Spinning door The robot can hold a certain number of balls. Weight of one ball is taken into account and the total weight of the chamber containing the balls is calculated. If Weight of one ball reaches the maximum (the sum of the weight of a chamber and the weight of the maximum number of balls allowed), a servo motor is actuated. a servo motor is connected with a flag which is folded by default. Under actuation a flag which is folded by default unfolds, alerting the user. the user can then operate The robot to come to the home position. Here, The robot is supposed to unload the chamber containing the balls and reinsert the chamber containing the balls. Now The robot is ready for The robot next hunt J"
": Initially the android application was to be created to get the order from the customer. The order and the table details are transmitted to the robot wirelessly. Ubuntu based system with ROS controls the robot to plan a path with the help of a camera, first the image is captured. By using python and image processing the path was generated and the robot will navigate to the destination and delivers the product. BLOCK DIAGRAM:"
: The patient will send the message through mobile phone which contain the valid address location of the patient home and details about the medicine. The robot will read the message and check for the medicine in there store. If the medicine is not available the robots send a message to patient that “the medicine is not found” and If the medicine is available The robot will pick the medicine using The robot arm by reading the barcode of the medicine from medical shop and collect the medicine into the collecting box and deliver the medicine to the patients home FLOWCHART . NO YES NO i=O; i<n; Take the medicine Place the medicine in delivery box i>n Send the medicine is Not available NO YES Read message Message received or not? START Wait for message Check for the medicine &acquire the count = ‘n’ the medicine delivered to patient STOP
": The implementation of the proposed idea comprises of two separate functions. The first 1. Loading 2. Unloading. Initially the porter robot pays a host in the “Robo Park” which perhaps present in the entrance of every railway station. Once the passenger reaches the taxi drop, he/she takes up the ticket which holds the information of the compartment and platform. the porter robot is retreated from the “Robo Park and the ticket is scanned with the porter robot. By doing so, the ticket information is updated to the porter robot and also apparently opens up the storage box. Once this process is done, the porter robot moves to the corresponding platform and to the mentioned compartment. The intriguing fact is that the box which rests in the porter robot cannot be opened until the same barcode which resides in the ticket is scanned. After the passenger reaches the destination, the porter robot awaits wherein the consignment is placed in the same box, and the ticket is scanned once again. the porter robot proceeds to the taxi pick up point and awaits the passenger for scanning the ticket and once this process is done, the porter robot release the consignment. Fig: Arena Entrance Robot Parking NO NO YES YES Open the storage box the porter robot moves to the porter robot parking Check for Bar Code Wait in the taxi pick up Open the Storage box Check for Bar Code LOADING NO NO YES Wait in the delivery place Check for barcode the porter robot moves to the porter robot parking NO Open Storage box Check for barcode Robot Move to the entrance Start Initialize I/OS Check for Bar Code Check loading/ unloading YES Move to destination depending on code YES Depending on Code, the porter robot moves to the compartment"
": The machine starts The machine function by ploughing the field, then sows the seeds in the ploughed area and ends the process with covering the seeds sown with soil. The mechanical design of The machine is also simple. The mechanical design of the machine is programmed to carry out the above functions simultaneously. To perform the function of ploughing The machine is equipped with spiked wheels which are fixed in the anterior end of The machine, to sow seeds The machine has a container with seeds and The machine bottom contains a perforation to drop the seed and finally the posterior end of The machine has a sloping metal sheet touching the ground to cover the sown seeds with soil. Automatic Seed Sowing Machine 2 BLOCK DIAGRAM:"
":The basic of this fire extinguisher is that it all depends on sound bass,The low frequency sound waves are required to extinguish this fire. The whole of apparatus is connected with a power supply ,the power is given to , Heat or smoke sensors, which sense fire.,A triggering circuit , A 555 tone generator,Voltage regulator,8 ohms speaker,Collimator tube, When these all are summed up .,,with power supply works as fire extinguisher., The sound waves are mechanical vibrations low pressure area traps this fire mechanical vibrations . The basic concept is that ,"" pressure waves and they displace some of the oxygen"" At a certain frequency The sound waves separate the oxygen from fuel. The pressure goes back and forth and that agitates where the air is. The space created is enough to keep fire from reigniting. The ultra high frequency did not work and music also because it is not consistent. The low frequency of range 30-60 Hz did it ,this fire started extinguishing. We are required to amplify that low frequency vibrations to make a use of it ."
"The operation of robot will be based on Line follower technique which will follow the black line path towards respective table. There will be switches for selection of table, at which table robot will serve the refreshment. We are also working on e-menu service. By using e-menu card customer can order directly to the kitchen. After the placement of the order customer will get the confirmation of his order on the table, here we are using tricolor LEDs on the table to inform the customer order status.it will be some sequential. When order will ready, the customer order will placed on robots arm. Robot will follow the line and reach to the table, customer will pick that refreshment. If there is any kind of obstacles in path robot will stop and wait for while path clearance, if path will not clear more than 15 sec(decided delay), Robot will request for the clearance of path. When customer will take the customer order, customer will press on the decided place for the confirmation of the receiving order. Robot will follow decided path return to the position. Figure: block diagram of waiter robot Figure: Architecture of waiter robot"
"The aim of this robot is to reduce pressure which is building on farmers due to increase of population. this robot can perform many tasks which farmers have to do in farmers day to day life for example watering crops, sowing seeds. this robot can also perform many other tasks like checking soil quality and also tells that which type of cropping should be suitable."
: The solar panel can be replaced by battery power supply for reduce the recharge cost. And one or more system can be monitoring through the GSM system. Then the GSM system also includes the weeding and harvesting in the GSM system. EXPERIMENTAL SETUP: Literature Survey/Prior Artwork: The fire bird V robot is programmed for a specific gap between the plants. The programme is written such that The programme SOLAR PANEL 10 WATTS 12 VOLTS CHARGING CONTROLLER 12 VOLTS LEAD ACID BATTERY FIRE BIRD v ROBOT PICKING MECHANISM SEED SOWING MECHANISM MICRO CONTROLLER FOR MOVEMENT RF RECEIVER identifies the plants present between the programmed distance and removes the plants present between the gaps. For example let us consider that the plants are to be placed at a distance of 10 centimeters for better yield. Then LEAD ACID BATTERY FIRE BIRD v ROBOT PICKING MECHANISM SEED SOWING MECHANISM MICRO CONTROLLER FOR MOVEMENT RF RECEIVER is programmed such that LEAD ACID BATTERY FIRE BIRD v ROBOT PICKING MECHANISM SEED SOWING MECHANISM MICRO CONTROLLER FOR MOVEMENT RF RECEIVER identifies the plants and does not harm the plants placed at multiples of 10centimeters. LEAD ACID BATTERY FIRE BIRD v ROBOT PICKING MECHANISM SEED SOWING MECHANISM MICRO CONTROLLER FOR MOVEMENT RF RECEIVER removes the remaining plants present in between the 10cm and removes the remaining plants present in between the 10cm with artificial arm.
": Before describing about how radiation detector works, let’s know about what is radioactivity and ionization radiation. WHAT IS RADIOACTIVITY? Radioactive decay occurs in unstable atomic nuclei that is, ones that don’t have enough binding energy to hold the nucleus together due to an excess of either protons or neutrons. WHAT IS IONIZING RADIATION? Earth is surrounded by a blanket of gas (the atmosphere) so, when radioactive particles race through Earth, Earth collide with molecules of gases such as oxygen and nitrogen, splitting Earth apart into electrons and positively charged ions. This is called ionization. Now radiation may be impossible to see but detecting ions and electrons is much easier. That's the job that a Geiger counter does for us: a Geiger counter detects ionizing radiation by detecting the charged particles that the radiation creates as the radiation passes through gases in the world around us. HOW us RADIATION DETECTOR WORKS? Radiation detector works on the basic principle of Geiger Muller counter. · WHAT IS GEIGER MULLER COUNTER? GEIGER MULLER COUNTER is an instrument used for measuring ionizing radiation used widely in such applications as radiation dosimetry, radiological protection, experimental physics and the nuclear industry. · HOW Geiger MULLER COUNTER WORKS? 1. Radiation (dark blue) is moving about randomly outside the detector tube. 2. Some of Radiation (dark blue) enters the window (gray) at the end of the detector tube. 3. When radiation (dark blue) collides with gas molecules in the tube (orange), When radiation (dark blue) collides with gas molecules in the tube (orange) causes ionization: some of the gas molecules are turned into positive ions (red) and electrons (yellow). 4. positive ions (red) and electrons (yellow) are attracted to the outside of the tube (light blue). 5. positive ions (red) and electrons (yellow) are attracted to a metal wire (red) running down the inside of the tube maintained at a high positive voltage. As positive ions (red) and electrons (yellow) head for a metal wire (red) running down the inside of the tube maintained at a high positive voltage, some of a metal wire (red) running down the inside of the tube maintained at a high positive voltage collide with other gas molecules, splitting some of them into ions and more electrons. So we get a kind of chain reaction in which even a single particle of radiation can produce avalanches of electrons in rapid succession; this process is known as a Geiger discharge. 6. Many electrons travel down a metal wire (red) running down the inside of the tube maintained at a high positive voltage making a burst of current in a circuit connected to it. 7. Many electrons make a meter needle deflect and, if a loudspeaker is connected, you can hear a loud click every time particles are detected. The number of clicks you hear gives a rough indication of how much radiation is present (the meter gives you a much more accurate idea). 8. Before the counter can detect any more radiation, the counter needs to be restored to the counter original state through a process called quenching, which cancels out the effects of the Geiger discharge. Sometimes that's achieved by having a second gas (called a quenching gas, often a halogen) inside the tube. Or the tube can be done using an external circuit with a very large resistance. · CIRCUIT DIAGRAM:- Circuit diagram to show how a G.M. tube is used to record ionizing radiation positive electrical pulses are produced across the resistor Construction is similar to ionization chambers; with a central wire electrode (anode) inside a hollow metal tube. a G.M. tube differs from ionization chamber in being filled with a gas such as argon or neon rather than air. a gas such as argon or neon rather than air is at 1/5th of atmospheric pressure. Incident ionizing radiation will produce free electrons within a G.M. tube and free electrons will be attracted toward the central electrode (anode) which is held at positive potential. The potential applied in G.M tube is larger than ionization chamber usually several hundred volts. The electrons attracted towards the central anode are accelerated by The potential applied in G.M tube and gain sufficient energy to cause further ionization when all the http://www.explainthatstuff.com/resistors.html electrons produced hit the central anode all the http://www.explainthatstuff.com/resistors.html electrons produced can cause photons of visible light or ultraviolet radiation to be emitted which can cause yet more ionization in the gas of the chamber. The net result is that the original incident gamma rays can produce about 10^8 electrons in the chamber and this are quite easily measured at a pulse of current lasting about ‘1’ (one) microsecond Above circuit shows how a G.M tube can be connected so that pulses of about 10 volts can be obtained. The capacitor shown in diagram is used to isolate the recording circuit from the high voltage applied to a G.M tube."
: Product purchasing Billing section/ Bill with bar code Start Stop Products to delivery section Show bill to robot Corresponding product delivered
": We are going to implement rescuing biped robot using firebird 5 robot. Here, We are adding wireless camera for firebird to capture visuals of surroundings to locate the victims. We are going to control firebird 5 robot manually using zigbee. As an additional feature to firebird 5 robot, We add a temperature sensor to indicate the range of temperatures at the accident place. We receive video and the temperature at that place where firebird 5 robot actually is. We use two legs with simple motors to provide motion instead of wheels to use firebird 5 robot even in rough places and to make firebird 5 robot walk like human being."
": The system starts when a user initially ""flicks the switch"" and turns The system on. The system will then enter an initial setup phase where a few steps happen. First, power is sent to the air pump to start the air pump running. At the same time, power is also sent to the LEDs. power LED indicated that The system has power while the status LED indicates the status of the pH and nutrient adjustment liquid tanks. the status LED will always be activated when The system is first turned ON but will change after subsequent testing. Next, The system will test the Electrical Conductivity (EC) of the base water being used with no nutrients. The system will store this value and add The system as an offset to the EC thresholds used in EC tests. This step accounts for the conductance of the water used and will ensure accurate readings of EC after nutrients are added. In the next activity, The system will configure the Wi-Fi settings needed to join a pre-specified network and connect to a web server. If the ping was successful, the Wi-Fi LED will receive power and turn on. These steps will occur when The system is first turned on and will only execute once. This step is to load the threshold values for The system. the threshold values for the system include light intensity range, temperature & humidity range, pH range, EC range, and phototransistor range (sunrise to sunset). the threshold values for the system will be stored in variables and are subject to change by user input via the website. User’s specified plants will have corresponding pH and EC values that will be transmitted to The system and stored in these declared variables. If the user does not specify any values, default young plant values of pH = 6.0-6.5 and EC = 0.8-1.2 will be used .Each time The system performs this activity any changed values will be updated. Next is a power test. If the power is below a defined threshold, The system will send a low power message to the server. The system will then loops and enter an idle state for 25 minutes. During an idle state, The system will use very little power. After this timeout, The system will return to the load threshold activity. After the load threshold activity, The system will run the power test again until the power is above the threshold value. During this ""low power loop"", no sensor testing will be performed and no sensor data will be sent to the server to conserve battery life. The only component that will be running is the air pump. Once the battery has sufficient charge above the threshold value, The system will exit the loop and continue to the next activity which is sensor testing. Each sensor will be polled for values. A sensor test will be performed for temperature, pH, EC, photoconductivity (phototransistor). After each test the sensor values are translated into usable values. For example, the pH sensor returns millivolt values that need to be translated into pH values on the pH scale of 0-14. This translation can be achieved by calibrating the sensors beforehand. For example, taking the reading of the pH sensor in two different liquids of known pH will create a linear relationship between the two. The derived equation can then be used in the translation calculation. After all sensor translation, the phototransistor value is checked to see if the phototransistor value is within the threshold values. If the phototransistor value is, the data is stored. Then, the pH value will be checked to see if it is within the threshold values. If it is not, the pH correction activity will run. The pH correction will activate the peristaltic pumps (liquid nutrient dispenser) that will disburse the nutrient into the reservoir. The amount of liquid the liquid dispenser disburses will be calibrated beforehand. This will give an accurate measure of the relationship between the time each pump is ON and the amount of pH adjustment. At the end of the pH correction activity, a counter is incremented. a counter is used to count the number of times the pH correction activity runs on consecutive sensor tests. For each pH test that is within the threshold values, a counter is reset to 0. If a counter reaches four, an assumption is made that the system is out of pH down or nutrient liquids and the status LED is turned off. When this occurs, the pH test value is changed to 0. A value of 0 sent to the server triggers an email and/or text message alerting the user. Upon completion of the pH threshold check, the EC threshold check follows the same steps. If EC is below the minimum threshold, the peristaltic nutrient pump disburses more nutrients. The case of EC being more is neglected because with time, EC will decrease as the plants absorb more nutrients. A different counter will be used for EC tests and be adjusted in the same format at the pH tests except that an EC measurement above the maximum threshold value with not increase the counter. After both pH an EC threshold tests, temperature & humidity is measured and incase of any variations found, suitably cooling fan is switched ON in case of high temperature or the ventilation window is opened in case of low temperature and all sensor values are sent to the server (if a connection can be made) using the Wi-Fi module. If a connection cannot be made, the stored values will be sent to the user via GSM and rewritten on the next subsequent test. After this event, the system loops and enters the idle state for another 25 minutes. After this timeout, the system will load any new threshold values and the process will repeat. Fig 2 : System flow diagram Initial setup Ping server Load threshold Turn OFF Wi-Fi LED &turn ON GSM AND c Power check Send to server Temperature & humidity sensor Water level sensor pH sensor Light intensity sensor Electrical conductivity sensor Idle state Check for the light intensity Reset count Run pH correction Switch on artificial light Check pH value Check electrical conductivity Reset value Run EC correction Success Failure Out of range Out of range Out of range Within range Within range Within range Check humidity & temperature Turn ON the fan Out of range Within range Reset value"
"· Use of Multi flame Sensors. "· Use of Multi flame Sensors. "· Use of Multi flame Sensors. · Study of Color, Texture and Shape features by using Neural Network."
"To implement the proposed system, the arena resembling the bed rooms or wards available in the hospitals as shown in figure 1 is considered. the arena resembling the bed rooms or wards available in the hospitals as shown in figure 1 is separated into two parts that the right part of the decision junction is considered as collection area where four different tablets are placed in the respective containers indicating by different colours (Red, Blue, Green and Yellow). The left part of the decision junction is considered as delivery area where the tablets are to be delivered to the patients in four beds (denoted as Bed 1, Bed 2, Bed 3 and Bed 4) respectively. As well the arena resembling the bed rooms or wards available in the hospitals as shown in figure 1 has the black line as shown by which the robot will traverse the entire area from START position to the END position. The concerned coloured container having tablet means to distribute tablet means to distribute them to the corresponding colouring bed which is available on the left side of the decision junction point to the corresponding colouring bed which is available on the left side of the decision junction point. Figure 1 - The arena design the robot consists of arm with gripper arrangement is used for picking and dropping the tablets. The representation of the robot is shown in figure 2. Figure 2 - Fire Bird V Robot with Gripper Arrangement Figure 2 - Fire Bird V Robot with Gripper Arrangement is made in such a way that one side of the vertical portion is fixed and the other is moveable and the horizontal portion of the gripper is also adjustable to provide the tablets to the patients in the hospital bed rooms. Figure 2 - Fire Bird V Robot with Gripper Arrangement is placed on freely rotating plate on which tablets collecting coloured (Red, Blue, Green and Yellow) trays are fixed. The rotating plate is used to collect the tablets when the robot reaches the corresponding coloured tablet boxes in the arena. the robot is performing the functions that the robot could the coloured tablet box using colour sensor and the tablets can be picked up using Infrared Proximity sensor. The operation of the robot is explained as stages such as stage 1, stage 2, stage 3 and stage 4. the robot is well programmed to perform all the stage from 1 to 4 of the robot is shown in figure 3. Stage 1 In the tablet area, the tablet boxes are initially filled with sufficient amount of tablets by the staff of the hospital manually. the robot has to be positioned at START in the arena. Then, the robot is informed through Zigbee module that from which tablet box the pill has to be taken by means of providing the data through the Terminal Software such as 1(Red Colour Tablet Box), 2(Blue Colour Tablet Box , 3(Red Colour Tablet Box) and 4(Yellow Colour Tablet Box). Stage 2 and Stage 3 After getting the information, the robot starts to pick up the tablet from the corresponding coloured tablet box as per the input given by the terminal software. In this stage, the robot takes the tablet using the arm with gripper arrangement as shown in stage 2 of the figure 3. Those tablets are kept upon the corresponding tray boxes available on the top surface portion of the robot. Then, robot moves to decision junction point and getting ready to dispense the tablet to the corresponding patients. Stage 4 From the decision junction point, the robot moves to the concerned beds depending upon the input received. Every bed has an adjunct parallel path and a dispenser box. Through this parallel path, all the tablets available on the trays can be dispensed automatically to the concerned coloured bed patients. After dispensing Those tablets, the robot again comes back to the START / END position to take up the next command or processes. This cyclic process would be taking place without any human interventions. Figure 3 - Implementation Diagram of DDR"
": Implementation of this robot involves a sequence of procedure like · Designing circuit layout and model of this robot. · After designing, all the parts are assembled as per the requirement. · this robot is then fabricated as per the requirement. · The working of this robot is monitored and the required application is then implemented and tested as per the need. Schematic layout of robot (Robot model, circuit diagrams) Identifying and gathering the necessary parts Development of robot (Fabrication and necessary software installation) Testing CIRCUIT DIAGRAM: MICRO CONTROLLER POWER BATTERY SOLAR PANEL SIGNAL MOTOR (FOR SPRAYING) SENSOR MOTOR (FOR MOVEMENT)"
OVERLOADED BUS CONTROLLER system is implemented using sensors and microcontroller and other electronic circuits like fuel injection circuit. OVERLOADED BUS CONTROLLER system will count the incoming passengers in the bus using a sensor and if the capacity of the bus is overloaded then the microcontroller will automatically make the bus static using fuel injection circuit and thereby Solving the Problems of dealing with excessive passengers in public buses and reducing cost and labour power and reduces deaths and severe injuries in accidents involving buses with excessive passengers.
": The patient’s vital signs such as respiration rate, heart rate, body temperature and blood pressure are monitored through sensors. The sensor is interfaced with arduino board. The sensor will check whether the 3 sensor output is within acceptable limits. If the sensor output exceeds standard values, then messages will be sent to the doctor. The block diagram is shown in figure 1. Figure 1: Block Diagram The algorithm for finding the heartbeat rate is shown as flowchart in figure 2. The algorithm for finding the blood pressure rate is shown as flowchart in figure 4. The algorithm for finding the body temperature is shown as flowchart in figure 5. The algorithm for finding the respiration rate is shown as flowchart in figure 6. Heart rate Monitor: Figure 2: Heartbeat Rate CALCULATION:- Five pulse time=time2-time1 4 Single pulse time= Five pulse time /5 Rate=60000/ Single pulse time OBSERVATION:- Figure 3: Analog output Blood Pressure Monitor: Figure 4: Blood Pressure Rate 5 CALCULATION:- Body Temperature & Respiration rate: BODY TEMPERATURE RESPIRATION RATE Figure 5: Body Temperature measurement Figure 6: Respiration Rate 6 Working: Our proposed idea is a wireless communication system for remote patient monitoring. The main objective is to give the report of a person’s health signs. In case of any emergency situation, the reports are sent to the doctor b means of GSM module. In heart rate monitor, an analog sensor is used where the samples are taken at every instant of 10 seconds and the rate of heartbeat is calculated. Similarly for blood pressure, body temperature and respiration rate, its corresponding sensors are used and the result is calculated according to its algorithm. Then every parameter is viewed by using LCD display. If the parameters cross the safe limit, a warning signal is given to the doctor along with the abnormal reports by using a GSM module. As it is user-friendly, even elderly persons can be benefitted."
"The user needs to give some voice commands to make a robot work. The voice input given through the microphone is either directly passed to the Google API.AI, here Google recognizes the input and as a output Google sends specific instructions to the Arduino or here we can also create we own database in which the commands are stored and a cloud of this instructions is created which will be accessed through Wi‐Fi and then accordingly based on the data from database the instructions are passed to the Arduino. Now as the Arduino receives the input for what to do, based on this input sets of instructions are performed and this makes the robot move and perform actions as per the user input."
"The GPS signal is sent to the Garbage locator when the ultrasonic sensor detects that the garbage is full , when The GPS signal is received by the garbage collector ,The GPS signal checks the location of the particular garbage bin with the google maps API our firebird find the shortest path to the desired garbage bin ,once the garbage collector finds the shortest path then the garbage collector starts searching the particular garbage bin in the desired path , the desired path is implemented using black line follower , if any object is in the line the garbage collector should stop and check for the second shortest path , then if the GPS location is reached , the GPS location is identified using image processing and the GPS location stops when an object is in the path of the garbage collector , once an object identified the particular garbage bin , the GPS location takes the particular garbage bin and drops the garbage in the particular garbage bin which is present in the particular garbage bin and places the particular garbage bin in the particular place ,and the particular garbage bin returns to the central station and disposes the garbage ."
"Implementation of the proposed device is the quantification of the force needed to penetratethe skin and provide an optimal penetration depth of the microneedle. In order to sample blood painlessly,the microneedle has to reach the blood capillaries without touching the nerves. In addition, the channel diameter of the microneedle has to be engineered sufficiently wide to pass the largest blood cells. At the sametime, the channel diameter of the microneedle has to be small enough to let capillary forces pullthe blood into and through the microneedle.A pyramidal, side-opened, out-of-plane microneedledesign found to be adequate mechanical strengthof about 400 lm (Griss and Stemme 2003). Thee-Mosquito microneedle (Fig. 2) is designed to either sample blood or subcutaneously deliver medication. Inorder to easily break the stratum corneum, the needlehas to be sharp. However, since the mechanical properties The e-Mosquito concept: device building blocks include microneedle, microactuator, blood collection and analysis compartment, microsensor, microelectronic conditioning and analog-todigital (A/D) conversion, radiofrequency (RF) transceiver and microbattery of human skin are not sufficiently well characterized or known, precise requirements for the sharpness of the needle are difficult to formulate (Wang and Prausnitz 2002). There are two possible failure scenarios for the needle: fracture or buckling. Both could occur during the insertion of the needle into the skin. Failure may occur under load, causing either fracture or buckling, whichever is lower. A worst-case estimate of the maximum load, which the needle can withstand, can be calculated assuming that the breakage is confined to a region near the microneedle tip. Specific microneedledesign requirements include simplicity, ease of fabrication, and low flow resistance for minimal clogging. The proposed silicon microneedle has the following dimensions: a height of 450 lm, a base length of 300 lm, a base width of 100 lm, a hole diameter of 50 lm, and an orifice aperture range between 300 and 375 lm above the base. For the following dimensions: a height of 450 lm, a base length of 300 lm, a base width of 100 lm, a hole diameter of 50 lm, and an orifice aperture range between 300 and 375 lm above the base, The proposed silicon microneedle was calculatedhat the capillary force draws the blood from the capillaries into the e-Mosquito blood compartment without an external assistance such as a micropump. 2.2 Microactuator: The most intricate design problem in the entire e-Mosquito system is the automatic actuation and control of an individual microneedle. 2.2 Microactuator has to meet a minimum of two pivotal design constraints to successfully fulfill 2.2 Microactuator purpose: (1) the maximal displacement has to be large enough to insert The proposed silicon microneedle up to 2.2 Microactuator optimal depth of 400 lm (2) the force exerted on The proposed silicon microneedle must be sufficient to pierce the sharp tip through the stratum corneum (the external and most resistive layer Although the motion analysis is focused on piezoelectric actuation, magnetic, thermal and electrostatic actuation methods were also explored. Of particular interest is the thermal actuation principle, being advantageous in (1) the manifestation of large displacements;(2) consuming a low operating voltage; and(3) being relatively straightforward to fabricate. fig.2 different layers of the human skin.the proposed microneedle penetrates the blood capaliriespainlessly without touching the nerves Fig,3 side of view of an ANSYS-based finite element analysis applied to the e- mosquito micro actuator-microneedleassembly.the actuated micro bridge introduces the implemented micro needle into the skin. Microsensor: Another building block of the e-Mosquito is the electrochemicalmicrosensor. The very small volume ofblood (_1.5 ll) delivered by the sampling process isstored in a miniature blood compartment just above themicroactuator. Figure 4 demonstrates the microsensor– microactuator assembly forming the blood compartment.Three microsensor electrodes (see Fig. 5) areimplemented at the ceiling of the microsensor structure.A microvalve, also attached at the ceiling of the microsensor structure, keeps theblood compartment sterile during the non-operationaltime of the e-Mosquito and also prevents the blood—-once inside the blood compartment—from leaking out of thechamber.The task of the microsensor is to convert the bloodelement of interest (for example, the glucose level) intoan electrical signal. This automated and selfcalibratedprocedure is performed by an amperometricmicrosensor integrated inside the blood compartment. Figure 5shows a bottom and a cross-sectional view of the microsensor structure. The amperometric glucose microsensor includes two active electrodes and a reference electrode. This electrode configuration is typically used for the implementation of Ion-Sensitive Field Emission Transistor (ISFET) microsensors Fig 4. Side view of the e-Mosquito microsensor–microactuator assembly. the microsensor structure is implemented on top of themicroactuator and hence forms the blood compartment. The microsensor electrodes are employed at the ceiling of the microsensor structure togetherwith a microvalve Fig 4. 5 Bottom view and crosssection(Z) of the e-mosquitomicrosensorstructure.The electrochemical lmicrosensorencompasses two activeelectrodes and arefereneelectrode which are embedded in a gel below a glucose selective membrane. 2.4 Microelectronics The control of the complete e-Mosquito system isimplemented utilizing microelectronic circuitry employing Very Large System Integration (VLSI) technology. 2.4 Microelectronics perform the following functions: (1) timing and triggering the microactuation; (2) converting, conditioning and amplifying the signals originating from the microsensor; and (3) directing data wirelessly either to a remote visualization device (i.e. wrist watch, personal digital assistant, cell phone, etc.) or to supplementary medication delivery mechanis such as an insulin infusion pump. The electrical diagram of a possible application of the e-Mosquitocell for automatic real-time insulin control is presented in Fig. 6. The current I resulting from the microsensor operation is converted in the first stage (I/V) into a voltage (vs), which is very small and noisy. In the amplification and conditioning stage (ACS) this small voltage (vs) is amplified into a voltage (Vs) and subsequently converted into a digital signal (0-1) in the stage (A/D). The RF transmitter (R·T) captures the digital signal (0-1) to transmit The RF transmitter (R·T) wirelessly (range _5 m) to the RF receiver (R·R) of the remote device. In the remote device, a data logger (DL) sends a digital signal (0-1) in the stage (A/D) to a microcontroller (lC), from which the processed signal is delivered to a display (LCD) and is finally read as a glucose concentration. This stage completes the blood sampling process and closes the glucose monitoring loop. In addition, the microcontroller output is utilized to close the insulin control loop by controlling an external insulin infusion pump (Insulin Ctrl) or by simply transmitting control sequence through the RF transmitter (R·T) back to the on-chip microelectronic control of the eMosquito to actuate dedicated drug-delivery cells within it. Upon completion of blood sampling and glucose concentration reading, the remote microcontroller (lC) decides when to issue another actuation signal to a different e-Mosquito cell based on a pre-programmed protocol. Two scenarios are possible: (a) if the current glucose-reading has been successful, the next actuation is pre-programmed to occur according to a specific schedule designed for the individual patient utilizing the e-Mosquito patch; or (b) in case of unsuccessful readout from the particular e-Mosquito cell, another actuation of a new cell is immediately initiated. It should be emphasized once again that each individual e-Mosquito cell is actuated only once and re-actuations are not envisioned. another actuation signal is wirelessly transmitted from the remote transmitter (R·T) to the RF receiver (R·R), which is part of the e-Mosquito device. An onchip microcontroller (lC) receives the incoming feedback signal and controls the actuation voltage (Va) of the next e-Mosquito cell. The e-Mosquito microcontroller lC is remotely programmable to control not only the actuation, but also the transmission of the conditioned analog voltage (Vs) representing the sensed blood glucose level to the analog-todigital converter(A/D) Fig. 6 Electrical diagram of glucose level monitoring and blood sampling control combined illustrating the e- Mosquito principle of operation. The electrical stages are discussed in detail in the text. Microbattery The energy consumption of each building block of the presented microsystem was calculated and The energy consumption of each building block of the presented microsystem was concluded that commercially available microbatterie scan be used as an energy source for the e-Mosquito microsystem. These batteries are as small as 29·22 mm2 in area, 0.44 mm in height and 0.6 g in weight (VARTA 2003). The cells have a nominal voltage of 3 V and a capacity of 25 mA h. The energy density reaches up to 110 Wh/kg System integration: System integration on a microscale is an involved and complex process, particularly in the context of the limited manufacturing technologies available (Moore and Syms 1999). For the successful design of an integrated microsystem, many characteristics and parameters need to converge. In the process of integration of the e- Mosquito system, diverse technologies (e.g. microelectronics,micromechanics and microfluidics, to mention a few) were studied and successfully brought together inorder to propose a feasible microsystem design with adequate functionality. These integration onsiderations were addressed, keeping in mind that a suitable micromachining process is imperative for practical implementation and testing of the device. In a feasible microsystem design with adequate functionality, the microneedle, the microactuator structure, and the microsensor structure (Fig. 7) are brought together into a configuration representing a single e-Mosquito cell, which is then multiplied into an entire network forming a complete e-Mosquito matrix. The dimensions of the e-Mosquito matrix depend on the dimensions of a single e-Mosquito cell, which are approximately length 10 mm, height 1 mm, and width 0.5 mm. The height of the matrix is equal to the sum of the height of the microsensor structure, and the height of the microactuator structure, respectively. The e-Mosquito matrix consists of three single eMosquito cells alongside each other, and 60 cells along The e-Mosquito matrix width. This builds a matrix of 180 individually actuated e-Mosquito cells. Substituting the dimensions numerically, a matrix of 180 individually actuated e-Mosquito cells has a square area of 900 mm2 with a length of 30 mm, a width of 30 mmand a height of 1 mm. The e-Mosquito matrix as shown in Fig. 7, is further integrated into an eMosquito patch (Fig. 8), which includes an adhesive and antiseptic layer, microelectronics, a microbattery, housing, and a band-aid type of cover. The area of the entire e-Mosquito patch is in the maximal range of 50·50 mm2. An example of the attachment of the e-Mosquito on a subject is presented in Fig. 9. The region of attachment of the e-Mosquito patch should be an area with high blood circulation (i.e.)skeletal muscle) and where high blood circulation (i.e.)skeletal muscle) comes close to the skin surface. A possible region that meets these requirements is the deltoid muscle which encompasses the shoulder bones. The attachment of subsequent e- Mosquito patches could be done on alternate shoulders to avoid possible skin irritation Fig. 7 Integration of the single e-Mosquito cell into the e- Mosquito matrix. The single eMosquito cell consists of the microneedle, the microactuator structure, and the microsensor structure Fig. 8 Exploded view of the e-Mosquito patch and the e-Mosquito patch building blocks: adhesive band-aid cover, housing, microbattery,microelectronics, e-Mosquito matrix, and adhesive and antiseptic layer Fig. 9 Compact 3D view of the e-Mosquito patch attached to the shoulder of a subject Fig. 10 The first three fabrication steps for the manufacturing of the e-Mosquito cell: microactuator structure (I), microsensor structure (II), and microelectronics (III) Fig. 11 Bonding is the fabrication step IV and the fabrication step IV assembles the e-Mosquito building blocks: microactuator structure, microsensor structure, and microelectronics 4 Fabrication and assembly The fabrication and assembly process of the e-Mosquito is divided into five steps. The fabrication of the microactuator and the microactuator integration with the microneedle (step I) is accomplished on a separate wafer, utilizing surface and bulk micromachining techniques (see Fig. 10). ISFET technology is used for the implementation of the microsensor on a second silicon wafer (step II). The fabrication of 2.4 Microelectronics using Complementary Metal Oxide Silicon (CMOS)-based VLSI technologyis implemented on a third wafer (step III). The bonding of the three wafers (microactuator microneedle, microsensor, and microelectronics) is completed in step IV (Fig. 11) and the assembly of the remaining parts including the microbattery, the adhesive and antiseptic layer, the housing, and the band-aid cover is finalized in step V. The outlined three-wafer fabrication procedure (steps I-IV), is advantageous in many ways. One of the most important benefits however is the most important benefits compatibility with the implementation of the e-Mosquito matrix: a siliconwafer containing a matrix of microsensors is aligned and bonded on top of a wafer holding a matrix of microactuators, with the same characteristics as fabrication steps I and II. A third wafer containing the outlined in microelectronics (fabrication step III) is then implemented on top of the wafer containing the matrix ofmicrosensors."
The main control i.e. push button controls our system then transporting robot follows the black path. speed of conveyor belt and laser sensor is controlled by Controller . After reaching the robot below the conveyor belt the laser sensor detects the robot and trolley carrying the material. controller slow down the speed of belt same with the speed of robot. the robot below the conveyor pick up material and transport the robot below the conveyor to reception section with obstacle avoiding.
"1) This project can be used in international airport and in all local airports. The bar code scanner will be placed in front of the boarding corner. 2) The advanced visa will be scanned by The bar code scanner by using arduino programming and also using Bio-metric scanner (Thumb impressions). 3) Where the boarding pass is be provided to the passengers by using system. 4) The advanced visa is act as a identity card of Indian citizen. 5) If the person doesn’t return to our country even after the expire of visa, then automatically information will be send through by message or e- mail. All related departments and customs, embassy and head quarters of police,etc…"
"Needy hospital will upload the requirement of organ on the website portal. The acknowledgement will be given to Needy hospital. Needy hospital will be ready to transport. Ground Station will provide GPS co-ordinates of needy hospital and path for same to VTOL . VTOL plane will transport the organ to needy hospital avoiding the obstacles. Web Portal : Here the user will upload the requirement of organ. Names of the donor hospitals with availability of organ will be displayed along with Names of the donor hospitals with availability of organ respective distances from needy hospital. the user will choose the donor hospital from where the user wants the organ. Ground Station : The server will send the hospital location ,distance and estimated time to Ground Station. Pilot will define the path for VTOL and Pilot will be given to VTOL. The real time monitoring is done and if the drone changes The real time monitoring predefined path Pilot will manually override the drone to bring the drone back to Pilot planned path. VTOL Drone: Basically VTOL is quad copter plus plane. Vertical Take Off and Landing plane is controlled by Autopilot. Autopilot is having Autopilot own accelerometer , gyroscope , magnetometer to stabilize the drone. Externally GPS is connected for automated flight. User Interface : User can track the real time location of VTOL and the time left for delivery . Before five minutes to reach the destination VTOL will send the message to needy hospital on online web portal. Image Processing : We are using GPS for landing VTOL. We are also providing a landing image at the receiving hospital to overcome the drawbacks in landing using GPS. So VTOL will land on the image accurately. For this We are using image processing to maintain vertical position in landing."
"An Arduino is an open source microcontroller development board. An Arduino sense the environment by receiving inputs from various sensors and control the peripherals based on the sensed values. An Arduino is powered up with sensors input and motor as an output device. An Arduino module contain different sensors like temperature and humidity, phase detector, this data is uploaded using IoT into the server. By this data farmer can monitor and control from any part of the world. We will place the sensor setfor every 4ft inthe field laterally. Each sensor set consists of 3 sensors with 1ft distance between Each sensor longitudinally.3 sensors with 1ft distance between them longitudinally gives the data to arduino module. For identifying, moisture content in the soil. We used a sensor to monitor the supply lines for any fault if so, a buzzer is placed to notify the fault in supply. By this data farmer knows what is the problem occurred in the power supply lines.The 3-ф detector circuit is used in this project to check whether the 3-ф power is available forthe motor or not. In case, if it is not available, The 3-ф detector circuit identifies this and immediately switch OFF the motor and sends a predefined alert to the farmer about the status of the motor. IoT uploads the sensed data into a dedicated website on based upon on the values in this data farmer is notified about the status of the station. Since IoT supports a two way communication farmer can also control the devices on observing the status of the stationthe station. Smart pump set management which includes temperature maintenance, humidity maintenance and theft detection in the pump set. Controlling of all these operations will be through any smartdevice connected to internet."
An intellectual robots is capable of detecting white line on a lighter surface depending on the constract using white line sensors. An intellectual robots estimate whether the line underneath An intellectual robots are shift towards An intellectual robots right /left as An intellectual robots move over An intellectual robots. Based on the estimation An intellectual robots give respective signals t the motors to turn right/left so as to maintain a steady centre with respect to the line IR Sensors in the front of the robots they emit rays as An intellectual robots traverse. If any obstacle comes on any obstacle way at a certain distance the rays gets reflected and signal are sent to the motor to halt thus avoiding any damage to the obstacle and the robot.